{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0da31a9",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6691363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    計算模型的參數數量\n",
    "    Returns:\n",
    "      total_params: 包含所有參數\n",
    "      trainable_params: 只包含 requires_grad=True 的參數\n",
    "    \"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "import io\n",
    "\n",
    "def estimate_model_size(model):\n",
    "    \"\"\"\n",
    "    將模型序列化到緩衝區，估算存檔大小（MB）\n",
    "    \"\"\"\n",
    "    buffer = io.BytesIO()\n",
    "    torch.save(model.state_dict(), buffer)\n",
    "    size_mb = buffer.getbuffer().nbytes / (1024 ** 2)\n",
    "    return size_mb\n",
    "\n",
    "def show_network_status( orig_net, prune_net ):\n",
    "    print( \"原始網路參數統計:\\n\" )\n",
    "    model = orig_net\n",
    "    total, trainable = count_parameters(model)\n",
    "    print(f\"總參數量: {total:,}\")\n",
    "    print(f\"可訓練參數量: {trainable:,}\")\n",
    "\n",
    "    size_mb = estimate_model_size(model)\n",
    "    print(f\"模型存儲大小: {size_mb:.2f} MB\")\n",
    "\n",
    "    print( \"剪枝網路參數統計:\\n\" )\n",
    "    model = prune_net\n",
    "    total, trainable = count_parameters(model)\n",
    "    print(f\"總參數量: {total:,}\")\n",
    "    print(f\"可訓練參數量: {trainable:,}\")\n",
    "\n",
    "    size_mb = estimate_model_size(model)\n",
    "    print(f\"模型存儲大小: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33ffb814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from os2d.modeling.model import build_os2d_from_config\n",
    "from os2d.config import cfg\n",
    "import  os2d.utils.visualization as visualizer\n",
    "from os2d.structures.feature_map import FeatureMapSize\n",
    "from os2d.utils import setup_logger, read_image, get_image_size_after_resize_preserving_aspect_ratio\n",
    "from os2d.data import dataloader\n",
    "from os2d.modeling.model import build_os2d_from_config\n",
    "\n",
    "from os2d.data.dataloader import build_eval_dataloaders_from_cfg, build_train_dataloader_from_config\n",
    "from os2d.engine.train import trainval_loop\n",
    "from os2d.utils import set_random_seed, get_trainable_parameters, mkdir, save_config, setup_logger, get_data_path\n",
    "from os2d.engine.optimization import create_optimizer\n",
    "from os2d.config import cfg\n",
    "from os2d.utils.visualization import *\n",
    "import random\n",
    "import os2d.utils.visualization as visualizer\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os2d.utils import get_image_size_after_resize_preserving_aspect_ratio\n",
    "from src.util.detection import generate_detection_boxes\n",
    "from src.util.visualize import visualize_boxes_on_image\n",
    "from src.util.filter import DataLoaderDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50cd0f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os2d.utils import setup_logger, read_image, get_image_size_after_resize_preserving_aspect_ratio\n",
    "\n",
    "logger = setup_logger(\"OS2D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c1c3bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-18 17:22:44,371 OS2D INFO: Building the OS2D model\n",
      "2025-07-18 17:22:44,742 OS2D INFO: Creating model on one GPU\n",
      "2025-07-18 17:22:44,770 OS2D INFO: Reading model file ./src/util/checkpoints-test/checkpoint_lcp_finetune_26_layer3.5.conv2.pth\n",
      "2025-07-18 17:22:44,808 OS2D INFO: Loaded feature extractor from checkpoint\n",
      "2025-07-18 17:22:44,837 OS2D INFO: Restoring pruned parameters to original dimensions...\n",
      "Found 40 total layers in database\n",
      "Filtered to 20 layers starting with 'layer'\n",
      "[LCP] 層級依賴分析完成 - net_feature_maps.layer1.0.conv1\n",
      "      BatchNorm: net_feature_maps.layer1.0.bn1\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[LCP] 層級依賴分析完成 - net_feature_maps.layer1.0.conv2\n",
      "      BatchNorm: net_feature_maps.layer1.0.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[LCP] 層級依賴分析完成 - net_feature_maps.layer1.1.conv1\n",
      "      BatchNorm: net_feature_maps.layer1.1.bn1\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[LCP] 層級依賴分析完成 - net_feature_maps.layer1.1.conv2\n",
      "      BatchNorm: net_feature_maps.layer1.1.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[LCP] 層級依賴分析完成 - net_feature_maps.layer1.2.conv1\n",
      "      BatchNorm: net_feature_maps.layer1.2.bn1\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[LCP] 層級依賴分析完成 - net_feature_maps.layer1.2.conv2\n",
      "      BatchNorm: net_feature_maps.layer1.2.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[LCP] 層級依賴分析完成 - net_feature_maps.layer2.0.conv1\n",
      "      BatchNorm: net_feature_maps.layer2.0.bn1\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[LCP] 層級依賴分析完成 - net_feature_maps.layer2.0.conv2\n",
      "      BatchNorm: net_feature_maps.layer2.0.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[LCP] 層級依賴分析完成 - net_feature_maps.layer2.1.conv1\n",
      "      BatchNorm: net_feature_maps.layer2.1.bn1\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[LCP] 層級依賴分析完成 - net_feature_maps.layer2.1.conv2\n",
      "      BatchNorm: net_feature_maps.layer2.1.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[LCP] 層級依賴分析完成 - net_feature_maps.layer2.2.conv1\n",
      "      BatchNorm: net_feature_maps.layer2.2.bn1\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[LCP] 層級依賴分析完成 - net_feature_maps.layer2.2.conv2\n",
      "      BatchNorm: net_feature_maps.layer2.2.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[LCP] 層級依賴分析完成 - net_feature_maps.layer2.3.conv1\n",
      "      BatchNorm: net_feature_maps.layer2.3.bn1\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[LCP] 層級依賴分析完成 - net_feature_maps.layer2.3.conv2\n",
      "      BatchNorm: net_feature_maps.layer2.3.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[LCP] 層級依賴分析完成 - net_feature_maps.layer3.0.conv2\n",
      "      BatchNorm: net_feature_maps.layer3.0.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[LCP] 層級依賴分析完成 - net_feature_maps.layer3.1.conv2\n",
      "      BatchNorm: net_feature_maps.layer3.1.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[LCP] 層級依賴分析完成 - net_feature_maps.layer3.2.conv2\n",
      "      BatchNorm: net_feature_maps.layer3.2.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[LCP] 層級依賴分析完成 - net_feature_maps.layer3.3.conv2\n",
      "      BatchNorm: net_feature_maps.layer3.3.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[LCP] 層級依賴分析完成 - net_feature_maps.layer3.4.conv2\n",
      "      BatchNorm: net_feature_maps.layer3.4.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[LCP] 層級依賴分析完成 - net_feature_maps.layer3.5.conv2\n",
      "      BatchNorm: net_feature_maps.layer3.5.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "✅ 恢復輸出通道: net_feature_maps.layer1.0.conv1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.0.bn1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.0.bn1.bias\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.0.bn1.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.0.bn1.running_var\n",
      "✅ 恢復輸出通道: net_feature_maps.layer1.0.conv2.weight\n",
      "✅ 恢復輸入通道: net_feature_maps.layer1.0.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.0.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.0.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.0.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.0.bn2.running_var\n",
      "✅ 恢復輸入通道: net_feature_maps.layer1.0.conv3.weight\n",
      "✅ 恢復輸出通道: net_feature_maps.layer1.1.conv1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.1.bn1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.1.bn1.bias\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.1.bn1.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.1.bn1.running_var\n",
      "✅ 恢復輸出通道: net_feature_maps.layer1.1.conv2.weight\n",
      "✅ 恢復輸入通道: net_feature_maps.layer1.1.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.1.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.1.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.1.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.1.bn2.running_var\n",
      "✅ 恢復輸入通道: net_feature_maps.layer1.1.conv3.weight\n",
      "✅ 恢復輸出通道: net_feature_maps.layer1.2.conv1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.2.bn1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.2.bn1.bias\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.2.bn1.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.2.bn1.running_var\n",
      "✅ 恢復輸出通道: net_feature_maps.layer1.2.conv2.weight\n",
      "✅ 恢復輸入通道: net_feature_maps.layer1.2.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.2.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.2.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.2.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer1.2.bn2.running_var\n",
      "✅ 恢復輸入通道: net_feature_maps.layer1.2.conv3.weight\n",
      "✅ 恢復輸出通道: net_feature_maps.layer2.0.conv1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.0.bn1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.0.bn1.bias\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.0.bn1.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.0.bn1.running_var\n",
      "✅ 恢復輸出通道: net_feature_maps.layer2.0.conv2.weight\n",
      "✅ 恢復輸入通道: net_feature_maps.layer2.0.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.0.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.0.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.0.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.0.bn2.running_var\n",
      "✅ 恢復輸入通道: net_feature_maps.layer2.0.conv3.weight\n",
      "✅ 恢復輸出通道: net_feature_maps.layer2.1.conv1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.1.bn1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.1.bn1.bias\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.1.bn1.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.1.bn1.running_var\n",
      "✅ 恢復輸出通道: net_feature_maps.layer2.1.conv2.weight\n",
      "✅ 恢復輸入通道: net_feature_maps.layer2.1.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.1.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.1.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.1.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.1.bn2.running_var\n",
      "✅ 恢復輸入通道: net_feature_maps.layer2.1.conv3.weight\n",
      "✅ 恢復輸出通道: net_feature_maps.layer2.2.conv1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.2.bn1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.2.bn1.bias\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.2.bn1.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.2.bn1.running_var\n",
      "✅ 恢復輸出通道: net_feature_maps.layer2.2.conv2.weight\n",
      "✅ 恢復輸入通道: net_feature_maps.layer2.2.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.2.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.2.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.2.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.2.bn2.running_var\n",
      "✅ 恢復輸入通道: net_feature_maps.layer2.2.conv3.weight\n",
      "✅ 恢復輸出通道: net_feature_maps.layer2.3.conv1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.3.bn1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.3.bn1.bias\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.3.bn1.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.3.bn1.running_var\n",
      "✅ 恢復輸出通道: net_feature_maps.layer2.3.conv2.weight\n",
      "✅ 恢復輸入通道: net_feature_maps.layer2.3.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.3.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.3.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.3.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer2.3.bn2.running_var\n",
      "✅ 恢復輸入通道: net_feature_maps.layer2.3.conv3.weight\n",
      "✅ 恢復輸出通道: net_feature_maps.layer3.0.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.0.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.0.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.0.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.0.bn2.running_var\n",
      "✅ 恢復輸入通道: net_feature_maps.layer3.0.conv3.weight\n",
      "✅ 恢復輸出通道: net_feature_maps.layer3.1.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.1.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.1.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.1.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.1.bn2.running_var\n",
      "✅ 恢復輸入通道: net_feature_maps.layer3.1.conv3.weight\n",
      "✅ 恢復輸出通道: net_feature_maps.layer3.2.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.2.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.2.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.2.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.2.bn2.running_var\n",
      "✅ 恢復輸入通道: net_feature_maps.layer3.2.conv3.weight\n",
      "✅ 恢復輸出通道: net_feature_maps.layer3.3.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.3.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.3.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.3.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.3.bn2.running_var\n",
      "✅ 恢復輸入通道: net_feature_maps.layer3.3.conv3.weight\n",
      "✅ 恢復輸出通道: net_feature_maps.layer3.4.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.4.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.4.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.4.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.4.bn2.running_var\n",
      "✅ 恢復輸入通道: net_feature_maps.layer3.4.conv3.weight\n",
      "✅ 恢復輸出通道: net_feature_maps.layer3.5.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.5.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.5.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.5.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_feature_maps.layer3.5.bn2.running_var\n",
      "✅ 恢復輸入通道: net_feature_maps.layer3.5.conv3.weight\n",
      "✅ 恢復輸出通道: net_label_features.net_class_features.layer1.0.conv1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.0.bn1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.0.bn1.bias\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.0.bn1.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.0.bn1.running_var\n",
      "✅ 恢復輸出通道: net_label_features.net_class_features.layer1.0.conv2.weight\n",
      "✅ 恢復輸入通道: net_label_features.net_class_features.layer1.0.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.0.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.0.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.0.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.0.bn2.running_var\n",
      "✅ 恢復輸入通道: net_label_features.net_class_features.layer1.0.conv3.weight\n",
      "✅ 恢復輸出通道: net_label_features.net_class_features.layer1.1.conv1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.1.bn1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.1.bn1.bias\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.1.bn1.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.1.bn1.running_var\n",
      "✅ 恢復輸出通道: net_label_features.net_class_features.layer1.1.conv2.weight\n",
      "✅ 恢復輸入通道: net_label_features.net_class_features.layer1.1.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.1.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.1.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.1.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.1.bn2.running_var\n",
      "✅ 恢復輸入通道: net_label_features.net_class_features.layer1.1.conv3.weight\n",
      "✅ 恢復輸出通道: net_label_features.net_class_features.layer1.2.conv1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.2.bn1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.2.bn1.bias\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.2.bn1.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.2.bn1.running_var\n",
      "✅ 恢復輸出通道: net_label_features.net_class_features.layer1.2.conv2.weight\n",
      "✅ 恢復輸入通道: net_label_features.net_class_features.layer1.2.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.2.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.2.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.2.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer1.2.bn2.running_var\n",
      "✅ 恢復輸入通道: net_label_features.net_class_features.layer1.2.conv3.weight\n",
      "✅ 恢復輸出通道: net_label_features.net_class_features.layer2.0.conv1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.0.bn1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.0.bn1.bias\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.0.bn1.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.0.bn1.running_var\n",
      "✅ 恢復輸出通道: net_label_features.net_class_features.layer2.0.conv2.weight\n",
      "✅ 恢復輸入通道: net_label_features.net_class_features.layer2.0.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.0.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.0.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.0.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.0.bn2.running_var\n",
      "✅ 恢復輸入通道: net_label_features.net_class_features.layer2.0.conv3.weight\n",
      "✅ 恢復輸出通道: net_label_features.net_class_features.layer2.1.conv1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.1.bn1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.1.bn1.bias\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.1.bn1.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.1.bn1.running_var\n",
      "✅ 恢復輸出通道: net_label_features.net_class_features.layer2.1.conv2.weight\n",
      "✅ 恢復輸入通道: net_label_features.net_class_features.layer2.1.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.1.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.1.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.1.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.1.bn2.running_var\n",
      "✅ 恢復輸入通道: net_label_features.net_class_features.layer2.1.conv3.weight\n",
      "✅ 恢復輸出通道: net_label_features.net_class_features.layer2.2.conv1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.2.bn1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.2.bn1.bias\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.2.bn1.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.2.bn1.running_var\n",
      "✅ 恢復輸出通道: net_label_features.net_class_features.layer2.2.conv2.weight\n",
      "✅ 恢復輸入通道: net_label_features.net_class_features.layer2.2.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.2.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.2.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.2.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.2.bn2.running_var\n",
      "✅ 恢復輸入通道: net_label_features.net_class_features.layer2.2.conv3.weight\n",
      "✅ 恢復輸出通道: net_label_features.net_class_features.layer2.3.conv1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.3.bn1.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.3.bn1.bias\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.3.bn1.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.3.bn1.running_var\n",
      "✅ 恢復輸出通道: net_label_features.net_class_features.layer2.3.conv2.weight\n",
      "✅ 恢復輸入通道: net_label_features.net_class_features.layer2.3.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.3.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.3.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.3.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer2.3.bn2.running_var\n",
      "✅ 恢復輸入通道: net_label_features.net_class_features.layer2.3.conv3.weight\n",
      "✅ 恢復輸出通道: net_label_features.net_class_features.layer3.0.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.0.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.0.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.0.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.0.bn2.running_var\n",
      "✅ 恢復輸入通道: net_label_features.net_class_features.layer3.0.conv3.weight\n",
      "✅ 恢復輸出通道: net_label_features.net_class_features.layer3.1.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.1.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.1.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.1.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.1.bn2.running_var\n",
      "✅ 恢復輸入通道: net_label_features.net_class_features.layer3.1.conv3.weight\n",
      "✅ 恢復輸出通道: net_label_features.net_class_features.layer3.2.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.2.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.2.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.2.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.2.bn2.running_var\n",
      "✅ 恢復輸入通道: net_label_features.net_class_features.layer3.2.conv3.weight\n",
      "✅ 恢復輸出通道: net_label_features.net_class_features.layer3.3.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.3.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.3.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.3.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.3.bn2.running_var\n",
      "✅ 恢復輸入通道: net_label_features.net_class_features.layer3.3.conv3.weight\n",
      "✅ 恢復輸出通道: net_label_features.net_class_features.layer3.4.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.4.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.4.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.4.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.4.bn2.running_var\n",
      "✅ 恢復輸入通道: net_label_features.net_class_features.layer3.4.conv3.weight\n",
      "✅ 恢復輸出通道: net_label_features.net_class_features.layer3.5.conv2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.5.bn2.weight\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.5.bn2.bias\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.5.bn2.running_mean\n",
      "✅ 恢復 BatchNorm 參數: net_label_features.net_class_features.layer3.5.bn2.running_var\n",
      "✅ 恢復輸入通道: net_label_features.net_class_features.layer3.5.conv3.weight\n",
      "2025-07-18 17:22:45,194 OS2D INFO: Successfully loaded restored pruned network state\n",
      "2025-07-18 17:22:45,199 OS2D INFO: OS2D has 139 blocks of 10169478 parameters (before freezing)\n",
      "2025-07-18 17:22:45,200 OS2D INFO: OS2D has 139 blocks of 10169478 trainable parameters\n",
      "2025-07-18 17:22:45,202 OS2D.dataset INFO: Preparing the GroZi-3.2k dataset: version grozi-train, eval scale 1280.0, image caching True\n",
      "2025-07-18 17:22:47,583 OS2D.dataset INFO: Read 878 GT images\n",
      "2025-07-18 17:23:37,412 OS2D.dataset INFO: Read 596 data images\n",
      "2025-07-18 17:23:38,056 OS2D.dataset INFO: Loaded dataset grozi-train with 596 images, 7781 boxes, 878 classes\n",
      "2025-07-18 17:23:38,189 OS2D.eval.dataset INFO: Preparing the GroZi-3.2k dataset: version grozi-val-new-cl, eval scale 1280, image caching False\n",
      "2025-07-18 17:23:41,918 OS2D.eval.dataset INFO: Read 185 GT images\n",
      "2025-07-18 17:23:47,837 OS2D.eval.dataset INFO: Found 84 data images\n",
      "2025-07-18 17:23:47,844 OS2D.eval.dataset INFO: Loaded dataset grozi-val-new-cl with 84 images, 622 boxes, 185 classes\n",
      "2025-07-18 17:23:47,845 OS2D.eval.dataset INFO: Preparing the GroZi-3.2k dataset: version grozi-val-old-cl, eval scale 1280, image caching False\n",
      "2025-07-18 17:23:48,360 OS2D.eval.dataset INFO: Read 158 GT images\n",
      "2025-07-18 17:23:54,015 OS2D.eval.dataset INFO: Found 84 data images\n",
      "2025-07-18 17:23:54,019 OS2D.eval.dataset INFO: Loaded dataset grozi-val-old-cl with 84 images, 518 boxes, 158 classes\n",
      "[LCP] 初始化完成，共 43 層的 channel 索引\n"
     ]
    }
   ],
   "source": [
    "if cfg.is_cuda:\n",
    "    assert torch.cuda.is_available(), \"Do not have available GPU, but cfg.is_cuda == 1\"\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# random seed\n",
    "set_random_seed(cfg.random_seed, cfg.is_cuda)\n",
    "\n",
    "# Model\n",
    "cfg.defrost()\n",
    "cfg.init.model = './src/util/checkpoints-test/checkpoint_lcp_finetune_26_layer3.5.conv2.pth'\n",
    "cfg.freeze()\n",
    "\n",
    "# net = torch.load( cfg.init.model, map_location=torch.device('cuda') )\n",
    "net, box_coder, criterion, img_normalization, optimizer_state = build_os2d_from_config(cfg)\n",
    "\n",
    "# Optimizer\n",
    "parameters = get_trainable_parameters(net)\n",
    "optimizer = create_optimizer(parameters, cfg.train.optim, optimizer_state)\n",
    "\n",
    "# load the dataset\n",
    "data_path = get_data_path()\n",
    "dataloader_train, datasets_train_for_eval = build_train_dataloader_from_config(cfg, box_coder, img_normalization,\n",
    "                                                                                data_path=data_path)\n",
    "\n",
    "dataloaders_eval = build_eval_dataloaders_from_cfg(cfg, box_coder, img_normalization,\n",
    "                                                    datasets_for_eval=datasets_train_for_eval,\n",
    "                                                    data_path=data_path)\n",
    "\n",
    "db = DataLoaderDB( path = './src/db/data.csv' , dataloader = dataloader_train)\n",
    "\n",
    "from src.lcp.ct_aoi_align import ContextAoiAlign\n",
    "transform_image = transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize(img_normalization[\"mean\"], img_normalization[\"std\"])\n",
    "                      ])\n",
    "\n",
    "context_aoi_align = ContextAoiAlign( db, dataloader_train, transform_image , net , cfg )\n",
    "\n",
    "from src.lcp.aux_net import AuxiliaryNetwork\n",
    "aux_net = AuxiliaryNetwork( context_aoi_align, db )\n",
    "\n",
    "from src.util.prune_db import PruneDBControler\n",
    "prune_db = PruneDBControler( path = './src/db/prune_channel_information.csv' )\n",
    "\n",
    "from src.lcp.lcp import LCP\n",
    "lcp = LCP(net, aux_net , dataloader_train)\n",
    "lcp.init_for_indices()\n",
    "lcp.set_prune_db( prune_db )\n",
    "\n",
    "from src.lcp.pruner import Pruner\n",
    "pruner = Pruner( lcp._prune_net )\n",
    "pruner.set_prune_db( prune_db )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac71fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.lcp.recontruction import LCPReconstruction\n",
    "# lcp_reconstruction = LCPReconstruction(\n",
    "#     prune_db = prune_db,\n",
    "#     pruner = pruner,\n",
    "#     prune_net = lcp._prune_net\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e31f118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = prune_db.get_all_layers()\n",
    "pruned_layers = []\n",
    "for layer in layers:\n",
    "    if layer not in pruned_layers and layer.startswith('layer'):\n",
    "        pruned_layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b997b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['layer1.0.conv1', 'layer1.0.conv2', 'layer1.1.conv1', 'layer1.1.conv2', 'layer1.2.conv1', 'layer1.2.conv2', 'layer2.0.conv1', 'layer2.0.conv2', 'layer2.1.conv1', 'layer2.1.conv2', 'layer2.2.conv1', 'layer2.2.conv2', 'layer2.3.conv1', 'layer2.3.conv2', 'layer3.0.conv2', 'layer3.1.conv2', 'layer3.2.conv2', 'layer3.3.conv2', 'layer3.4.conv2', 'layer3.5.conv2']\n"
     ]
    }
   ],
   "source": [
    "print( pruned_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36f3e25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.0.conv1: 64 channels\n",
      "[LCP] 開始基於數學推導的無梯度通道重要性計算 - net_feature_maps.layer1.0.conv1\n",
      "[322, 372, 298]\n",
      "[LOG] 原始網路特徵提取完成\n",
      "[LOG] 剪枝網路特徵提取完成\n",
      "322 {'channels': [{'l1_norm': 3.1238338947296143, 'variance': 0.19176186621189117, 'mean_deviation': 2.702387809753418, 'energy': 9.95009708404541, 'sparsity': 0.0, 'importance': 1.5046344995498657}, {'l1_norm': 2.974565267562866, 'variance': 0.38810089230537415, 'mean_deviation': 2.55311918258667, 'energy': 9.236136436462402, 'sparsity': 0.0, 'importance': 1.4393484592437744}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 3.0585670471191406, 'variance': 10.141693115234375, 'mean_deviation': 1.9314370155334473, 'energy': 15.677680015563965, 'sparsity': 0.0, 'importance': 2.345611810684204}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 3.5477263927459717, 'variance': 0.3555949032306671, 'mean_deviation': 3.1262803077697754, 'energy': 12.941953659057617, 'sparsity': 0.0, 'importance': 1.785443663597107}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 6.285487651824951, 'variance': 1.0393273830413818, 'mean_deviation': 6.706933975219727, 'energy': 40.54667282104492, 'sparsity': 0.0, 'importance': 4.08143424987793}, {'l1_norm': 3.2803361415863037, 'variance': 0.5792497992515564, 'mean_deviation': 2.8588900566101074, 'energy': 11.339849472045898, 'sparsity': 0.0, 'importance': 1.6440306901931763}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 3.9363067150115967, 'variance': 1.1249603033065796, 'mean_deviation': 3.5148606300354004, 'energy': 16.619464874267578, 'sparsity': 0.0, 'importance': 2.130061149597168}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 3.408867835998535, 'variance': 0.6539008021354675, 'mean_deviation': 2.987421751022339, 'energy': 12.27427864074707, 'sparsity': 0.0, 'importance': 1.7321758270263672}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 2.8917973041534424, 'variance': 1.628307819366455, 'mean_deviation': 2.470351219177246, 'energy': 9.990789413452148, 'sparsity': 0.0, 'importance': 1.5348553657531738}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 3.8102331161499023, 'variance': 0.356935054063797, 'mean_deviation': 3.388787031173706, 'energy': 14.874807357788086, 'sparsity': 0.0, 'importance': 1.9566961526870728}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 4.000450134277344, 'variance': 4.897566795349121, 'mean_deviation': 3.425633430480957, 'energy': 19.697551727294922, 'sparsity': 0.0, 'importance': 2.532487392425537}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4214460849761963, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04843650385737419}, {'l1_norm': 3.946230173110962, 'variance': 1.324885606765747, 'mean_deviation': 3.5247840881347656, 'energy': 16.89760971069336, 'sparsity': 0.0, 'importance': 2.15989351272583}, {'l1_norm': 3.861823081970215, 'variance': 0.21790796518325806, 'mean_deviation': 4.283268928527832, 'energy': 15.131585121154785, 'sparsity': 0.0, 'importance': 2.0719292163848877}], 'global_mean': -0.4214460849761963, 'global_std': 1.7402002811431885}\n",
      "[LOG] 原始網路特徵提取完成\n",
      "[LOG] 剪枝網路特徵提取完成\n",
      "372 {'channels': [{'l1_norm': 3.2140424251556396, 'variance': 0.6584641933441162, 'mean_deviation': 2.7791738510131836, 'energy': 10.988529205322266, 'sparsity': 0.0, 'importance': 1.5102506875991821}, {'l1_norm': 3.337226629257202, 'variance': 2.683717966079712, 'mean_deviation': 2.902358055114746, 'energy': 13.820779800415039, 'sparsity': 0.0, 'importance': 1.7911897897720337}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 3.759758472442627, 'variance': 12.47498893737793, 'mean_deviation': 2.5675718784332275, 'energy': 21.48954963684082, 'sparsity': 0.0, 'importance': 2.7502236366271973}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 3.764982223510742, 'variance': 1.2651292085647583, 'mean_deviation': 3.330113649368286, 'energy': 15.440213203430176, 'sparsity': 0.0, 'importance': 1.8957867622375488}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 6.538462162017822, 'variance': 2.6207802295684814, 'mean_deviation': 6.973330497741699, 'energy': 45.37225341796875, 'sparsity': 0.0, 'importance': 4.1665825843811035}, {'l1_norm': 3.3756513595581055, 'variance': 0.8485888838768005, 'mean_deviation': 2.9407827854156494, 'energy': 12.243606567382812, 'sparsity': 0.0, 'importance': 1.6217979192733765}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 4.090221881866455, 'variance': 2.359408140182495, 'mean_deviation': 3.655353307723999, 'energy': 19.089309692382812, 'sparsity': 0.0, 'importance': 2.2129034996032715}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 3.310802936553955, 'variance': 0.7928919196128845, 'mean_deviation': 2.875934362411499, 'energy': 11.754302978515625, 'sparsity': 0.0, 'importance': 1.5789051055908203}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 2.9467270374298096, 'variance': 2.100537061691284, 'mean_deviation': 2.5118584632873535, 'energy': 10.783721923828125, 'sparsity': 0.0, 'importance': 1.5140818357467651}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 3.764049530029297, 'variance': 0.49145635962486267, 'mean_deviation': 3.329180955886841, 'energy': 14.659524917602539, 'sparsity': 0.0, 'importance': 1.8145215511322021}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 3.6229465007781982, 'variance': 6.104028224945068, 'mean_deviation': 3.0537407398223877, 'energy': 18.274377822875977, 'sparsity': 0.0, 'importance': 2.2574515342712402}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4348685145378113, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04747926816344261}, {'l1_norm': 3.9657576084136963, 'variance': 1.6594294309616089, 'mean_deviation': 3.5308890342712402, 'energy': 17.386653900146484, 'sparsity': 0.0, 'importance': 2.061099052429199}, {'l1_norm': 3.8904666900634766, 'variance': 0.4217965304851532, 'mean_deviation': 4.3253350257873535, 'energy': 15.557523727416992, 'sparsity': 0.0, 'importance': 1.9799760580062866}], 'global_mean': -0.4348685145378113, 'global_std': 1.8318248987197876}\n",
      "[LOG] 原始網路特徵提取完成\n",
      "[LOG] 剪枝網路特徵提取完成\n",
      "298 {'channels': [{'l1_norm': 3.0430586338043213, 'variance': 0.24856451153755188, 'mean_deviation': 2.611539125442505, 'energy': 9.508769035339355, 'sparsity': 0.0, 'importance': 1.3967266082763672}, {'l1_norm': 3.182961940765381, 'variance': 1.4630507230758667, 'mean_deviation': 2.7514424324035645, 'energy': 11.59428882598877, 'sparsity': 0.0, 'importance': 1.6057270765304565}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 3.5717740058898926, 'variance': 12.589010238647461, 'mean_deviation': 2.555115222930908, 'energy': 21.508907318115234, 'sparsity': 0.0, 'importance': 2.7860682010650635}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 3.812237501144409, 'variance': 1.4246745109558105, 'mean_deviation': 3.3807179927825928, 'energy': 15.957818031311035, 'sparsity': 0.0, 'importance': 1.978094458580017}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 6.406459331512451, 'variance': 1.934605598449707, 'mean_deviation': 6.837978839874268, 'energy': 42.9773063659668, 'sparsity': 0.0, 'importance': 4.064748764038086}, {'l1_norm': 3.3935868740081787, 'variance': 0.8965519666671753, 'mean_deviation': 2.9620673656463623, 'energy': 12.41297435760498, 'sparsity': 0.0, 'importance': 1.6669338941574097}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 3.7945003509521484, 'variance': 0.6915111541748047, 'mean_deviation': 3.362980842590332, 'energy': 15.089738845825195, 'sparsity': 0.0, 'importance': 1.8883576393127441}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 3.268498420715332, 'variance': 0.6921235918998718, 'mean_deviation': 2.8369789123535156, 'energy': 11.375200271606445, 'sparsity': 0.0, 'importance': 1.5720878839492798}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 2.995819091796875, 'variance': 2.4400172233581543, 'mean_deviation': 2.5642995834350586, 'energy': 11.414931297302246, 'sparsity': 0.0, 'importance': 1.6055582761764526}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 3.8056812286376953, 'variance': 0.541481614112854, 'mean_deviation': 3.374161720275879, 'energy': 15.024687767028809, 'sparsity': 0.0, 'importance': 1.8792682886123657}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 3.664893865585327, 'variance': 6.051692008972168, 'mean_deviation': 3.020246744155884, 'energy': 17.966341018676758, 'sparsity': 0.0, 'importance': 2.289585828781128}, {'l1_norm': 0.0, 'variance': 0.0, 'mean_deviation': 0.4315195381641388, 'energy': 0.0, 'sparsity': 1.0, 'importance': 0.04777286946773529}, {'l1_norm': 4.189309597015381, 'variance': 2.781007766723633, 'mean_deviation': 3.7577900886535645, 'energy': 20.331300735473633, 'sparsity': 0.0, 'importance': 2.3665871620178223}, {'l1_norm': 3.9003446102142334, 'variance': 0.4134635329246521, 'mean_deviation': 4.331864356994629, 'energy': 15.626148223876953, 'sparsity': 0.0, 'importance': 2.02081298828125}], 'global_mean': -0.4315195381641388, 'global_std': 1.8065464496612549}\n",
      "[LCP] 基於數學推導的無梯度計算完成\n",
      "layer layer1.0.conv1 , 預計保留通道數量: 32/64, 預計捨棄通道數量: 32/64\n"
     ]
    }
   ],
   "source": [
    "layers = lcp.get_layers_name()\n",
    "\n",
    "for name, ch in layers:\n",
    "    if name == 'layer1.0.conv1':\n",
    "        pass\n",
    "    else:\n",
    "        continue\n",
    "    print(f\"{name}: {ch} channels\")\n",
    "    keep, discard = lcp.get_channel_selection_by_no_grad(\n",
    "        layer_name   = f\"net_feature_maps.{name}\",\n",
    "        discard_rate = 0.5,\n",
    "        lambda_rate  = 1.0,\n",
    "        use_image_num= 3,\n",
    "        random_seed  = 42\n",
    "    )\n",
    "    print(f\"layer {name} , 預計保留通道數量: {len(keep)}/{ch}, 預計捨棄通道數量: {len(discard)}/{ch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55f7c146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PRUNE] 開始剪枝層級: layer1.0.conv1\n",
      "=== net_feature_maps 詳細層級資訊 ===\n",
      "[LCP] 層級依賴分析完成 - layer1.0.conv1\n",
      "      BatchNorm: net_feature_maps.layer1.0.bn1\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[PRUNE] 開始剪枝輸出通道: layer1.0.conv1\n",
      "[PRUNE] 保留通道索引: [0, 1, 4, 7, 13, 14, 24, 29, 44, 54, 60, 62, 63]\n",
      "[PRUNE] 保留通道數量: 13\n",
      "[PRUNE] 原始輸出通道數: 64\n",
      "[PRUNE] Conv2d 權重: torch.Size([64, 64, 1, 1]) -> torch.Size([13, 64, 1, 1])\n",
      "[PRUNE] 更新 out_channels: 13\n",
      "[PRUNE] 輸出通道剪枝完成: 64 -> 13\n",
      "[PRUNE] 開始剪枝 BatchNorm 層: net_feature_maps.layer1.0.bn1\n",
      "[PRUNE] BatchNorm 通道數變化: 64 -> 13\n",
      "[PRUNE] BatchNorm weight 剪枝完成: torch.Size([13])\n",
      "[PRUNE] BatchNorm bias 剪枝完成: torch.Size([13])\n",
      "[PRUNE] BatchNorm running_mean 剪枝完成: torch.Size([13])\n",
      "[PRUNE] BatchNorm running_var 剪枝完成: torch.Size([13])\n",
      "[VALIDATE] BatchNorm 層 net_feature_maps.layer1.0.bn1 剪枝驗證通過\n",
      "[PRUNE] BatchNorm 層 net_feature_maps.layer1.0.bn1 剪枝成功\n",
      "[PRUNE] 修補 net_feature_maps.layer1.0.conv2 的輸入通道 (來源 layer1.0.conv1)\n",
      "[PRUNE] Conv 輸入維度: torch.Size([64, 64, 3, 3]) → torch.Size([64, 13, 3, 3])\n",
      "[0, 1, 4, 7, 13, 14, 24, 29, 44, 54, 60, 62, 63]\n",
      "<class 'list'>\n",
      "[0, 1, 4, 7, 13, 14, 24, 29, 44, 54, 60, 62, 63]\n",
      "[INFO] 覆蓋現有層級數據: layer1.0.conv1\n",
      "[TRACK] layer1.0.conv1 剪枝率 0.0%\n",
      "[PRUNE] 完成剪枝層級: layer1.0.conv1\n",
      "[PRUNE] 開始剪枝層級: layer1.0.conv2\n",
      "=== net_feature_maps 詳細層級資訊 ===\n",
      "[LCP] 層級依賴分析完成 - layer1.0.conv2\n",
      "      BatchNorm: net_feature_maps.layer1.0.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[PRUNE] 開始剪枝輸出通道: layer1.0.conv2\n",
      "[PRUNE] 保留通道索引: [3, 11, 13, 14, 15, 20, 25, 32, 40, 51, 53, 54, 55]\n",
      "[PRUNE] 保留通道數量: 13\n",
      "[PRUNE] 原始輸出通道數: 64\n",
      "[PRUNE] Conv2d 權重: torch.Size([64, 13, 3, 3]) -> torch.Size([13, 13, 3, 3])\n",
      "[PRUNE] 更新 out_channels: 13\n",
      "[PRUNE] 輸出通道剪枝完成: 64 -> 13\n",
      "[PRUNE] 開始剪枝 BatchNorm 層: net_feature_maps.layer1.0.bn2\n",
      "[PRUNE] BatchNorm 通道數變化: 64 -> 13\n",
      "[PRUNE] BatchNorm weight 剪枝完成: torch.Size([13])\n",
      "[PRUNE] BatchNorm bias 剪枝完成: torch.Size([13])\n",
      "[PRUNE] BatchNorm running_mean 剪枝完成: torch.Size([13])\n",
      "[PRUNE] BatchNorm running_var 剪枝完成: torch.Size([13])\n",
      "[VALIDATE] BatchNorm 層 net_feature_maps.layer1.0.bn2 剪枝驗證通過\n",
      "[PRUNE] BatchNorm 層 net_feature_maps.layer1.0.bn2 剪枝成功\n",
      "[PRUNE] 修補 net_feature_maps.layer1.0.conv3 的輸入通道 (來源 layer1.0.conv2)\n",
      "[PRUNE] Conv 輸入維度: torch.Size([256, 64, 1, 1]) → torch.Size([256, 13, 1, 1])\n",
      "[3, 11, 13, 14, 15, 20, 25, 32, 40, 51, 53, 54, 55]\n",
      "<class 'list'>\n",
      "[3, 11, 13, 14, 15, 20, 25, 32, 40, 51, 53, 54, 55]\n",
      "[INFO] 覆蓋現有層級數據: layer1.0.conv2\n",
      "[TRACK] layer1.0.conv2 剪枝率 0.0%\n",
      "[PRUNE] 完成剪枝層級: layer1.0.conv2\n",
      "[PRUNE] 開始剪枝層級: layer1.1.conv1\n",
      "=== net_feature_maps 詳細層級資訊 ===\n",
      "[LCP] 層級依賴分析完成 - layer1.1.conv1\n",
      "      BatchNorm: net_feature_maps.layer1.1.bn1\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[PRUNE] 開始剪枝輸出通道: layer1.1.conv1\n",
      "[PRUNE] 保留通道索引: [6, 7, 8, 11, 13, 15, 16, 17, 21, 26, 27, 38, 45]\n",
      "[PRUNE] 保留通道數量: 13\n",
      "[PRUNE] 原始輸出通道數: 64\n",
      "[PRUNE] Conv2d 權重: torch.Size([64, 256, 1, 1]) -> torch.Size([13, 256, 1, 1])\n",
      "[PRUNE] 更新 out_channels: 13\n",
      "[PRUNE] 輸出通道剪枝完成: 64 -> 13\n",
      "[PRUNE] 開始剪枝 BatchNorm 層: net_feature_maps.layer1.1.bn1\n",
      "[PRUNE] BatchNorm 通道數變化: 64 -> 13\n",
      "[PRUNE] BatchNorm weight 剪枝完成: torch.Size([13])\n",
      "[PRUNE] BatchNorm bias 剪枝完成: torch.Size([13])\n",
      "[PRUNE] BatchNorm running_mean 剪枝完成: torch.Size([13])\n",
      "[PRUNE] BatchNorm running_var 剪枝完成: torch.Size([13])\n",
      "[VALIDATE] BatchNorm 層 net_feature_maps.layer1.1.bn1 剪枝驗證通過\n",
      "[PRUNE] BatchNorm 層 net_feature_maps.layer1.1.bn1 剪枝成功\n",
      "[PRUNE] 修補 net_feature_maps.layer1.1.conv2 的輸入通道 (來源 layer1.1.conv1)\n",
      "[PRUNE] Conv 輸入維度: torch.Size([64, 64, 3, 3]) → torch.Size([64, 13, 3, 3])\n",
      "[6, 7, 8, 11, 13, 15, 16, 17, 21, 26, 27, 38, 45]\n",
      "<class 'list'>\n",
      "[6, 7, 8, 11, 13, 15, 16, 17, 21, 26, 27, 38, 45]\n",
      "[INFO] 覆蓋現有層級數據: layer1.1.conv1\n",
      "[TRACK] layer1.1.conv1 剪枝率 0.0%\n",
      "[PRUNE] 完成剪枝層級: layer1.1.conv1\n",
      "[PRUNE] 開始剪枝層級: layer1.1.conv2\n",
      "=== net_feature_maps 詳細層級資訊 ===\n",
      "[LCP] 層級依賴分析完成 - layer1.1.conv2\n",
      "      BatchNorm: net_feature_maps.layer1.1.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[PRUNE] 開始剪枝輸出通道: layer1.1.conv2\n",
      "[PRUNE] 保留通道索引: [5, 12, 15, 17, 25, 31, 39, 41, 46, 51, 56, 59, 61]\n",
      "[PRUNE] 保留通道數量: 13\n",
      "[PRUNE] 原始輸出通道數: 64\n",
      "[PRUNE] Conv2d 權重: torch.Size([64, 13, 3, 3]) -> torch.Size([13, 13, 3, 3])\n",
      "[PRUNE] 更新 out_channels: 13\n",
      "[PRUNE] 輸出通道剪枝完成: 64 -> 13\n",
      "[PRUNE] 開始剪枝 BatchNorm 層: net_feature_maps.layer1.1.bn2\n",
      "[PRUNE] BatchNorm 通道數變化: 64 -> 13\n",
      "[PRUNE] BatchNorm weight 剪枝完成: torch.Size([13])\n",
      "[PRUNE] BatchNorm bias 剪枝完成: torch.Size([13])\n",
      "[PRUNE] BatchNorm running_mean 剪枝完成: torch.Size([13])\n",
      "[PRUNE] BatchNorm running_var 剪枝完成: torch.Size([13])\n",
      "[VALIDATE] BatchNorm 層 net_feature_maps.layer1.1.bn2 剪枝驗證通過\n",
      "[PRUNE] BatchNorm 層 net_feature_maps.layer1.1.bn2 剪枝成功\n",
      "[PRUNE] 修補 net_feature_maps.layer1.1.conv3 的輸入通道 (來源 layer1.1.conv2)\n",
      "[PRUNE] Conv 輸入維度: torch.Size([256, 64, 1, 1]) → torch.Size([256, 13, 1, 1])\n",
      "[5, 12, 15, 17, 25, 31, 39, 41, 46, 51, 56, 59, 61]\n",
      "<class 'list'>\n",
      "[5, 12, 15, 17, 25, 31, 39, 41, 46, 51, 56, 59, 61]\n",
      "[INFO] 覆蓋現有層級數據: layer1.1.conv2\n",
      "[TRACK] layer1.1.conv2 剪枝率 0.0%\n",
      "[PRUNE] 完成剪枝層級: layer1.1.conv2\n",
      "[PRUNE] 開始剪枝層級: layer1.2.conv1\n",
      "=== net_feature_maps 詳細層級資訊 ===\n",
      "[LCP] 層級依賴分析完成 - layer1.2.conv1\n",
      "      BatchNorm: net_feature_maps.layer1.2.bn1\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[PRUNE] 開始剪枝輸出通道: layer1.2.conv1\n",
      "[PRUNE] 保留通道索引: [0, 4, 16, 25, 31, 37, 43, 48, 51, 53, 58, 60, 62]\n",
      "[PRUNE] 保留通道數量: 13\n",
      "[PRUNE] 原始輸出通道數: 64\n",
      "[PRUNE] Conv2d 權重: torch.Size([64, 256, 1, 1]) -> torch.Size([13, 256, 1, 1])\n",
      "[PRUNE] 更新 out_channels: 13\n",
      "[PRUNE] 輸出通道剪枝完成: 64 -> 13\n",
      "[PRUNE] 開始剪枝 BatchNorm 層: net_feature_maps.layer1.2.bn1\n",
      "[PRUNE] BatchNorm 通道數變化: 64 -> 13\n",
      "[PRUNE] BatchNorm weight 剪枝完成: torch.Size([13])\n",
      "[PRUNE] BatchNorm bias 剪枝完成: torch.Size([13])\n",
      "[PRUNE] BatchNorm running_mean 剪枝完成: torch.Size([13])\n",
      "[PRUNE] BatchNorm running_var 剪枝完成: torch.Size([13])\n",
      "[VALIDATE] BatchNorm 層 net_feature_maps.layer1.2.bn1 剪枝驗證通過\n",
      "[PRUNE] BatchNorm 層 net_feature_maps.layer1.2.bn1 剪枝成功\n",
      "[PRUNE] 修補 net_feature_maps.layer1.2.conv2 的輸入通道 (來源 layer1.2.conv1)\n",
      "[PRUNE] Conv 輸入維度: torch.Size([64, 64, 3, 3]) → torch.Size([64, 13, 3, 3])\n",
      "[0, 4, 16, 25, 31, 37, 43, 48, 51, 53, 58, 60, 62]\n",
      "<class 'list'>\n",
      "[0, 4, 16, 25, 31, 37, 43, 48, 51, 53, 58, 60, 62]\n",
      "[INFO] 覆蓋現有層級數據: layer1.2.conv1\n",
      "[TRACK] layer1.2.conv1 剪枝率 0.0%\n",
      "[PRUNE] 完成剪枝層級: layer1.2.conv1\n",
      "[PRUNE] 開始剪枝層級: layer1.2.conv2\n",
      "=== net_feature_maps 詳細層級資訊 ===\n",
      "[LCP] 層級依賴分析完成 - layer1.2.conv2\n",
      "      BatchNorm: net_feature_maps.layer1.2.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[PRUNE] 開始剪枝輸出通道: layer1.2.conv2\n",
      "[PRUNE] 保留通道索引: [2, 4, 9, 10, 16, 22, 25, 27, 38, 42, 50, 53, 63]\n",
      "[PRUNE] 保留通道數量: 13\n",
      "[PRUNE] 原始輸出通道數: 64\n",
      "[PRUNE] Conv2d 權重: torch.Size([64, 13, 3, 3]) -> torch.Size([13, 13, 3, 3])\n",
      "[PRUNE] 更新 out_channels: 13\n",
      "[PRUNE] 輸出通道剪枝完成: 64 -> 13\n",
      "[PRUNE] 開始剪枝 BatchNorm 層: net_feature_maps.layer1.2.bn2\n",
      "[PRUNE] BatchNorm 通道數變化: 64 -> 13\n",
      "[PRUNE] BatchNorm weight 剪枝完成: torch.Size([13])\n",
      "[PRUNE] BatchNorm bias 剪枝完成: torch.Size([13])\n",
      "[PRUNE] BatchNorm running_mean 剪枝完成: torch.Size([13])\n",
      "[PRUNE] BatchNorm running_var 剪枝完成: torch.Size([13])\n",
      "[VALIDATE] BatchNorm 層 net_feature_maps.layer1.2.bn2 剪枝驗證通過\n",
      "[PRUNE] BatchNorm 層 net_feature_maps.layer1.2.bn2 剪枝成功\n",
      "[PRUNE] 修補 net_feature_maps.layer1.2.conv3 的輸入通道 (來源 layer1.2.conv2)\n",
      "[PRUNE] Conv 輸入維度: torch.Size([256, 64, 1, 1]) → torch.Size([256, 13, 1, 1])\n",
      "[2, 4, 9, 10, 16, 22, 25, 27, 38, 42, 50, 53, 63]\n",
      "<class 'list'>\n",
      "[2, 4, 9, 10, 16, 22, 25, 27, 38, 42, 50, 53, 63]\n",
      "[INFO] 覆蓋現有層級數據: layer1.2.conv2\n",
      "[TRACK] layer1.2.conv2 剪枝率 0.0%\n",
      "[PRUNE] 完成剪枝層級: layer1.2.conv2\n",
      "[PRUNE] 開始剪枝層級: layer2.0.conv1\n",
      "=== net_feature_maps 詳細層級資訊 ===\n",
      "[LCP] 層級依賴分析完成 - layer2.0.conv1\n",
      "      BatchNorm: net_feature_maps.layer2.0.bn1\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[PRUNE] 開始剪枝輸出通道: layer2.0.conv1\n",
      "[PRUNE] 保留通道索引: [5, 8, 10, 14, 15, 19, 21, 26, 28, 32, 40, 53, 57, 62, 65, 70, 76, 80, 90, 94, 96, 102, 109, 115, 121, 125]\n",
      "[PRUNE] 保留通道數量: 26\n",
      "[PRUNE] 原始輸出通道數: 128\n",
      "[PRUNE] Conv2d 權重: torch.Size([128, 256, 1, 1]) -> torch.Size([26, 256, 1, 1])\n",
      "[PRUNE] 更新 out_channels: 26\n",
      "[PRUNE] 輸出通道剪枝完成: 128 -> 26\n",
      "[PRUNE] 開始剪枝 BatchNorm 層: net_feature_maps.layer2.0.bn1\n",
      "[PRUNE] BatchNorm 通道數變化: 128 -> 26\n",
      "[PRUNE] BatchNorm weight 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm bias 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm running_mean 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm running_var 剪枝完成: torch.Size([26])\n",
      "[VALIDATE] BatchNorm 層 net_feature_maps.layer2.0.bn1 剪枝驗證通過\n",
      "[PRUNE] BatchNorm 層 net_feature_maps.layer2.0.bn1 剪枝成功\n",
      "[PRUNE] 修補 net_feature_maps.layer2.0.conv2 的輸入通道 (來源 layer2.0.conv1)\n",
      "[PRUNE] Conv 輸入維度: torch.Size([128, 128, 3, 3]) → torch.Size([128, 26, 3, 3])\n",
      "[5, 8, 10, 14, 15, 19, 21, 26, 28, 32, 40, 53, 57, 62, 65, 70, 76, 80, 90, 94, 96, 102, 109, 115, 121, 125]\n",
      "<class 'list'>\n",
      "[5, 8, 10, 14, 15, 19, 21, 26, 28, 32, 40, 53, 57, 62, 65, 70, 76, 80, 90, 94, 96, 102, 109, 115, 121, 125]\n",
      "[INFO] 覆蓋現有層級數據: layer2.0.conv1\n",
      "[TRACK] layer2.0.conv1 剪枝率 0.0%\n",
      "[PRUNE] 完成剪枝層級: layer2.0.conv1\n",
      "[PRUNE] 開始剪枝層級: layer2.0.conv2\n",
      "=== net_feature_maps 詳細層級資訊 ===\n",
      "[LCP] 層級依賴分析完成 - layer2.0.conv2\n",
      "      BatchNorm: net_feature_maps.layer2.0.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[PRUNE] 開始剪枝輸出通道: layer2.0.conv2\n",
      "[PRUNE] 保留通道索引: [2, 3, 4, 9, 19, 20, 29, 35, 36, 37, 39, 44, 57, 63, 65, 67, 69, 73, 85, 86, 94, 102, 104, 105, 113, 123]\n",
      "[PRUNE] 保留通道數量: 26\n",
      "[PRUNE] 原始輸出通道數: 128\n",
      "[PRUNE] Conv2d 權重: torch.Size([128, 26, 3, 3]) -> torch.Size([26, 26, 3, 3])\n",
      "[PRUNE] 更新 out_channels: 26\n",
      "[PRUNE] 輸出通道剪枝完成: 128 -> 26\n",
      "[PRUNE] 開始剪枝 BatchNorm 層: net_feature_maps.layer2.0.bn2\n",
      "[PRUNE] BatchNorm 通道數變化: 128 -> 26\n",
      "[PRUNE] BatchNorm weight 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm bias 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm running_mean 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm running_var 剪枝完成: torch.Size([26])\n",
      "[VALIDATE] BatchNorm 層 net_feature_maps.layer2.0.bn2 剪枝驗證通過\n",
      "[PRUNE] BatchNorm 層 net_feature_maps.layer2.0.bn2 剪枝成功\n",
      "[PRUNE] 修補 net_feature_maps.layer2.0.conv3 的輸入通道 (來源 layer2.0.conv2)\n",
      "[PRUNE] Conv 輸入維度: torch.Size([512, 128, 1, 1]) → torch.Size([512, 26, 1, 1])\n",
      "[2, 3, 4, 9, 19, 20, 29, 35, 36, 37, 39, 44, 57, 63, 65, 67, 69, 73, 85, 86, 94, 102, 104, 105, 113, 123]\n",
      "<class 'list'>\n",
      "[2, 3, 4, 9, 19, 20, 29, 35, 36, 37, 39, 44, 57, 63, 65, 67, 69, 73, 85, 86, 94, 102, 104, 105, 113, 123]\n",
      "[INFO] 覆蓋現有層級數據: layer2.0.conv2\n",
      "[TRACK] layer2.0.conv2 剪枝率 0.0%\n",
      "[PRUNE] 完成剪枝層級: layer2.0.conv2\n",
      "[PRUNE] 開始剪枝層級: layer2.1.conv1\n",
      "=== net_feature_maps 詳細層級資訊 ===\n",
      "[LCP] 層級依賴分析完成 - layer2.1.conv1\n",
      "      BatchNorm: net_feature_maps.layer2.1.bn1\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[PRUNE] 開始剪枝輸出通道: layer2.1.conv1\n",
      "[PRUNE] 保留通道索引: [1, 6, 7, 12, 14, 36, 37, 51, 59, 62, 66, 69, 71, 72, 73, 78, 80, 83, 92, 100, 102, 109, 113, 115, 117, 121]\n",
      "[PRUNE] 保留通道數量: 26\n",
      "[PRUNE] 原始輸出通道數: 128\n",
      "[PRUNE] Conv2d 權重: torch.Size([128, 512, 1, 1]) -> torch.Size([26, 512, 1, 1])\n",
      "[PRUNE] 更新 out_channels: 26\n",
      "[PRUNE] 輸出通道剪枝完成: 128 -> 26\n",
      "[PRUNE] 開始剪枝 BatchNorm 層: net_feature_maps.layer2.1.bn1\n",
      "[PRUNE] BatchNorm 通道數變化: 128 -> 26\n",
      "[PRUNE] BatchNorm weight 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm bias 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm running_mean 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm running_var 剪枝完成: torch.Size([26])\n",
      "[VALIDATE] BatchNorm 層 net_feature_maps.layer2.1.bn1 剪枝驗證通過\n",
      "[PRUNE] BatchNorm 層 net_feature_maps.layer2.1.bn1 剪枝成功\n",
      "[PRUNE] 修補 net_feature_maps.layer2.1.conv2 的輸入通道 (來源 layer2.1.conv1)\n",
      "[PRUNE] Conv 輸入維度: torch.Size([128, 128, 3, 3]) → torch.Size([128, 26, 3, 3])\n",
      "[1, 6, 7, 12, 14, 36, 37, 51, 59, 62, 66, 69, 71, 72, 73, 78, 80, 83, 92, 100, 102, 109, 113, 115, 117, 121]\n",
      "<class 'list'>\n",
      "[1, 6, 7, 12, 14, 36, 37, 51, 59, 62, 66, 69, 71, 72, 73, 78, 80, 83, 92, 100, 102, 109, 113, 115, 117, 121]\n",
      "[INFO] 覆蓋現有層級數據: layer2.1.conv1\n",
      "[TRACK] layer2.1.conv1 剪枝率 0.0%\n",
      "[PRUNE] 完成剪枝層級: layer2.1.conv1\n",
      "[PRUNE] 開始剪枝層級: layer2.1.conv2\n",
      "=== net_feature_maps 詳細層級資訊 ===\n",
      "[LCP] 層級依賴分析完成 - layer2.1.conv2\n",
      "      BatchNorm: net_feature_maps.layer2.1.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[PRUNE] 開始剪枝輸出通道: layer2.1.conv2\n",
      "[PRUNE] 保留通道索引: [10, 18, 22, 27, 31, 42, 45, 47, 52, 54, 55, 59, 65, 66, 70, 73, 75, 79, 82, 91, 101, 112, 115, 120, 125, 127]\n",
      "[PRUNE] 保留通道數量: 26\n",
      "[PRUNE] 原始輸出通道數: 128\n",
      "[PRUNE] Conv2d 權重: torch.Size([128, 26, 3, 3]) -> torch.Size([26, 26, 3, 3])\n",
      "[PRUNE] 更新 out_channels: 26\n",
      "[PRUNE] 輸出通道剪枝完成: 128 -> 26\n",
      "[PRUNE] 開始剪枝 BatchNorm 層: net_feature_maps.layer2.1.bn2\n",
      "[PRUNE] BatchNorm 通道數變化: 128 -> 26\n",
      "[PRUNE] BatchNorm weight 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm bias 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm running_mean 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm running_var 剪枝完成: torch.Size([26])\n",
      "[VALIDATE] BatchNorm 層 net_feature_maps.layer2.1.bn2 剪枝驗證通過\n",
      "[PRUNE] BatchNorm 層 net_feature_maps.layer2.1.bn2 剪枝成功\n",
      "[PRUNE] 修補 net_feature_maps.layer2.1.conv3 的輸入通道 (來源 layer2.1.conv2)\n",
      "[PRUNE] Conv 輸入維度: torch.Size([512, 128, 1, 1]) → torch.Size([512, 26, 1, 1])\n",
      "[10, 18, 22, 27, 31, 42, 45, 47, 52, 54, 55, 59, 65, 66, 70, 73, 75, 79, 82, 91, 101, 112, 115, 120, 125, 127]\n",
      "<class 'list'>\n",
      "[10, 18, 22, 27, 31, 42, 45, 47, 52, 54, 55, 59, 65, 66, 70, 73, 75, 79, 82, 91, 101, 112, 115, 120, 125, 127]\n",
      "[INFO] 覆蓋現有層級數據: layer2.1.conv2\n",
      "[TRACK] layer2.1.conv2 剪枝率 0.0%\n",
      "[PRUNE] 完成剪枝層級: layer2.1.conv2\n",
      "[PRUNE] 開始剪枝層級: layer2.2.conv1\n",
      "=== net_feature_maps 詳細層級資訊 ===\n",
      "[LCP] 層級依賴分析完成 - layer2.2.conv1\n",
      "      BatchNorm: net_feature_maps.layer2.2.bn1\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[PRUNE] 開始剪枝輸出通道: layer2.2.conv1\n",
      "[PRUNE] 保留通道索引: [1, 6, 11, 14, 23, 24, 30, 32, 34, 41, 44, 55, 61, 62, 63, 68, 70, 80, 81, 83, 90, 95, 98, 101, 110, 127]\n",
      "[PRUNE] 保留通道數量: 26\n",
      "[PRUNE] 原始輸出通道數: 128\n",
      "[PRUNE] Conv2d 權重: torch.Size([128, 512, 1, 1]) -> torch.Size([26, 512, 1, 1])\n",
      "[PRUNE] 更新 out_channels: 26\n",
      "[PRUNE] 輸出通道剪枝完成: 128 -> 26\n",
      "[PRUNE] 開始剪枝 BatchNorm 層: net_feature_maps.layer2.2.bn1\n",
      "[PRUNE] BatchNorm 通道數變化: 128 -> 26\n",
      "[PRUNE] BatchNorm weight 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm bias 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm running_mean 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm running_var 剪枝完成: torch.Size([26])\n",
      "[VALIDATE] BatchNorm 層 net_feature_maps.layer2.2.bn1 剪枝驗證通過\n",
      "[PRUNE] BatchNorm 層 net_feature_maps.layer2.2.bn1 剪枝成功\n",
      "[PRUNE] 修補 net_feature_maps.layer2.2.conv2 的輸入通道 (來源 layer2.2.conv1)\n",
      "[PRUNE] Conv 輸入維度: torch.Size([128, 128, 3, 3]) → torch.Size([128, 26, 3, 3])\n",
      "[1, 6, 11, 14, 23, 24, 30, 32, 34, 41, 44, 55, 61, 62, 63, 68, 70, 80, 81, 83, 90, 95, 98, 101, 110, 127]\n",
      "<class 'list'>\n",
      "[1, 6, 11, 14, 23, 24, 30, 32, 34, 41, 44, 55, 61, 62, 63, 68, 70, 80, 81, 83, 90, 95, 98, 101, 110, 127]\n",
      "[INFO] 覆蓋現有層級數據: layer2.2.conv1\n",
      "[TRACK] layer2.2.conv1 剪枝率 0.0%\n",
      "[PRUNE] 完成剪枝層級: layer2.2.conv1\n",
      "[PRUNE] 開始剪枝層級: layer2.2.conv2\n",
      "=== net_feature_maps 詳細層級資訊 ===\n",
      "[LCP] 層級依賴分析完成 - layer2.2.conv2\n",
      "      BatchNorm: net_feature_maps.layer2.2.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[PRUNE] 開始剪枝輸出通道: layer2.2.conv2\n",
      "[PRUNE] 保留通道索引: [1, 2, 5, 6, 21, 24, 44, 50, 54, 59, 65, 68, 74, 80, 81, 91, 93, 95, 98, 102, 111, 113, 116, 120, 121, 124]\n",
      "[PRUNE] 保留通道數量: 26\n",
      "[PRUNE] 原始輸出通道數: 128\n",
      "[PRUNE] Conv2d 權重: torch.Size([128, 26, 3, 3]) -> torch.Size([26, 26, 3, 3])\n",
      "[PRUNE] 更新 out_channels: 26\n",
      "[PRUNE] 輸出通道剪枝完成: 128 -> 26\n",
      "[PRUNE] 開始剪枝 BatchNorm 層: net_feature_maps.layer2.2.bn2\n",
      "[PRUNE] BatchNorm 通道數變化: 128 -> 26\n",
      "[PRUNE] BatchNorm weight 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm bias 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm running_mean 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm running_var 剪枝完成: torch.Size([26])\n",
      "[VALIDATE] BatchNorm 層 net_feature_maps.layer2.2.bn2 剪枝驗證通過\n",
      "[PRUNE] BatchNorm 層 net_feature_maps.layer2.2.bn2 剪枝成功\n",
      "[PRUNE] 修補 net_feature_maps.layer2.2.conv3 的輸入通道 (來源 layer2.2.conv2)\n",
      "[PRUNE] Conv 輸入維度: torch.Size([512, 128, 1, 1]) → torch.Size([512, 26, 1, 1])\n",
      "[1, 2, 5, 6, 21, 24, 44, 50, 54, 59, 65, 68, 74, 80, 81, 91, 93, 95, 98, 102, 111, 113, 116, 120, 121, 124]\n",
      "<class 'list'>\n",
      "[1, 2, 5, 6, 21, 24, 44, 50, 54, 59, 65, 68, 74, 80, 81, 91, 93, 95, 98, 102, 111, 113, 116, 120, 121, 124]\n",
      "[INFO] 覆蓋現有層級數據: layer2.2.conv2\n",
      "[TRACK] layer2.2.conv2 剪枝率 0.0%\n",
      "[PRUNE] 完成剪枝層級: layer2.2.conv2\n",
      "[PRUNE] 開始剪枝層級: layer2.3.conv1\n",
      "=== net_feature_maps 詳細層級資訊 ===\n",
      "[LCP] 層級依賴分析完成 - layer2.3.conv1\n",
      "      BatchNorm: net_feature_maps.layer2.3.bn1\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[PRUNE] 開始剪枝輸出通道: layer2.3.conv1\n",
      "[PRUNE] 保留通道索引: [2, 4, 8, 20, 22, 24, 26, 28, 39, 48, 50, 51, 58, 64, 71, 77, 80, 81, 93, 97, 107, 109, 110, 116, 117, 121]\n",
      "[PRUNE] 保留通道數量: 26\n",
      "[PRUNE] 原始輸出通道數: 128\n",
      "[PRUNE] Conv2d 權重: torch.Size([128, 512, 1, 1]) -> torch.Size([26, 512, 1, 1])\n",
      "[PRUNE] 更新 out_channels: 26\n",
      "[PRUNE] 輸出通道剪枝完成: 128 -> 26\n",
      "[PRUNE] 開始剪枝 BatchNorm 層: net_feature_maps.layer2.3.bn1\n",
      "[PRUNE] BatchNorm 通道數變化: 128 -> 26\n",
      "[PRUNE] BatchNorm weight 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm bias 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm running_mean 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm running_var 剪枝完成: torch.Size([26])\n",
      "[VALIDATE] BatchNorm 層 net_feature_maps.layer2.3.bn1 剪枝驗證通過\n",
      "[PRUNE] BatchNorm 層 net_feature_maps.layer2.3.bn1 剪枝成功\n",
      "[PRUNE] 修補 net_feature_maps.layer2.3.conv2 的輸入通道 (來源 layer2.3.conv1)\n",
      "[PRUNE] Conv 輸入維度: torch.Size([128, 128, 3, 3]) → torch.Size([128, 26, 3, 3])\n",
      "[2, 4, 8, 20, 22, 24, 26, 28, 39, 48, 50, 51, 58, 64, 71, 77, 80, 81, 93, 97, 107, 109, 110, 116, 117, 121]\n",
      "<class 'list'>\n",
      "[2, 4, 8, 20, 22, 24, 26, 28, 39, 48, 50, 51, 58, 64, 71, 77, 80, 81, 93, 97, 107, 109, 110, 116, 117, 121]\n",
      "[INFO] 覆蓋現有層級數據: layer2.3.conv1\n",
      "[TRACK] layer2.3.conv1 剪枝率 0.0%\n",
      "[PRUNE] 完成剪枝層級: layer2.3.conv1\n",
      "[PRUNE] 開始剪枝層級: layer2.3.conv2\n",
      "=== net_feature_maps 詳細層級資訊 ===\n",
      "[LCP] 層級依賴分析完成 - layer2.3.conv2\n",
      "      BatchNorm: net_feature_maps.layer2.3.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[PRUNE] 開始剪枝輸出通道: layer2.3.conv2\n",
      "[PRUNE] 保留通道索引: [5, 15, 22, 24, 27, 31, 32, 43, 49, 52, 55, 64, 66, 73, 74, 80, 81, 86, 89, 90, 97, 100, 103, 104, 111, 124]\n",
      "[PRUNE] 保留通道數量: 26\n",
      "[PRUNE] 原始輸出通道數: 128\n",
      "[PRUNE] Conv2d 權重: torch.Size([128, 26, 3, 3]) -> torch.Size([26, 26, 3, 3])\n",
      "[PRUNE] 更新 out_channels: 26\n",
      "[PRUNE] 輸出通道剪枝完成: 128 -> 26\n",
      "[PRUNE] 開始剪枝 BatchNorm 層: net_feature_maps.layer2.3.bn2\n",
      "[PRUNE] BatchNorm 通道數變化: 128 -> 26\n",
      "[PRUNE] BatchNorm weight 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm bias 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm running_mean 剪枝完成: torch.Size([26])\n",
      "[PRUNE] BatchNorm running_var 剪枝完成: torch.Size([26])\n",
      "[VALIDATE] BatchNorm 層 net_feature_maps.layer2.3.bn2 剪枝驗證通過\n",
      "[PRUNE] BatchNorm 層 net_feature_maps.layer2.3.bn2 剪枝成功\n",
      "[PRUNE] 修補 net_feature_maps.layer2.3.conv3 的輸入通道 (來源 layer2.3.conv2)\n",
      "[PRUNE] Conv 輸入維度: torch.Size([512, 128, 1, 1]) → torch.Size([512, 26, 1, 1])\n",
      "[5, 15, 22, 24, 27, 31, 32, 43, 49, 52, 55, 64, 66, 73, 74, 80, 81, 86, 89, 90, 97, 100, 103, 104, 111, 124]\n",
      "<class 'list'>\n",
      "[5, 15, 22, 24, 27, 31, 32, 43, 49, 52, 55, 64, 66, 73, 74, 80, 81, 86, 89, 90, 97, 100, 103, 104, 111, 124]\n",
      "[INFO] 覆蓋現有層級數據: layer2.3.conv2\n",
      "[TRACK] layer2.3.conv2 剪枝率 0.0%\n",
      "[PRUNE] 完成剪枝層級: layer2.3.conv2\n",
      "[PRUNE] 開始剪枝層級: layer3.0.conv2\n",
      "=== net_feature_maps 詳細層級資訊 ===\n",
      "[LCP] 層級依賴分析完成 - layer3.0.conv2\n",
      "      BatchNorm: net_feature_maps.layer3.0.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[PRUNE] 開始剪枝輸出通道: layer3.0.conv2\n",
      "[PRUNE] 保留通道索引: [2, 4, 6, 7, 9, 10, 11, 12, 14, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 41, 43, 44, 45, 47, 48, 51, 52, 53, 55, 56, 57, 60, 64, 65, 66, 70, 72, 73, 74, 77, 78, 81, 82, 83, 84, 85, 87, 88, 90, 94, 95, 100, 101, 102, 104, 107, 108, 110, 111, 112, 113, 114, 115, 119, 120, 121, 123, 124, 125, 126, 127, 128, 131, 133, 136, 137, 138, 139, 141, 145, 146, 148, 155, 156, 159, 161, 162, 163, 165, 166, 167, 169, 171, 172, 175, 176, 177, 178, 180, 181, 186, 188, 190, 191, 192, 193, 195, 198, 199, 202, 203, 204, 206, 208, 210, 211, 212, 213, 216, 217, 221, 222, 223, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 243, 244, 246, 247, 248, 252, 253, 255]\n",
      "[PRUNE] 保留通道數量: 154\n",
      "[PRUNE] 原始輸出通道數: 256\n",
      "[PRUNE] Conv2d 權重: torch.Size([256, 256, 3, 3]) -> torch.Size([154, 256, 3, 3])\n",
      "[PRUNE] 更新 out_channels: 154\n",
      "[PRUNE] 輸出通道剪枝完成: 256 -> 154\n",
      "[PRUNE] 開始剪枝 BatchNorm 層: net_feature_maps.layer3.0.bn2\n",
      "[PRUNE] BatchNorm 通道數變化: 256 -> 154\n",
      "[PRUNE] BatchNorm weight 剪枝完成: torch.Size([154])\n",
      "[PRUNE] BatchNorm bias 剪枝完成: torch.Size([154])\n",
      "[PRUNE] BatchNorm running_mean 剪枝完成: torch.Size([154])\n",
      "[PRUNE] BatchNorm running_var 剪枝完成: torch.Size([154])\n",
      "[VALIDATE] BatchNorm 層 net_feature_maps.layer3.0.bn2 剪枝驗證通過\n",
      "[PRUNE] BatchNorm 層 net_feature_maps.layer3.0.bn2 剪枝成功\n",
      "[PRUNE] 修補 net_feature_maps.layer3.0.conv3 的輸入通道 (來源 layer3.0.conv2)\n",
      "[PRUNE] Conv 輸入維度: torch.Size([1024, 256, 1, 1]) → torch.Size([1024, 154, 1, 1])\n",
      "[2, 4, 6, 7, 9, 10, 11, 12, 14, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 41, 43, 44, 45, 47, 48, 51, 52, 53, 55, 56, 57, 60, 64, 65, 66, 70, 72, 73, 74, 77, 78, 81, 82, 83, 84, 85, 87, 88, 90, 94, 95, 100, 101, 102, 104, 107, 108, 110, 111, 112, 113, 114, 115, 119, 120, 121, 123, 124, 125, 126, 127, 128, 131, 133, 136, 137, 138, 139, 141, 145, 146, 148, 155, 156, 159, 161, 162, 163, 165, 166, 167, 169, 171, 172, 175, 176, 177, 178, 180, 181, 186, 188, 190, 191, 192, 193, 195, 198, 199, 202, 203, 204, 206, 208, 210, 211, 212, 213, 216, 217, 221, 222, 223, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 243, 244, 246, 247, 248, 252, 253, 255]\n",
      "<class 'list'>\n",
      "[2, 4, 6, 7, 9, 10, 11, 12, 14, 17, 18, 19, 22, 23, 24, 25, 26, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 41, 43, 44, 45, 47, 48, 51, 52, 53, 55, 56, 57, 60, 64, 65, 66, 70, 72, 73, 74, 77, 78, 81, 82, 83, 84, 85, 87, 88, 90, 94, 95, 100, 101, 102, 104, 107, 108, 110, 111, 112, 113, 114, 115, 119, 120, 121, 123, 124, 125, 126, 127, 128, 131, 133, 136, 137, 138, 139, 141, 145, 146, 148, 155, 156, 159, 161, 162, 163, 165, 166, 167, 169, 171, 172, 175, 176, 177, 178, 180, 181, 186, 188, 190, 191, 192, 193, 195, 198, 199, 202, 203, 204, 206, 208, 210, 211, 212, 213, 216, 217, 221, 222, 223, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 243, 244, 246, 247, 248, 252, 253, 255]\n",
      "[INFO] 覆蓋現有層級數據: layer3.0.conv2\n",
      "[TRACK] layer3.0.conv2 剪枝率 0.0%\n",
      "[PRUNE] 完成剪枝層級: layer3.0.conv2\n",
      "[PRUNE] 開始剪枝層級: layer3.1.conv2\n",
      "=== net_feature_maps 詳細層級資訊 ===\n",
      "[LCP] 層級依賴分析完成 - layer3.1.conv2\n",
      "      BatchNorm: net_feature_maps.layer3.1.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[PRUNE] 開始剪枝輸出通道: layer3.1.conv2\n",
      "[PRUNE] 保留通道索引: [2, 3, 4, 6, 8, 11, 13, 16, 18, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 35, 36, 38, 39, 40, 42, 44, 45, 46, 47, 52, 53, 57, 60, 61, 63, 67, 69, 71, 72, 75, 78, 79, 81, 82, 85, 86, 87, 88, 91, 92, 93, 95, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 115, 116, 120, 121, 124, 125, 129, 131, 132, 133, 134, 135, 136, 139, 140, 141, 143, 144, 146, 147, 148, 149, 150, 151, 153, 154, 158, 159, 161, 162, 163, 166, 168, 169, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 184, 189, 190, 195, 199, 200, 202, 203, 204, 206, 207, 208, 210, 212, 214, 217, 218, 219, 220, 221, 222, 225, 229, 230, 231, 232, 233, 235, 237, 238, 240, 242, 243, 244, 246, 247, 248, 251, 252, 253, 254, 255]\n",
      "[PRUNE] 保留通道數量: 154\n",
      "[PRUNE] 原始輸出通道數: 256\n",
      "[PRUNE] Conv2d 權重: torch.Size([256, 256, 3, 3]) -> torch.Size([154, 256, 3, 3])\n",
      "[PRUNE] 更新 out_channels: 154\n",
      "[PRUNE] 輸出通道剪枝完成: 256 -> 154\n",
      "[PRUNE] 開始剪枝 BatchNorm 層: net_feature_maps.layer3.1.bn2\n",
      "[PRUNE] BatchNorm 通道數變化: 256 -> 154\n",
      "[PRUNE] BatchNorm weight 剪枝完成: torch.Size([154])\n",
      "[PRUNE] BatchNorm bias 剪枝完成: torch.Size([154])\n",
      "[PRUNE] BatchNorm running_mean 剪枝完成: torch.Size([154])\n",
      "[PRUNE] BatchNorm running_var 剪枝完成: torch.Size([154])\n",
      "[VALIDATE] BatchNorm 層 net_feature_maps.layer3.1.bn2 剪枝驗證通過\n",
      "[PRUNE] BatchNorm 層 net_feature_maps.layer3.1.bn2 剪枝成功\n",
      "[PRUNE] 修補 net_feature_maps.layer3.1.conv3 的輸入通道 (來源 layer3.1.conv2)\n",
      "[PRUNE] Conv 輸入維度: torch.Size([1024, 256, 1, 1]) → torch.Size([1024, 154, 1, 1])\n",
      "[2, 3, 4, 6, 8, 11, 13, 16, 18, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 35, 36, 38, 39, 40, 42, 44, 45, 46, 47, 52, 53, 57, 60, 61, 63, 67, 69, 71, 72, 75, 78, 79, 81, 82, 85, 86, 87, 88, 91, 92, 93, 95, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 115, 116, 120, 121, 124, 125, 129, 131, 132, 133, 134, 135, 136, 139, 140, 141, 143, 144, 146, 147, 148, 149, 150, 151, 153, 154, 158, 159, 161, 162, 163, 166, 168, 169, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 184, 189, 190, 195, 199, 200, 202, 203, 204, 206, 207, 208, 210, 212, 214, 217, 218, 219, 220, 221, 222, 225, 229, 230, 231, 232, 233, 235, 237, 238, 240, 242, 243, 244, 246, 247, 248, 251, 252, 253, 254, 255]\n",
      "<class 'list'>\n",
      "[2, 3, 4, 6, 8, 11, 13, 16, 18, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 35, 36, 38, 39, 40, 42, 44, 45, 46, 47, 52, 53, 57, 60, 61, 63, 67, 69, 71, 72, 75, 78, 79, 81, 82, 85, 86, 87, 88, 91, 92, 93, 95, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 115, 116, 120, 121, 124, 125, 129, 131, 132, 133, 134, 135, 136, 139, 140, 141, 143, 144, 146, 147, 148, 149, 150, 151, 153, 154, 158, 159, 161, 162, 163, 166, 168, 169, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 184, 189, 190, 195, 199, 200, 202, 203, 204, 206, 207, 208, 210, 212, 214, 217, 218, 219, 220, 221, 222, 225, 229, 230, 231, 232, 233, 235, 237, 238, 240, 242, 243, 244, 246, 247, 248, 251, 252, 253, 254, 255]\n",
      "[INFO] 覆蓋現有層級數據: layer3.1.conv2\n",
      "[TRACK] layer3.1.conv2 剪枝率 0.0%\n",
      "[PRUNE] 完成剪枝層級: layer3.1.conv2\n",
      "[PRUNE] 開始剪枝層級: layer3.2.conv2\n",
      "=== net_feature_maps 詳細層級資訊 ===\n",
      "[LCP] 層級依賴分析完成 - layer3.2.conv2\n",
      "      BatchNorm: net_feature_maps.layer3.2.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[PRUNE] 開始剪枝輸出通道: layer3.2.conv2\n",
      "[PRUNE] 保留通道索引: [1, 2, 3, 6, 7, 8, 10, 11, 12, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 38, 40, 42, 43, 44, 46, 48, 50, 52, 53, 54, 56, 57, 58, 59, 64, 65, 66, 70, 73, 74, 75, 78, 79, 80, 82, 83, 86, 89, 91, 93, 94, 99, 100, 101, 104, 105, 106, 107, 108, 109, 110, 111, 112, 115, 117, 119, 120, 123, 124, 126, 128, 129, 132, 133, 135, 136, 137, 139, 140, 142, 143, 145, 147, 148, 149, 150, 151, 152, 154, 156, 157, 160, 163, 165, 167, 168, 170, 171, 176, 177, 178, 181, 183, 185, 186, 187, 188, 189, 190, 192, 194, 195, 197, 198, 199, 203, 205, 209, 210, 213, 214, 216, 217, 218, 220, 222, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 245, 247, 248, 249, 250, 253]\n",
      "[PRUNE] 保留通道數量: 154\n",
      "[PRUNE] 原始輸出通道數: 256\n",
      "[PRUNE] Conv2d 權重: torch.Size([256, 256, 3, 3]) -> torch.Size([154, 256, 3, 3])\n",
      "[PRUNE] 更新 out_channels: 154\n",
      "[PRUNE] 輸出通道剪枝完成: 256 -> 154\n",
      "[PRUNE] 開始剪枝 BatchNorm 層: net_feature_maps.layer3.2.bn2\n",
      "[PRUNE] BatchNorm 通道數變化: 256 -> 154\n",
      "[PRUNE] BatchNorm weight 剪枝完成: torch.Size([154])\n",
      "[PRUNE] BatchNorm bias 剪枝完成: torch.Size([154])\n",
      "[PRUNE] BatchNorm running_mean 剪枝完成: torch.Size([154])\n",
      "[PRUNE] BatchNorm running_var 剪枝完成: torch.Size([154])\n",
      "[VALIDATE] BatchNorm 層 net_feature_maps.layer3.2.bn2 剪枝驗證通過\n",
      "[PRUNE] BatchNorm 層 net_feature_maps.layer3.2.bn2 剪枝成功\n",
      "[PRUNE] 修補 net_feature_maps.layer3.2.conv3 的輸入通道 (來源 layer3.2.conv2)\n",
      "[PRUNE] Conv 輸入維度: torch.Size([1024, 256, 1, 1]) → torch.Size([1024, 154, 1, 1])\n",
      "[1, 2, 3, 6, 7, 8, 10, 11, 12, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 38, 40, 42, 43, 44, 46, 48, 50, 52, 53, 54, 56, 57, 58, 59, 64, 65, 66, 70, 73, 74, 75, 78, 79, 80, 82, 83, 86, 89, 91, 93, 94, 99, 100, 101, 104, 105, 106, 107, 108, 109, 110, 111, 112, 115, 117, 119, 120, 123, 124, 126, 128, 129, 132, 133, 135, 136, 137, 139, 140, 142, 143, 145, 147, 148, 149, 150, 151, 152, 154, 156, 157, 160, 163, 165, 167, 168, 170, 171, 176, 177, 178, 181, 183, 185, 186, 187, 188, 189, 190, 192, 194, 195, 197, 198, 199, 203, 205, 209, 210, 213, 214, 216, 217, 218, 220, 222, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 245, 247, 248, 249, 250, 253]\n",
      "<class 'list'>\n",
      "[1, 2, 3, 6, 7, 8, 10, 11, 12, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 38, 40, 42, 43, 44, 46, 48, 50, 52, 53, 54, 56, 57, 58, 59, 64, 65, 66, 70, 73, 74, 75, 78, 79, 80, 82, 83, 86, 89, 91, 93, 94, 99, 100, 101, 104, 105, 106, 107, 108, 109, 110, 111, 112, 115, 117, 119, 120, 123, 124, 126, 128, 129, 132, 133, 135, 136, 137, 139, 140, 142, 143, 145, 147, 148, 149, 150, 151, 152, 154, 156, 157, 160, 163, 165, 167, 168, 170, 171, 176, 177, 178, 181, 183, 185, 186, 187, 188, 189, 190, 192, 194, 195, 197, 198, 199, 203, 205, 209, 210, 213, 214, 216, 217, 218, 220, 222, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 245, 247, 248, 249, 250, 253]\n",
      "[INFO] 覆蓋現有層級數據: layer3.2.conv2\n",
      "[TRACK] layer3.2.conv2 剪枝率 0.0%\n",
      "[PRUNE] 完成剪枝層級: layer3.2.conv2\n",
      "[PRUNE] 開始剪枝層級: layer3.3.conv2\n",
      "=== net_feature_maps 詳細層級資訊 ===\n",
      "[LCP] 層級依賴分析完成 - layer3.3.conv2\n",
      "      BatchNorm: net_feature_maps.layer3.3.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[PRUNE] 開始剪枝輸出通道: layer3.3.conv2\n",
      "[PRUNE] 保留通道索引: [0, 1, 2, 3, 5, 7, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 32, 33, 35, 36, 38, 39, 41, 42, 43, 44, 48, 51, 52, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 73, 74, 75, 77, 80, 82, 83, 84, 85, 86, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 105, 106, 107, 108, 110, 113, 114, 117, 120, 124, 125, 129, 130, 131, 132, 135, 137, 138, 139, 140, 142, 143, 145, 147, 149, 151, 152, 154, 155, 157, 158, 159, 164, 167, 170, 173, 178, 179, 180, 181, 182, 183, 184, 185, 192, 193, 194, 195, 196, 198, 200, 201, 202, 203, 204, 206, 208, 211, 212, 213, 215, 216, 219, 221, 222, 226, 228, 229, 230, 232, 233, 239, 240, 242, 243, 244, 245, 246, 250, 252, 255]\n",
      "[PRUNE] 保留通道數量: 154\n",
      "[PRUNE] 原始輸出通道數: 256\n",
      "[PRUNE] Conv2d 權重: torch.Size([256, 256, 3, 3]) -> torch.Size([154, 256, 3, 3])\n",
      "[PRUNE] 更新 out_channels: 154\n",
      "[PRUNE] 輸出通道剪枝完成: 256 -> 154\n",
      "[PRUNE] 開始剪枝 BatchNorm 層: net_feature_maps.layer3.3.bn2\n",
      "[PRUNE] BatchNorm 通道數變化: 256 -> 154\n",
      "[PRUNE] BatchNorm weight 剪枝完成: torch.Size([154])\n",
      "[PRUNE] BatchNorm bias 剪枝完成: torch.Size([154])\n",
      "[PRUNE] BatchNorm running_mean 剪枝完成: torch.Size([154])\n",
      "[PRUNE] BatchNorm running_var 剪枝完成: torch.Size([154])\n",
      "[VALIDATE] BatchNorm 層 net_feature_maps.layer3.3.bn2 剪枝驗證通過\n",
      "[PRUNE] BatchNorm 層 net_feature_maps.layer3.3.bn2 剪枝成功\n",
      "[PRUNE] 修補 net_feature_maps.layer3.3.conv3 的輸入通道 (來源 layer3.3.conv2)\n",
      "[PRUNE] Conv 輸入維度: torch.Size([1024, 256, 1, 1]) → torch.Size([1024, 154, 1, 1])\n",
      "[0, 1, 2, 3, 5, 7, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 32, 33, 35, 36, 38, 39, 41, 42, 43, 44, 48, 51, 52, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 73, 74, 75, 77, 80, 82, 83, 84, 85, 86, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 105, 106, 107, 108, 110, 113, 114, 117, 120, 124, 125, 129, 130, 131, 132, 135, 137, 138, 139, 140, 142, 143, 145, 147, 149, 151, 152, 154, 155, 157, 158, 159, 164, 167, 170, 173, 178, 179, 180, 181, 182, 183, 184, 185, 192, 193, 194, 195, 196, 198, 200, 201, 202, 203, 204, 206, 208, 211, 212, 213, 215, 216, 219, 221, 222, 226, 228, 229, 230, 232, 233, 239, 240, 242, 243, 244, 245, 246, 250, 252, 255]\n",
      "<class 'list'>\n",
      "[0, 1, 2, 3, 5, 7, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 32, 33, 35, 36, 38, 39, 41, 42, 43, 44, 48, 51, 52, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 73, 74, 75, 77, 80, 82, 83, 84, 85, 86, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 105, 106, 107, 108, 110, 113, 114, 117, 120, 124, 125, 129, 130, 131, 132, 135, 137, 138, 139, 140, 142, 143, 145, 147, 149, 151, 152, 154, 155, 157, 158, 159, 164, 167, 170, 173, 178, 179, 180, 181, 182, 183, 184, 185, 192, 193, 194, 195, 196, 198, 200, 201, 202, 203, 204, 206, 208, 211, 212, 213, 215, 216, 219, 221, 222, 226, 228, 229, 230, 232, 233, 239, 240, 242, 243, 244, 245, 246, 250, 252, 255]\n",
      "[INFO] 覆蓋現有層級數據: layer3.3.conv2\n",
      "[TRACK] layer3.3.conv2 剪枝率 0.0%\n",
      "[PRUNE] 完成剪枝層級: layer3.3.conv2\n",
      "[PRUNE] 開始剪枝層級: layer3.4.conv2\n",
      "=== net_feature_maps 詳細層級資訊 ===\n",
      "[LCP] 層級依賴分析完成 - layer3.4.conv2\n",
      "      BatchNorm: net_feature_maps.layer3.4.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[PRUNE] 開始剪枝輸出通道: layer3.4.conv2\n",
      "[PRUNE] 保留通道索引: [2, 4, 5, 7, 8, 12, 13, 15, 18, 20, 21, 22, 24, 26, 27, 29, 31, 32, 34, 36, 41, 45, 46, 47, 50, 51, 53, 54, 55, 58, 61, 62, 63, 64, 65, 67, 70, 77, 78, 80, 81, 82, 83, 84, 85, 86, 89, 90, 91, 92, 94, 95, 98, 99, 101, 102, 104, 108, 109, 110, 115, 116, 117, 119, 121, 123, 125, 126, 128, 130, 131, 133, 135, 136, 137, 138, 139, 141, 142, 143, 144, 146, 147, 148, 149, 150, 154, 155, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 171, 172, 174, 175, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 194, 196, 197, 199, 200, 201, 203, 204, 205, 207, 208, 209, 210, 213, 215, 216, 217, 219, 220, 221, 223, 224, 225, 226, 227, 229, 233, 235, 236, 237, 239, 241, 242, 244, 246, 250, 252, 254]\n",
      "[PRUNE] 保留通道數量: 154\n",
      "[PRUNE] 原始輸出通道數: 256\n",
      "[PRUNE] Conv2d 權重: torch.Size([256, 256, 3, 3]) -> torch.Size([154, 256, 3, 3])\n",
      "[PRUNE] 更新 out_channels: 154\n",
      "[PRUNE] 輸出通道剪枝完成: 256 -> 154\n",
      "[PRUNE] 開始剪枝 BatchNorm 層: net_feature_maps.layer3.4.bn2\n",
      "[PRUNE] BatchNorm 通道數變化: 256 -> 154\n",
      "[PRUNE] BatchNorm weight 剪枝完成: torch.Size([154])\n",
      "[PRUNE] BatchNorm bias 剪枝完成: torch.Size([154])\n",
      "[PRUNE] BatchNorm running_mean 剪枝完成: torch.Size([154])\n",
      "[PRUNE] BatchNorm running_var 剪枝完成: torch.Size([154])\n",
      "[VALIDATE] BatchNorm 層 net_feature_maps.layer3.4.bn2 剪枝驗證通過\n",
      "[PRUNE] BatchNorm 層 net_feature_maps.layer3.4.bn2 剪枝成功\n",
      "[PRUNE] 修補 net_feature_maps.layer3.4.conv3 的輸入通道 (來源 layer3.4.conv2)\n",
      "[PRUNE] Conv 輸入維度: torch.Size([1024, 256, 1, 1]) → torch.Size([1024, 154, 1, 1])\n",
      "[2, 4, 5, 7, 8, 12, 13, 15, 18, 20, 21, 22, 24, 26, 27, 29, 31, 32, 34, 36, 41, 45, 46, 47, 50, 51, 53, 54, 55, 58, 61, 62, 63, 64, 65, 67, 70, 77, 78, 80, 81, 82, 83, 84, 85, 86, 89, 90, 91, 92, 94, 95, 98, 99, 101, 102, 104, 108, 109, 110, 115, 116, 117, 119, 121, 123, 125, 126, 128, 130, 131, 133, 135, 136, 137, 138, 139, 141, 142, 143, 144, 146, 147, 148, 149, 150, 154, 155, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 171, 172, 174, 175, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 194, 196, 197, 199, 200, 201, 203, 204, 205, 207, 208, 209, 210, 213, 215, 216, 217, 219, 220, 221, 223, 224, 225, 226, 227, 229, 233, 235, 236, 237, 239, 241, 242, 244, 246, 250, 252, 254]\n",
      "<class 'list'>\n",
      "[2, 4, 5, 7, 8, 12, 13, 15, 18, 20, 21, 22, 24, 26, 27, 29, 31, 32, 34, 36, 41, 45, 46, 47, 50, 51, 53, 54, 55, 58, 61, 62, 63, 64, 65, 67, 70, 77, 78, 80, 81, 82, 83, 84, 85, 86, 89, 90, 91, 92, 94, 95, 98, 99, 101, 102, 104, 108, 109, 110, 115, 116, 117, 119, 121, 123, 125, 126, 128, 130, 131, 133, 135, 136, 137, 138, 139, 141, 142, 143, 144, 146, 147, 148, 149, 150, 154, 155, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 171, 172, 174, 175, 177, 178, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 194, 196, 197, 199, 200, 201, 203, 204, 205, 207, 208, 209, 210, 213, 215, 216, 217, 219, 220, 221, 223, 224, 225, 226, 227, 229, 233, 235, 236, 237, 239, 241, 242, 244, 246, 250, 252, 254]\n",
      "[INFO] 覆蓋現有層級數據: layer3.4.conv2\n",
      "[TRACK] layer3.4.conv2 剪枝率 0.0%\n",
      "[PRUNE] 完成剪枝層級: layer3.4.conv2\n",
      "[PRUNE] 開始剪枝層級: layer3.5.conv2\n",
      "=== net_feature_maps 詳細層級資訊 ===\n",
      "[LCP] 層級依賴分析完成 - layer3.5.conv2\n",
      "      BatchNorm: net_feature_maps.layer3.5.bn2\n",
      "      下游層級: 1 個\n",
      "      跳躍連接: 0 個\n",
      "[PRUNE] 開始剪枝輸出通道: layer3.5.conv2\n",
      "[PRUNE] 保留通道索引: [0, 3, 6, 8, 11, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 27, 28, 30, 31, 32, 34, 35, 38, 39, 41, 42, 43, 44, 45, 46, 51, 52, 53, 54, 55, 58, 61, 62, 64, 65, 66, 67, 68, 70, 72, 74, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 95, 97, 99, 100, 101, 105, 106, 107, 108, 110, 111, 114, 115, 117, 119, 120, 121, 122, 123, 126, 127, 128, 132, 133, 134, 135, 137, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 154, 155, 156, 157, 158, 161, 162, 164, 167, 170, 172, 174, 176, 177, 178, 180, 181, 184, 185, 186, 188, 189, 190, 192, 193, 196, 198, 199, 200, 201, 208, 210, 212, 213, 214, 218, 220, 221, 223, 226, 227, 228, 229, 231, 232, 233, 235, 237, 239, 241, 243, 244, 245, 251, 253, 254]\n",
      "[PRUNE] 保留通道數量: 154\n",
      "[PRUNE] 原始輸出通道數: 256\n",
      "[PRUNE] Conv2d 權重: torch.Size([256, 256, 3, 3]) -> torch.Size([154, 256, 3, 3])\n",
      "[PRUNE] 更新 out_channels: 154\n",
      "[PRUNE] 輸出通道剪枝完成: 256 -> 154\n",
      "[PRUNE] 開始剪枝 BatchNorm 層: net_feature_maps.layer3.5.bn2\n",
      "[PRUNE] BatchNorm 通道數變化: 256 -> 154\n",
      "[PRUNE] BatchNorm weight 剪枝完成: torch.Size([154])\n",
      "[PRUNE] BatchNorm bias 剪枝完成: torch.Size([154])\n",
      "[PRUNE] BatchNorm running_mean 剪枝完成: torch.Size([154])\n",
      "[PRUNE] BatchNorm running_var 剪枝完成: torch.Size([154])\n",
      "[VALIDATE] BatchNorm 層 net_feature_maps.layer3.5.bn2 剪枝驗證通過\n",
      "[PRUNE] BatchNorm 層 net_feature_maps.layer3.5.bn2 剪枝成功\n",
      "[PRUNE] 修補 net_feature_maps.layer3.5.conv3 的輸入通道 (來源 layer3.5.conv2)\n",
      "[PRUNE] Conv 輸入維度: torch.Size([1024, 256, 1, 1]) → torch.Size([1024, 154, 1, 1])\n",
      "[0, 3, 6, 8, 11, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 27, 28, 30, 31, 32, 34, 35, 38, 39, 41, 42, 43, 44, 45, 46, 51, 52, 53, 54, 55, 58, 61, 62, 64, 65, 66, 67, 68, 70, 72, 74, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 95, 97, 99, 100, 101, 105, 106, 107, 108, 110, 111, 114, 115, 117, 119, 120, 121, 122, 123, 126, 127, 128, 132, 133, 134, 135, 137, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 154, 155, 156, 157, 158, 161, 162, 164, 167, 170, 172, 174, 176, 177, 178, 180, 181, 184, 185, 186, 188, 189, 190, 192, 193, 196, 198, 199, 200, 201, 208, 210, 212, 213, 214, 218, 220, 221, 223, 226, 227, 228, 229, 231, 232, 233, 235, 237, 239, 241, 243, 244, 245, 251, 253, 254]\n",
      "<class 'list'>\n",
      "[0, 3, 6, 8, 11, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 27, 28, 30, 31, 32, 34, 35, 38, 39, 41, 42, 43, 44, 45, 46, 51, 52, 53, 54, 55, 58, 61, 62, 64, 65, 66, 67, 68, 70, 72, 74, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 95, 97, 99, 100, 101, 105, 106, 107, 108, 110, 111, 114, 115, 117, 119, 120, 121, 122, 123, 126, 127, 128, 132, 133, 134, 135, 137, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 154, 155, 156, 157, 158, 161, 162, 164, 167, 170, 172, 174, 176, 177, 178, 180, 181, 184, 185, 186, 188, 189, 190, 192, 193, 196, 198, 199, 200, 201, 208, 210, 212, 213, 214, 218, 220, 221, 223, 226, 227, 228, 229, 231, 232, 233, 235, 237, 239, 241, 243, 244, 245, 251, 253, 254]\n",
      "[INFO] 覆蓋現有層級數據: layer3.5.conv2\n",
      "[TRACK] layer3.5.conv2 剪枝率 0.0%\n",
      "[PRUNE] 完成剪枝層級: layer3.5.conv2\n"
     ]
    }
   ],
   "source": [
    "for layer in pruned_layers:\n",
    "    lcp.prune_layer(\n",
    "        layer_name   = layer,\n",
    "        discard_rate = None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca472fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始網路參數統計:\n",
      "\n",
      "總參數量: 10,169,478\n",
      "可訓練參數量: 10,169,478\n",
      "模型存儲大小: 39.05 MB\n",
      "剪枝網路參數統計:\n",
      "\n",
      "總參數量: 6,997,533\n",
      "可訓練參數量: 6,997,533\n",
      "模型存儲大小: 26.93 MB\n"
     ]
    }
   ],
   "source": [
    "show_network_status( net, lcp._prune_net )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "093bfe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range( 20 ):\n",
    "#     lcp.debug_for_test_vision(\n",
    "#         dataloader_train = dataloader_train,\n",
    "#         img_normalization = img_normalization,\n",
    "#         box_coder = box_coder,\n",
    "#         cfg = cfg,\n",
    "#         count = 1\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd001596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始評估 50 張圖像...\n",
      "Image 56 size FeatureMapSize(w=3264, h=2448) has 17 boxes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\anaconda3\\envs\\ntut-project\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((0.05505147321670215, 0.0), (0.36141354602699194, 0.43856912543903964)), ((0.6738199493901559, 0.6073022479732005), (0.9154952051457852, 1.0)), ((0.0, 0.6088683941072459), (0.19607413558431366, 0.9831397311333238)), ((0.1708903323695511, 0.617684943571377), (0.3717804307475101, 0.9854671487081409))]\n",
      "converted_boxes: [((0.05505147321670215, 0.0), (0.36141354602699194, 0.43856912543903964)), ((0.6738199493901559, 0.6073022479732005), (0.9154952051457852, 1.0)), ((0.0, 0.6088683941072459), (0.19607413558431366, 0.9831397311333238)), ((0.1708903323695511, 0.617684943571377), (0.3717804307475101, 0.9854671487081409))], tpoints: [((0.02499999953251259, 0.6767000185897927), (0.18999999177222157, 0.950000039892259)), ((0.1875, 0.6800000059838388), (0.35000000747979854, 0.9600000319138072)), ((0.01999999962601007, 0.42330000135633683), (0.1875, 0.689999998005387)), ((0.1875, 0.43000000598383886), (0.3449999865363626, 0.6932999853994332))]\n",
      "Image 421 size FeatureMapSize(w=2448, h=3264) has 9 boxes\n",
      "[((0.0, 0.8206383262440459), (0.13217473195276414, 1.0))]\n",
      "converted_boxes: [((0.0, 0.8206383262440459), (0.13217473195276414, 1.0))], tpoints: [((0.6767000185897927, 0.755000020943436), (1.0, 0.9724999970080805))]\n",
      "Image 521 size FeatureMapSize(w=2448, h=3264) has 18 boxes\n",
      "[((0.25432896191932497, 0.18945772378053732), (0.7576426916438126, 0.6403775468434252)), ((0.11808264705196907, 0.16457023356307737), (0.4640672080235999, 0.5987421965213626)), ((0.06056862963998749, 0.0), (0.44963753856632505, 0.35910879932429995)), ((0.0, 0.20365412405952296), (0.2755569563726905, 0.544095045975119))]\n",
      "converted_boxes: [((0.25432896191932497, 0.18945772378053732), (0.7576426916438126, 0.6403775468434252)), ((0.11808264705196907, 0.16457023356307737), (0.4640672080235999, 0.5987421965213626)), ((0.06056862963998749, 0.0), (0.44963753856632505, 0.35910879932429995)), ((0.0, 0.20365412405952296), (0.2755569563726905, 0.544095045975119))], tpoints: [((0.24669998767329196, 0.27000000897575827), (0.44999999002693525, 0.5100000044878792)), ((0.023299999486387165, 0.27000000897575827), (0.2766999886705985, 0.5125000149595971)), ((0.0032999998603770934, 0.0), (0.24329999537249797, 0.27250000074797986)), ((0.21000000698114532, 0.002499999953251259), (0.4432999853994332, 0.27000000897575827))]\n",
      "Image 498 size FeatureMapSize(w=3264, h=2448) has 6 boxes\n",
      "[((0.7199789492142393, 0.4847993329454147), (0.9564972276225101, 0.8160514097382602))]\n",
      "converted_boxes: [((0.7199789492142393, 0.4847993329454147), (0.9564972276225101, 0.8160514097382602))], tpoints: [((0.7099999820484835, 0.49670001260595387), (0.9350000269272748, 0.8400000279245813))]\n",
      "Image 186 size FeatureMapSize(w=2448, h=3264) has 15 boxes\n",
      "[((0.21537213402587327, 0.20270906584918086), (0.6398583721251925, 0.6277661753031177)), ((0.0, 0.2045298657846781), (0.19186054843494393, 0.4732556772562428)), ((0.0, 0.22507857395374747), (0.40844552713325155, 0.6169740883913106))]\n",
      "converted_boxes: [((0.21537213402587327, 0.20270906584918086), (0.6398583721251925, 0.6277661753031177)), ((0.0, 0.2045298657846781), (0.19186054843494393, 0.4732556772562428)), ((0.0, 0.22507857395374747), (0.40844552713325155, 0.6169740883913106))], tpoints: [((0.0, 0.16250000747979856), (0.12330000384960299, 0.5200000089757583)), ((0.126699996150397, 0.18249999775606043), (0.24329999537249797, 0.5200000089757583)), ((0.22999999102424173, 0.1700000014959597), (0.3700000039892259, 0.5200000089757583))]\n",
      "Image 524 size FeatureMapSize(w=3264, h=2448) has 8 boxes\n",
      "[((0.36973688068345845, 0.01802498785874952), (0.6827447552053262, 0.6039323931569958)), ((0.0, 0.0061542255498520495), (0.11970029306742115, 0.36917215278278964)), ((0.045399866258299656, 0.0025203431726327943), (0.39084094886691684, 0.5095605769462086))]\n",
      "converted_boxes: [((0.36973688068345845, 0.01802498785874952), (0.6827447552053262, 0.6039323931569958)), ((0.0, 0.0061542255498520495), (0.11970029306742115, 0.36917215278278964)), ((0.045399866258299656, 0.0025203431726327943), (0.39084094886691684, 0.5095605769462086))], tpoints: [((0.38249999401616114, 0.4032999923805785), (0.5475000119676777, 0.7333000033509498)), ((0.38500000448787913, 0.1000000012466331), (0.5475000119676777, 0.41670000163558263)), ((0.5499999850404029, 0.4067000096140344), (0.7275000179515165, 0.7367000205844056))]\n",
      "Image 643 size FeatureMapSize(w=2448, h=3264) has 18 boxes\n",
      "[((0.5494425173811586, 0.1347342088095861), (0.9836513175700058, 0.6938554089834729))]\n",
      "converted_boxes: [((0.5494425173811586, 0.1347342088095861), (0.9836513175700058, 0.6938554089834729))], tpoints: [((0.9082999634586908, 0.4511999990425858), (1.0, 0.6887999889897365))]\n",
      "Image 234 size FeatureMapSize(w=3264, h=2448) has 13 boxes\n",
      "[((0.2160095320562843, 0.0), (0.6754637403245887, 0.46392328909858543)), ((0.875687315062067, 0.1136534751792244), (1.0, 0.9027492414537626)), ((0.6455733583375433, 0.0024367781030480177), (1.0, 0.6850311537721324)), ((0.08418536461528399, 0.0), (0.4376772556789478, 0.7262482558698999)), ((0.4389881724298138, 0.0), (0.8115099759355153, 0.7054264811573807)), ((0.1632061048688294, 0.25575802562969113), (0.9658363818021074, 0.9225608115016358)), ((0.425909099622907, 0.36985817572261115), (0.6673376774953089, 0.8506953215213626)), ((0.18682531836952404, 0.3817167568427035), (0.4185464696025188, 0.8433592622329676)), ((0.31508275267708935, 0.37470318777364797), (0.5345766626935082, 0.8362605775476328)), ((0.5670897944144233, 0.3474613744722503), (0.8166575795233112, 0.8611678078690339)), ((0.7085402138514001, 0.37356701293663397), (0.9837309592865906, 0.8447168833297248))]\n",
      "converted_boxes: [((0.2160095320562843, 0.0), (0.6754637403245887, 0.46392328909858543)), ((0.875687315062067, 0.1136534751792244), (1.0, 0.9027492414537626)), ((0.6455733583375433, 0.0024367781030480177), (1.0, 0.6850311537721324)), ((0.08418536461528399, 0.0), (0.4376772556789478, 0.7262482558698999)), ((0.4389881724298138, 0.0), (0.8115099759355153, 0.7054264811573807)), ((0.1632061048688294, 0.25575802562969113), (0.9658363818021074, 0.9225608115016358)), ((0.425909099622907, 0.36985817572261115), (0.6673376774953089, 0.8506953215213626)), ((0.18682531836952404, 0.3817167568427035), (0.4185464696025188, 0.8433592622329676)), ((0.31508275267708935, 0.37470318777364797), (0.5345766626935082, 0.8362605775476328)), ((0.5670897944144233, 0.3474613744722503), (0.8166575795233112, 0.8611678078690339)), ((0.7085402138514001, 0.37356701293663397), (0.9837309592865906, 0.8447168833297248))], tpoints: [((0.1424999985040403, 0.48670002058440565), (0.24250000598383883, 0.7333000033509498)), ((0.1724999932681813, 0.253300012326708), (0.282500005235859, 0.48330000335094975)), ((0.23999999551212087, 0.49329999537249797), (0.35750000149595973, 0.7699999840430964)), ((0.282500005235859, 0.26669999664905025), (0.377500010471718, 0.48330000335094975)), ((0.377500010471718, 0.27329999636980445), (0.4675000134636374, 0.48330000335094975)), ((0.4675000134636374, 0.27329999636980445), (0.565000010471718, 0.49329999537249797)), ((0.3624999850404029, 0.49329999537249797), (0.47999999102424173, 0.7699999840430964)), ((0.47999999102424173, 0.5), (0.5925000134636375, 0.7666999966490502)), ((0.6000000074797985, 0.4133000093347886), (0.7625000149595971, 0.7799999760646447)), ((0.755000020943436, 0.41670000163558263), (0.9025000029919195, 0.7833000133240146)), ((0.8974999820484835, 0.42000001396229064), (1.0, 0.7833000133240146))]\n",
      "Image 584 size FeatureMapSize(w=2448, h=3264) has 11 boxes\n",
      "[((0.0, 0.07664482698154229), (0.43847703236263474, 0.5824065880191794)), ((0.4513008053069669, 0.13606591698203846), (0.9721627062884911, 0.5576499604187717)), ((0.2646207625908151, 0.13379674475407766), (0.6634316154403628, 0.5890107540280384))]\n",
      "converted_boxes: [((0.0, 0.07664482698154229), (0.43847703236263474, 0.5824065880191794)), ((0.4513008053069669, 0.13606591698203846), (0.9721627062884911, 0.5576499604187717)), ((0.2646207625908151, 0.13379674475407766), (0.6634316154403628, 0.5890107540280384))], tpoints: [((0.23330000335094975, 0.35499999102424173), (0.5732999814102073, 0.47750001795151653)), ((0.22670000363019557, 0.16250000747979856), (0.629999996010774, 0.372499989528282)), ((0.620000003989226, 0.36499999551212087), (0.9900000079784518, 0.4699999865363626))]\n",
      "Image 297 size FeatureMapSize(w=3264, h=2448) has 10 boxes\n",
      "[((0.0, 0.0), (0.2904387863899213, 0.47090619963072555))]\n",
      "converted_boxes: [((0.0, 0.0), (0.2904387863899213, 0.47090619963072555))], tpoints: [((0.31999999401616114, 0.0032999998603770934), (0.47750001795151653, 0.2766999886705985))]\n",
      "已評估 10/50 張圖像，當前平均 IoU: 0.2475\n",
      "Image 32 size FeatureMapSize(w=3264, h=2448) has 26 boxes\n",
      "[((0.20616560444820836, 0.7445990699726953), (0.5137976102410509, 1.0)), ((0.4283717906502598, 0.0), (0.7609522160977193, 0.7542683261463144)), ((0.5047973914730081, 0.7046401660381784), (0.7914978450220121, 1.0))]\n",
      "converted_boxes: [((0.20616560444820836, 0.7445990699726953), (0.5137976102410509, 1.0)), ((0.4283717906502598, 0.0), (0.7609522160977193, 0.7542683261463144)), ((0.5047973914730081, 0.7046401660381784), (0.7914978450220121, 1.0))], tpoints: [((0.0, 0.23669999565174377), (0.09999999813005037, 0.316700006622115)), ((0.0012000000067785674, 0.310000001994613), (0.09000000299191942, 0.435000001994613)), ((0.0012000000067785674, 0.4317000146005668), (0.07249999981300503, 0.5567000146005668))]\n",
      "Image 545 size FeatureMapSize(w=3264, h=2448) has 15 boxes\n",
      "[((0.41003460256387125, 0.5354527333225076), (0.6539379939196016, 0.9237667609399057)), ((0.6976766608328522, 0.0), (0.9888332446232679, 0.23406573641382794)), ((0.2013234761790921, 0.5129853117181485), (0.431003491267321, 0.8762590439159931)), ((0.6010647745110421, 0.32962562378963384), (0.8641341916408054, 0.8227870785520112))]\n",
      "converted_boxes: [((0.41003460256387125, 0.5354527333225076), (0.6539379939196016, 0.9237667609399057)), ((0.6976766608328522, 0.0), (0.9888332446232679, 0.23406573641382794)), ((0.2013234761790921, 0.5129853117181485), (0.431003491267321, 0.8762590439159931)), ((0.6010647745110421, 0.32962562378963384), (0.8641341916408054, 0.8227870785520112))], tpoints: [((0.47500000747979854, 0.5933000153186274), (0.6025000179515165, 0.9066999846813726)), ((0.37000001645555686, 0.5732999814102073), (0.47750001795151653, 0.8567000245736316)), ((0.26000000448787913, 0.566700006622115), (0.372499989528282, 0.8732999913832721)), ((0.14499999962601007, 0.5732999814102073), (0.2650000067318187, 0.8767000086167279))]\n",
      "Image 318 size FeatureMapSize(w=3264, h=2448) has 37 boxes\n",
      "[((0.31565613779680285, 0.0), (0.6362615501632867, 0.6651687915734459)), ((0.7291238621806437, 0.007843346481969304), (1.0, 0.6810910736624326))]\n",
      "converted_boxes: [((0.31565613779680285, 0.0), (0.6362615501632867, 0.6651687915734459)), ((0.7291238621806437, 0.007843346481969304), (1.0, 0.6810910736624326))], tpoints: [((0.004999999906502518, 0.6267000086167279), (0.09000000299191942, 0.6999999900269352)), ((0.03250000056098489, 0.7066999946544373), (0.157500005235859, 0.8367000405305351))]\n",
      "Image 32 size FeatureMapSize(w=3264, h=2448) has 26 boxes\n",
      "[((0.024624566833637052, 0.0), (0.3785670326708646, 0.6499649294529446)), ((0.5137696651608509, 0.16502447326519198), (0.8109736982173787, 0.7058752939460643)), ((0.6164856661825202, 0.0), (0.9468333043897951, 0.5380970262581793)), ((0.37491810294276845, 0.0), (0.6701576990563655, 0.5038605793519053))]\n",
      "converted_boxes: [((0.024624566833637052, 0.0), (0.3785670326708646, 0.6499649294529446)), ((0.5137696651608509, 0.16502447326519198), (0.8109736982173787, 0.7058752939460643)), ((0.6164856661825202, 0.0), (0.9468333043897951, 0.5380970262581793)), ((0.37491810294276845, 0.0), (0.6701576990563655, 0.5038605793519053))], tpoints: [((0.47999999102424173, 0.14000000049865324), (0.5974999970080805, 0.3499999950134676)), ((0.47500000747979854, 0.3432999903859656), (0.5949999865363625, 0.560000001994613)), ((0.5925000134636375, 0.13329999587115118), (0.7099999820484835, 0.3499999950134676)), ((0.5949999865363625, 0.3467000076194215), (0.7200000239353553, 0.560000001994613))]\n",
      "Image 213 size FeatureMapSize(w=3264, h=2448) has 16 boxes\n",
      "[((0.03796665112361071, 0.37694642945745527), (0.45087522722557016, 0.960058011120333)), ((0.6343232963156755, 0.5672453306930813), (0.9018721018872691, 0.8632061659509719)), ((0.7777881930661807, 0.5849561449011259), (1.0, 0.9248892627742494))]\n",
      "converted_boxes: [((0.03796665112361071, 0.37694642945745527), (0.45087522722557016, 0.960058011120333)), ((0.6343232963156755, 0.5672453306930813), (0.9018721018872691, 0.8632061659509719)), ((0.7777881930661807, 0.5849561449011259), (1.0, 0.9248892627742494))], tpoints: [((0.7350000119676777, 0.5833000232970792), (0.8224999670888863, 0.8667000165951797)), ((0.8274999880323223, 0.6000000199461295), (0.9650000029919195, 0.9232999514910131)), ((0.9474999670888863, 0.5699999940161612), (1.0, 0.8650000079784518))]\n",
      "Image 369 size FeatureMapSize(w=3264, h=2448) has 17 boxes\n",
      "[((0.3833070539161735, 0.05345439250144342), (0.6457826116619154, 0.46563443484170514)), ((0.20624369561809866, 0.0695292389879234), (0.5234142417995814, 1.0)), ((0.0, 0.38300408648930667), (0.17197405878996463, 0.7917648679573229)), ((0.0, 0.029406916829051194), (0.14692186703582835, 0.4472096173739415))]\n",
      "converted_boxes: [((0.3833070539161735, 0.05345439250144342), (0.6457826116619154, 0.46563443484170514)), ((0.20624369561809866, 0.0695292389879234), (0.5234142417995814, 1.0)), ((0.0, 0.38300408648930667), (0.17197405878996463, 0.7917648679573229)), ((0.0, 0.029406916829051194), (0.14692186703582835, 0.4472096173739415))], tpoints: [((0.0, 0.10669999964096967), (0.18500000822777843, 0.22999999102424173)), ((0.0, 0.22670000363019557), (0.16749999102424173, 0.3366999906652114)), ((0.24250000598383883, 0.18669999814500995), (0.39500000897575827, 0.33000001097037124)), ((0.440000010471718, 0.1733000013563368), (0.5900000029919195, 0.33329999836441737))]\n",
      "Image 118 size FeatureMapSize(w=2448, h=3264) has 12 boxes\n",
      "[((0.2559339891863934, 0.6527783259508516), (0.6858190194380293, 1.0)), ((0.5541444327667918, 0.6711014886375938), (0.9802947128801001, 1.0))]\n",
      "converted_boxes: [((0.2559339891863934, 0.6527783259508516), (0.6858190194380293, 1.0)), ((0.5541444327667918, 0.6711014886375938), (0.9802947128801001, 1.0))], tpoints: [((0.35330000734017564, 0.6800000059838388), (0.6666999767029208, 1.0)), ((0.6399999880323223, 0.6775000329111137), (0.9767000285628574, 1.0))]\n",
      "Image 433 size FeatureMapSize(w=3264, h=2448) has 10 boxes\n",
      "[((0.6846578479088482, 0.2787093352684156), (0.9825711503590502, 0.9546755466945728))]\n",
      "converted_boxes: [((0.6846578479088482, 0.2787093352684156), (0.9825711503590502, 0.9546755466945728))], tpoints: [((0.8624999850404029, 0.7933000053455627), (1.0, 0.9733000113294016))]\n",
      "Image 613 size FeatureMapSize(w=2448, h=3264) has 8 boxes\n",
      "[((0.0038281823232414356, 0.3225368297127598), (0.42958112309949964, 0.7708827628825058)), ((0.1848049853929104, 0.6542833429561201), (0.4869378187548114, 0.9082795246644053)), ((0.0, 0.6389408243721132), (0.18171197364108208, 0.977347499503825))]\n",
      "converted_boxes: [((0.0038281823232414356, 0.3225368297127598), (0.42958112309949964, 0.7708827628825058)), ((0.1848049853929104, 0.6542833429561201), (0.4869378187548114, 0.9082795246644053)), ((0.0, 0.6389408243721132), (0.18171197364108208, 0.977347499503825))], tpoints: [((0.18669999814500995, 0.6624999700808057), (0.46330001930785336, 0.9174999910242417)), ((0.4666999866759855, 0.6500000299191943), (0.7233000113294016, 0.8600000119676777)), ((0.6999999900269352, 0.6399999880323223), (0.9266999687244689, 0.8624999850404029))]\n",
      "Image 378 size FeatureMapSize(w=2448, h=3264) has 11 boxes\n",
      "[((0.18083712465493287, 0.6852453641473009), (0.4790904079610518, 0.9577487302432159)), ((0.38551056871421524, 0.5849020872050015), (0.7702158398587856, 1.0))]\n",
      "converted_boxes: [((0.18083712465493287, 0.6852453641473009), (0.4790904079610518, 0.9577487302432159)), ((0.38551056871421524, 0.5849020872050015), (0.7702158398587856, 1.0))], tpoints: [((0.26330000434825623, 0.6525000029919195), (0.4432999853994332, 0.932499979056564)), ((0.41670000163558263, 0.6749999850404029), (0.6232999913832721, 0.9874999850404029))]\n",
      "已評估 20/50 張圖像，當前平均 IoU: 0.2329\n",
      "Image 171 size FeatureMapSize(w=3264, h=2448) has 19 boxes\n",
      "[((0.0, 0.06651384854335066), (0.15426110670693202, 0.4313303277160316)), ((0.0, 0.23804819813317937), (0.3352160729106524, 0.9079805980561971)), ((0.3164412782594183, 0.0), (0.6383425952655889, 0.3198211646428743))]\n",
      "converted_boxes: [((0.0, 0.06651384854335066), (0.15426110670693202, 0.4313303277160316)), ((0.0, 0.23804819813317937), (0.3352160729106524, 0.9079805980561971)), ((0.3164412782594183, 0.0), (0.6383425952655889, 0.3198211646428743))], tpoints: [((0.25, 0.009999999813005036), (0.375, 0.23330000335094975)), ((0.375, 0.009999999813005036), (0.4874999850404029, 0.253300012326708)), ((0.4874999850404029, 0.01999999962601007), (0.6075000014959597, 0.253300012326708))]\n",
      "Image 611 size FeatureMapSize(w=3264, h=2448) has 3 boxes\n",
      "[((0.3398226414211353, 0.5416301113536856), (0.5714608560258191, 0.909821801776607)), ((0.4778806056491772, 0.5332383646976039), (0.7694924863326357, 1.0)), ((0.6802355477771362, 0.4687255671429946), (0.9609422925988741, 0.9357338803286182))]\n",
      "converted_boxes: [((0.3398226414211353, 0.5416301113536856), (0.5714608560258191, 0.909821801776607)), ((0.4778806056491772, 0.5332383646976039), (0.7694924863326357, 1.0)), ((0.6802355477771362, 0.4687255671429946), (0.9609422925988741, 0.9357338803286182))], tpoints: [((0.6800000059838388, 0.46330001930785336), (0.9724999970080805, 0.8767000086167279)), ((0.5149999880323223, 0.5500000099730648), (0.7099999820484835, 0.870000003989226)), ((0.26749999850404027, 0.5099999920215482), (0.5249999925202015, 0.8767000086167279))]\n",
      "Image 606 size FeatureMapSize(w=2448, h=3264) has 11 boxes\n",
      "[((0.0, 0.3538797215556438), (0.3332795575547897, 0.7600641757181005))]\n",
      "converted_boxes: [((0.0, 0.3538797215556438), (0.3332795575547897, 0.7600641757181005))], tpoints: [((0.7833000133240146, 0.5049999835444432), (1.0, 0.6800000059838388))]\n",
      "Image 163 size FeatureMapSize(w=2448, h=3264) has 19 boxes\n",
      "[((0.65140223925255, 0.4164043188645713), (1.0, 0.715224197775332))]\n",
      "converted_boxes: [((0.65140223925255, 0.4164043188645713), (1.0, 0.715224197775332))], tpoints: [((0.7266999786975337, 0.4050000134636374), (0.9800000159569036, 0.6674999910242417))]\n",
      "Image 413 size FeatureMapSize(w=3264, h=2448) has 5 boxes\n",
      "[((0.17922929583190494, 0.02916987112983545), (0.47693991716133805, 0.5336802235192937)), ((0.0, 0.045085622128199575), (0.26815475217189305, 0.499466611937067)), ((0.37542851472286376, 0.058306969340899246), (0.6648039432375866, 0.5336682890083718))]\n",
      "converted_boxes: [((0.17922929583190494, 0.02916987112983545), (0.47693991716133805, 0.5336802235192937)), ((0.0, 0.045085622128199575), (0.26815475217189305, 0.499466611937067)), ((0.37542851472286376, 0.058306969340899246), (0.6648039432375866, 0.5336682890083718))], tpoints: [((0.042500000373989925, 0.0032999998603770934), (0.22749999925202014, 0.4666999866759855)), ((0.22749999925202014, 0.0032999998603770934), (0.42250001196767767, 0.4700000239353554)), ((0.41749999102424173, 0.0), (0.6124999850404029, 0.4733000113294015))]\n",
      "Image 131 size FeatureMapSize(w=3264, h=2448) has 13 boxes\n",
      "[((0.12319523412691252, 0.5819521251323133), (0.2913107222277353, 0.9591340732354214)), ((0.0, 0.5861396818917196), (0.1164794287560443, 0.994538692624134))]\n",
      "converted_boxes: [((0.12319523412691252, 0.5819521251323133), (0.2913107222277353, 0.9591340732354214)), ((0.0, 0.5861396818917196), (0.1164794287560443, 0.994538692624134))], tpoints: [((0.0, 0.6767000185897927), (0.13500000448787913, 0.9967000126059539)), ((0.1399999973820705, 0.620000003989226), (0.27250000074797986, 1.0))]\n",
      "Image 168 size FeatureMapSize(w=3264, h=2448) has 27 boxes\n",
      "[((0.28270270367417544, 0.3286058809135032), (0.6398948334656467, 1.0)), ((0.4719564600849812, 0.8286905266671478), (0.7096228478411879, 1.0)), ((0.12268298988254187, 0.48971137090129424), (0.30434412438654734, 0.8050840640637028)), ((0.5233765705628428, 0.14653889081219326), (0.7528784489796839, 0.4751367488212086))]\n",
      "converted_boxes: [((0.28270270367417544, 0.3286058809135032), (0.6398948334656467, 1.0)), ((0.4719564600849812, 0.8286905266671478), (0.7096228478411879, 1.0)), ((0.12268298988254187, 0.48971137090129424), (0.30434412438654734, 0.8050840640637028)), ((0.5233765705628428, 0.14653889081219326), (0.7528784489796839, 0.4751367488212086))], tpoints: [((0.17749999551212087, 0.5), (0.282500005235859, 0.7400000079784518)), ((0.35000000747979854, 0.5032999873940461), (0.434999989528282, 0.7833000133240146)), ((0.43000000598383886, 0.5032999873940461), (0.5074999940161612, 0.7833000133240146)), ((0.5, 0.4800000159569036), (0.5774999880323223, 0.7799999760646447))]\n",
      "Image 88 size FeatureMapSize(w=3264, h=2448) has 5 boxes\n",
      "[((0.2153094954633823, 0.0), (0.6019543654373557, 0.7668192968449288)), ((0.47948647866898814, 0.5984980558963626), (0.7933616726282837, 1.0)), ((0.5550092736788215, 0.0951556410580254), (0.9517927984717812, 1.0)), ((0.38530514477031613, 0.2576118921481067), (0.6952432892339059, 0.8857560014614607)), ((0.0965387639492819, 0.3743105940492085), (0.553048536904139, 1.0))]\n",
      "converted_boxes: [((0.2153094954633823, 0.0), (0.6019543654373557, 0.7668192968449288)), ((0.47948647866898814, 0.5984980558963626), (0.7933616726282837, 1.0)), ((0.5550092736788215, 0.0951556410580254), (0.9517927984717812, 1.0)), ((0.38530514477031613, 0.2576118921481067), (0.6952432892339059, 0.8857560014614607)), ((0.0965387639492819, 0.3743105940492085), (0.553048536904139, 1.0))], tpoints: [((0.007499999859753777, 0.5199999840430964), (0.32749998803232233, 1.0)), ((0.30249999551212087, 0.31999999401616114), (0.6324999940161612, 0.8067000146005668)), ((0.4375, 0.6633000093347886), (0.7299999910242417, 1.0)), ((0.7024999880323223, 0.5266999886705984), (0.9850000119676777, 0.9800000159569036)), ((0.5900000029919195, 0.316700006622115), (0.8474999970080805, 0.6666999767029208))]\n",
      "Image 237 size FeatureMapSize(w=3264, h=2448) has 17 boxes\n",
      "[((0.40697029941902424, 0.0), (0.7368214807664549, 0.4127372994250385)), ((0.0, 0.43181320554573227), (0.1577632278548102, 0.7966470226496344)), ((0.13888567424536302, 0.20834691236347672), (0.5001066000852519, 0.937876265997883)), ((0.6020402093407188, 0.607762995272806), (0.9101831731289693, 1.0)), ((0.8537909175176819, 0.18722010282849788), (1.0, 0.610624975567143)), ((0.6673774278742062, 0.26944218753758903), (0.9834442491068851, 0.8597676172175712)), ((0.44509422531304127, 0.602559172620766), (0.6652898986675447, 1.0)), ((0.4443236740852338, 0.28264760640697173), (0.8265191974595842, 0.8479509478444958)), ((0.02653314885586569, 0.17917121493697075), (0.30599298983743506, 0.6637943024081023)), ((0.0, 0.2743572561074625), (0.14549119698257976, 0.5939429725840791))]\n",
      "converted_boxes: [((0.40697029941902424, 0.0), (0.7368214807664549, 0.4127372994250385)), ((0.0, 0.43181320554573227), (0.1577632278548102, 0.7966470226496344)), ((0.13888567424536302, 0.20834691236347672), (0.5001066000852519, 0.937876265997883)), ((0.6020402093407188, 0.607762995272806), (0.9101831731289693, 1.0)), ((0.8537909175176819, 0.18722010282849788), (1.0, 0.610624975567143)), ((0.6673774278742062, 0.26944218753758903), (0.9834442491068851, 0.8597676172175712)), ((0.44509422531304127, 0.602559172620766), (0.6652898986675447, 1.0)), ((0.4443236740852338, 0.28264760640697173), (0.8265191974595842, 0.8479509478444958)), ((0.02653314885586569, 0.17917121493697075), (0.30599298983743506, 0.6637943024081023)), ((0.0, 0.2743572561074625), (0.14549119698257976, 0.5939429725840791))], tpoints: [((0.46249999252020146, 0.3066999896679049), (0.5400000179515165, 0.48330000335094975)), ((0.45499999850404027, 0.10330000110701018), (0.5224999820484835, 0.26330000434825623)), ((0.5300000134636375, 0.10330000110701018), (0.6000000074797985, 0.27329999636980445)), ((0.6025000179515165, 0.10999999950134676), (0.682499979056564, 0.2832999883913526)), ((0.6749999850404029, 0.10330000110701018), (0.7425000059838388, 0.26669999664905025)), ((0.5475000119676777, 0.33000001097037124), (0.6399999880323223, 0.5266999886705984)), ((0.6349999670888863, 0.3366999906652114), (0.7200000239353553, 0.5199999840430964)), ((0.7174999760646447, 0.3366999906652114), (0.8199999940161612, 0.5433000053455627)), ((0.8325000089757583, 0.2599999920215482), (0.9599999820484835, 0.5433000053455627)), ((0.9474999670888863, 0.25670000462750203), (1.0, 0.5467000225790186))]\n",
      "Image 32 size FeatureMapSize(w=3264, h=2448) has 26 boxes\n",
      "[((0.0, 0.2612364829917244), (0.21843911538773816, 0.7100983253343919)), ((0.4919636926805175, 0.2711312967231404), (0.7223827899465936, 0.7117119275945438))]\n",
      "converted_boxes: [((0.0, 0.2612364829917244), (0.21843911538773816, 0.7100983253343919)), ((0.4919636926805175, 0.2711312967231404), (0.7223827899465936, 0.7117119275945438))], tpoints: [((0.0, 0.8533000073401756), (0.1550000041138892, 1.0)), ((0.004999999906502518, 0.7367000205844056), (0.1424999985040403, 0.8500000199461295))]\n",
      "已評估 30/50 張圖像，當前平均 IoU: 0.2427\n",
      "Image 565 size FeatureMapSize(w=3264, h=2448) has 14 boxes\n",
      "[((0.03477689465529374, 0.5014353363765397), (0.33682814811724165, 1.0)), ((0.33379577213842376, 0.5762913140817456), (0.6087190482688005, 0.9688994163178406))]\n",
      "converted_boxes: [((0.03477689465529374, 0.5014353363765397), (0.33682814811724165, 1.0)), ((0.33379577213842376, 0.5762913140817456), (0.6087190482688005, 0.9688994163178406))], tpoints: [((0.35000000747979854, 0.7233000113294016), (0.5949999865363625, 0.8600000119676777)), ((0.38500000448787913, 0.5966999826867596), (0.5524999955121208, 0.6867000106113409))]\n",
      "Image 594 size FeatureMapSize(w=3264, h=2448) has 21 boxes\n",
      "[((0.0, 0.1550016689520785), (0.5531840687811237, 0.9485005179765685)), ((0.4303956769630485, 0.35003847705115715), (0.6770125955136764, 0.8051250360854504)), ((0.7352459843659787, 0.28574733719447654), (1.0, 0.9956462528266936)), ((0.5038983563077367, 0.662955503632602), (0.6913992020604792, 1.0)), ((0.08502355844264217, 0.3913640469381495), (0.27248754347169096, 0.7680158020442408)), ((0.6216043027388857, 0.6000729414754138), (0.9017379091187933, 1.0)), ((0.614205234871175, 0.12045659277418928), (0.9427150523690098, 0.6762685915247305)), ((0.0, 0.4350413967775693), (0.17031483286798138, 0.8573669950442648)), ((0.5565281398852483, 0.37127943971324096), (0.8073242751335161, 0.7712139220674558))]\n",
      "converted_boxes: [((0.0, 0.1550016689520785), (0.5531840687811237, 0.9485005179765685)), ((0.4303956769630485, 0.35003847705115715), (0.6770125955136764, 0.8051250360854504)), ((0.7352459843659787, 0.28574733719447654), (1.0, 0.9956462528266936)), ((0.5038983563077367, 0.662955503632602), (0.6913992020604792, 1.0)), ((0.08502355844264217, 0.3913640469381495), (0.27248754347169096, 0.7680158020442408)), ((0.6216043027388857, 0.6000729414754138), (0.9017379091187933, 1.0)), ((0.614205234871175, 0.12045659277418928), (0.9427150523690098, 0.6762685915247305)), ((0.0, 0.4350413967775693), (0.17031483286798138, 0.8573669950442648)), ((0.5565281398852483, 0.37127943971324096), (0.8073242751335161, 0.7712139220674558))], tpoints: [((0.5249999925202015, 0.6932999853994332), (0.6549999760646447, 0.9800000159569036)), ((0.6549999760646447, 0.6932999853994332), (0.7775000029919195, 0.9733000113294016)), ((0.7750000299191943, 0.6867000106113409), (0.9099999970080805, 0.9700000239353553)), ((0.9075000239353553, 0.6867000106113409), (1.0, 0.9667000365413092)), ((0.5200000089757583, 0.4432999853994332), (0.6525000029919195, 0.6999999900269352)), ((0.6500000299191943, 0.439999998005387), (0.7750000299191943, 0.6999999900269352)), ((0.6375000149595971, 0.18669999814500995), (0.7700000089757583, 0.4432999853994332)), ((0.7700000089757583, 0.4367000106113409), (0.9025000029919195, 0.6967000026328891)), ((0.9000000299191943, 0.433299993377885), (1.0, 0.6967000026328891))]\n",
      "Image 431 size FeatureMapSize(w=2448, h=3264) has 8 boxes\n",
      "[((0.5979947390420516, 0.34429367805463335), (1.0, 0.7833423922849307)), ((0.06397950346420324, 0.623173033117422), (0.44119142880340645, 1.0)), ((0.24562073928562836, 0.2416605960414261), (0.687408799662601, 0.7145628191307015)), ((0.285613214905396, 0.6176463208628031), (0.7090996792905601, 1.0))]\n",
      "converted_boxes: [((0.5979947390420516, 0.34429367805463335), (1.0, 0.7833423922849307)), ((0.06397950346420324, 0.623173033117422), (0.44119142880340645, 1.0)), ((0.24562073928562836, 0.2416605960414261), (0.687408799662601, 0.7145628191307015)), ((0.285613214905396, 0.6176463208628031), (0.7090996792905601, 1.0))], tpoints: [((0.0, 0.7949999640969669), (0.3132999893886591, 0.9850000119676777)), ((0.0, 0.7099999820484835), (0.33329999836441737, 0.8025000329111137)), ((0.3132999893886591, 0.807499979056564), (0.7200000239353553, 0.9824999640969669)), ((0.316700006622115, 0.7200000239353553), (0.6666999767029208, 0.8125))]\n",
      "Image 649 size FeatureMapSize(w=2448, h=3264) has 14 boxes\n",
      "[((0.8022582162059757, 0.13894677988100823), (1.0, 0.40322322713310116))]\n",
      "converted_boxes: [((0.8022582162059757, 0.13894677988100823), (1.0, 0.40322322713310116))], tpoints: [((0.8299999860377093, 0.1724999932681813), (0.9833000033509498, 0.39999999252020146))]\n",
      "Image 472 size FeatureMapSize(w=2448, h=3264) has 9 boxes\n",
      "[((0.4608220077643861, 0.7147770764921334), (0.8689389599571786, 1.0)), ((0.32690535406592813, 0.1964264620809577), (0.818382774159209, 0.6263276908469255))]\n",
      "converted_boxes: [((0.4608220077643861, 0.7147770764921334), (0.8689389599571786, 1.0)), ((0.32690535406592813, 0.1964264620809577), (0.818382774159209, 0.6263276908469255))], tpoints: [((0.35669999964096966, 0.8875000149595971), (0.8299999860377093, 1.0)), ((0.3732999913832721, 0.7350000119676777), (0.8266999986436632, 0.8450000239353553))]\n",
      "Image 94 size FeatureMapSize(w=2448, h=3264) has 7 boxes\n",
      "[((0.26057465797759094, 0.20846716195826717), (0.6118426245850174, 0.5078689892352591)), ((0.04085869088000385, 0.013295004053974812), (0.5441619191746054, 0.5496709880872908))]\n",
      "converted_boxes: [((0.26057465797759094, 0.20846716195826717), (0.6118426245850174, 0.5078689892352591)), ((0.04085869088000385, 0.013295004053974812), (0.5441619191746054, 0.5496709880872908))], tpoints: [((0.030000000997306476, 0.0775000020569446), (0.5067000046275021, 0.38999998803232233)), ((0.45169999864366317, 0.22999999102424173), (0.6633000093347886, 0.38120000502642465))]\n",
      "Image 642 size FeatureMapSize(w=2448, h=3264) has 19 boxes\n",
      "[((0.22147837485415464, 0.2791335742413034), (0.6296258916113356, 0.7992560758877021)), ((0.0, 0.33920982307980296), (0.21927218183909497, 0.7792087757559902))]\n",
      "converted_boxes: [((0.22147837485415464, 0.2791335742413034), (0.6296258916113356, 0.7992560758877021)), ((0.0, 0.33920982307980296), (0.21927218183909497, 0.7792087757559902))], tpoints: [((0.0032999998603770934, 0.35250001795151653), (0.2400000079784518, 0.5674999835444432)), ((0.0, 0.5725000044878792), (0.25, 0.6974999670888863))]\n",
      "Image 480 size FeatureMapSize(w=3264, h=2448) has 13 boxes\n",
      "[((0.8011804452944573, 0.0), (1.0, 0.48192278690940143)), ((0.28242466246008047, 0.059254964192708336), (0.5907231214140084, 0.6515376536638761)), ((0.879258224099668, 0.22875415076651512), (1.0, 0.6264140985854504)), ((0.43089706738055716, 0.08329149206571161), (1.0, 0.7149269156863453)), ((0.5095164098585451, 0.3925459629026535), (0.7640564105802541, 0.7477529289357198)), ((0.7110405408757938, 0.21654911643271266), (0.968590293690459, 0.5995272899977145))]\n",
      "converted_boxes: [((0.8011804452944573, 0.0), (1.0, 0.48192278690940143)), ((0.28242466246008047, 0.059254964192708336), (0.5907231214140084, 0.6515376536638761)), ((0.879258224099668, 0.22875415076651512), (1.0, 0.6264140985854504)), ((0.43089706738055716, 0.08329149206571161), (1.0, 0.7149269156863453)), ((0.5095164098585451, 0.3925459629026535), (0.7640564105802541, 0.7477529289357198)), ((0.7110405408757938, 0.21654911643271266), (0.968590293690459, 0.5995272899977145))], tpoints: [((0.7324999640969669, 0.5132999794155944), (0.9625000299191943, 0.6132999993617239)), ((0.5349999970080805, 0.5299999760646447), (0.7324999640969669, 0.6267000086167279)), ((0.7224999970080805, 0.3732999913832721), (0.942500020943436, 0.5199999840430964)), ((0.7075000089757583, 0.253300012326708), (0.9150000179515165, 0.39330000035903034)), ((0.5375000074797985, 0.4067000096140344), (0.7224999970080805, 0.5299999760646447)), ((0.5475000119676777, 0.2800000009973065), (0.7099999820484835, 0.4133000093347886))]\n",
      "Image 317 size FeatureMapSize(w=2448, h=3264) has 19 boxes\n",
      "[((0.4875909278170708, 0.43994390826852986), (0.9005245358508949, 0.6978757651243144)), ((0.761974449245814, 0.11031863981251354), (1.0, 0.3750087394450058)), ((0.0, 0.43792308780943273), (0.20789751224649972, 0.6688312063591585))]\n",
      "converted_boxes: [((0.4875909278170708, 0.43994390826852986), (0.9005245358508949, 0.6978757651243144)), ((0.761974449245814, 0.11031863981251354), (1.0, 0.3750087394450058)), ((0.0, 0.43792308780943273), (0.20789751224649972, 0.6688312063591585))], tpoints: [((0.41670000163558263, 0.21500000299191943), (0.5467000225790186, 0.33749999252020146)), ((0.6767000185897927, 0.1550000041138892), (0.8400000279245813, 0.3400000029919194)), ((0.8500000199461295, 0.14499999962601007), (1.0, 0.3400000029919194))]\n",
      "Image 664 size FeatureMapSize(w=3264, h=2448) has 5 boxes\n",
      "[((0.2636978114174365, 0.33673955551746537), (0.5551924848666643, 0.9582500736744611)), ((0.0770273186593353, 0.3461942254258083), (0.3435895536568093, 1.0))]\n",
      "converted_boxes: [((0.2636978114174365, 0.33673955551746537), (0.5551924848666643, 0.9582500736744611)), ((0.0770273186593353, 0.3461942254258083), (0.3435895536568093, 1.0))], tpoints: [((0.09000000299191942, 0.42000001396229064), (0.32250000448787913, 0.8767000086167279)), ((0.32749998803232233, 0.439999998005387), (0.5224999820484835, 0.8467000325520834))]\n",
      "已評估 40/50 張圖像，當前平均 IoU: 0.2398\n",
      "Image 186 size FeatureMapSize(w=2448, h=3264) has 15 boxes\n",
      "[((0.3380475121337327, 0.2080849169583574), (0.780160529508877, 0.5602303520361215)), ((0.0, 0.7023694608833718), (0.3417276172476424, 1.0)), ((0.0, 0.1581043128879186), (0.3924755304937091, 0.5807099022986432))]\n",
      "converted_boxes: [((0.3380475121337327, 0.2080849169583574), (0.780160529508877, 0.5602303520361215)), ((0.0, 0.7023694608833718), (0.3417276172476424, 1.0)), ((0.0, 0.1581043128879186), (0.3924755304937091, 0.5807099022986432))], tpoints: [((0.0, 0.7099999820484835), (0.10999999950134676, 1.0)), ((0.10669999964096967, 0.7024999880323223), (0.23330000335094975, 1.0)), ((0.22999999102424173, 0.7075000089757583), (0.36000001196767767, 1.0))]\n",
      "Image 153 size FeatureMapSize(w=3264, h=2448) has 10 boxes\n",
      "[((0.7253054295070728, 0.06530341191691927), (0.9825294265570872, 0.5287777707611624)), ((0.38464672626028434, 0.12523056159485663), (0.6474169583573903, 0.5657939720006977)), ((0.6125016069302107, 0.09938898593118504), (0.8395690213174798, 0.5006146742987394)), ((0.22029415068945762, 0.09424394309474836), (0.4508881954342884, 0.49460597695342573))]\n",
      "converted_boxes: [((0.7253054295070728, 0.06530341191691927), (0.9825294265570872, 0.5287777707611624)), ((0.38464672626028434, 0.12523056159485663), (0.6474169583573903, 0.5657939720006977)), ((0.6125016069302107, 0.09938898593118504), (0.8395690213174798, 0.5006146742987394)), ((0.22029415068945762, 0.09424394309474836), (0.4508881954342884, 0.49460597695342573))], tpoints: [((0.220000005235859, 0.09330000285229652), (0.4249999850404029, 0.4566999946544373)), ((0.42000000149595973, 0.15330000484690948), (0.5925000134636375, 0.45999998204848347)), ((0.6025000179515165, 0.10669999964096967), (0.807499979056564, 0.46330001930785336)), ((0.7825000239353553, 0.16329999686845767), (0.942500020943436, 0.4700000239353554))]\n",
      "Image 354 size FeatureMapSize(w=2448, h=3264) has 25 boxes\n",
      "[((0.0, 0.6217760610250073), (0.17135092696380028, 0.846392483964528)), ((0.4840663002489896, 0.0), (0.9532335382686201, 0.3008886958379944))]\n",
      "converted_boxes: [((0.0, 0.6217760610250073), (0.17135092696380028, 0.846392483964528)), ((0.4840663002489896, 0.0), (0.9532335382686201, 0.3008886958379944))], tpoints: [((0.7900000179515165, 0.7224999970080805), (0.9366999607460171, 1.0)), ((0.9266999687244689, 0.7200000239353553), (1.0, 1.0))]\n",
      "Image 466 size FeatureMapSize(w=3264, h=2448) has 13 boxes\n",
      "[((0.7085551554831842, 0.5415928042604888), (0.9530907470139289, 0.9954637581793687))]\n",
      "converted_boxes: [((0.7085551554831842, 0.5415928042604888), (0.9530907470139289, 0.9954637581793687))], tpoints: [((0.7275000179515165, 0.6232999913832721), (0.9300000059838388, 0.9767000285628574))]\n",
      "Image 277 size FeatureMapSize(w=2448, h=3264) has 8 boxes\n",
      "[((0.35360830540469834, 0.765292337254619), (0.7482966539766166, 1.0)), ((0.21765625375890107, 0.1275481120543447), (0.6669421001431389, 0.6622390570871824))]\n",
      "converted_boxes: [((0.35360830540469834, 0.765292337254619), (0.7482966539766166, 1.0)), ((0.21765625375890107, 0.1275481120543447), (0.6669421001431389, 0.6622390570871824))], tpoints: [((0.30000000997306475, 0.682499979056564), (0.7799999760646447, 0.807499979056564)), ((0.310000001994613, 0.8574999640969669), (0.8567000245736316, 1.0))]\n",
      "Image 448 size FeatureMapSize(w=3264, h=2448) has 12 boxes\n",
      "[((0.7180130674437067, 0.14688960802931342), (1.0, 0.7354538046093149)), ((0.6929845655762846, 0.5488390258131255), (0.9894366892050376, 1.0))]\n",
      "converted_boxes: [((0.7180130674437067, 0.14688960802931342), (1.0, 0.7354538046093149)), ((0.6929845655762846, 0.5488390258131255), (0.9894366892050376, 1.0))], tpoints: [((0.06500000112196978, 0.7933000053455627), (0.4074999865363626, 0.8899999880323223)), ((0.07999999850404028, 0.5966999826867596), (0.41250000747979854, 0.6767000185897927))]\n",
      "Image 589 size FeatureMapSize(w=2448, h=3264) has 8 boxes\n",
      "[((0.2554320819199865, 0.33061979439186995), (0.6354488992434084, 0.8943223490726039)), ((0.3152865438483329, 0.19155180757095303), (0.5226316855814569, 0.6167798471781177)), ((0.0, 0.36513450569699046), (0.40068381928406466, 0.6492668310434108)), ((0.47759986272493266, 0.25650861356880594), (1.0, 0.5957585922840286))]\n",
      "converted_boxes: [((0.2554320819199865, 0.33061979439186995), (0.6354488992434084, 0.8943223490726039)), ((0.3152865438483329, 0.19155180757095303), (0.5226316855814569, 0.6167798471781177)), ((0.0, 0.36513450569699046), (0.40068381928406466, 0.6492668310434108)), ((0.47759986272493266, 0.25650861356880594), (1.0, 0.5957585922840286))], tpoints: [((0.0, 0.37999998354444314), (0.43000000598383886, 0.5849999820484835)), ((0.0, 0.18500000822777843), (0.41670000163558263, 0.3624999850404029)), ((0.4267000185897927, 0.3250000149595971), (0.9900000079784518, 0.5149999880323223)), ((0.4432999853994332, 0.13749999626010073), (1.0, 0.33250000897575827))]\n",
      "Image 210 size FeatureMapSize(w=3264, h=2448) has 18 boxes\n",
      "[((0.0, 0.0822906846537601), (0.39817626812166207, 0.5019345184396651)), ((0.5113575430995597, 0.0), (0.7835226080984772, 0.7699486759646844)), ((0.3287280921847936, 0.2527768411849259), (0.6287457684171117, 0.797866598104311)), ((0.0, 0.4815550724114704), (0.2029032718226761, 0.8728674814460643))]\n",
      "converted_boxes: [((0.0, 0.0822906846537601), (0.39817626812166207, 0.5019345184396651)), ((0.5113575430995597, 0.0), (0.7835226080984772, 0.7699486759646844)), ((0.3287280921847936, 0.2527768411849259), (0.6287457684171117, 0.797866598104311)), ((0.0, 0.4815550724114704), (0.2029032718226761, 0.8728674814460643))], tpoints: [((0.12249999887803022, 0.6967000026328891), (0.19250000224393957, 0.9633000193078534)), ((0.1875, 0.7032999774209814), (0.2650000067318187, 0.9800000159569036)), ((0.46249999252020146, 0.7166999866759854), (0.5249999925202015, 0.9433000352647569)), ((0.5200000089757583, 0.6600000219407425), (0.565000010471718, 0.8400000279245813))]\n",
      "Image 453 size FeatureMapSize(w=3264, h=2448) has 4 boxes\n",
      "[((0.04325436774907982, 0.5591402472304416), (0.3832083827628825, 1.0)), ((0.642306849807845, 0.43762019086196113), (0.9835577914125649, 0.8487475529553984))]\n",
      "converted_boxes: [((0.04325436774907982, 0.5591402472304416), (0.3832083827628825, 1.0)), ((0.642306849807845, 0.43762019086196113), (0.9835577914125649, 0.8487475529553984))], tpoints: [((0.5674999835444432, 0.7300000159569036), (1.0, 0.9032999674479166)), ((0.5699999940161612, 0.5266999886705984), (1.0, 0.7333000033509498))]\n",
      "Image 667 size FeatureMapSize(w=2448, h=3264) has 14 boxes\n",
      "[((0.0, 0.06315552885482824), (0.43897527470049075, 0.5411287444293086)), ((0.4638914324119515, 0.6848038107363236), (0.8020953618167821, 0.989491451695114)), ((0.2649539421850943, 0.041917743638811705), (0.7389479850786663, 0.5837797028363164)), ((0.0, 0.08293971178438041), (0.19803204143662193, 0.3890084141121175)), ((0.0, 0.23798569465619587), (0.2117989226613621, 0.5641983772260212)), ((0.0, 0.67913818359375), (0.19464538903122594, 0.9907445048625144)), ((0.6111519734982438, 0.09027873120737406), (1.0, 0.5940260677910292))]\n",
      "converted_boxes: [((0.0, 0.06315552885482824), (0.43897527470049075, 0.5411287444293086)), ((0.4638914324119515, 0.6848038107363236), (0.8020953618167821, 0.989491451695114)), ((0.2649539421850943, 0.041917743638811705), (0.7389479850786663, 0.5837797028363164)), ((0.0, 0.08293971178438041), (0.19803204143662193, 0.3890084141121175)), ((0.0, 0.23798569465619587), (0.2117989226613621, 0.5641983772260212)), ((0.0, 0.67913818359375), (0.19464538903122594, 0.9907445048625144)), ((0.6111519734982438, 0.09027873120737406), (1.0, 0.5940260677910292))], tpoints: [((0.8600000119676777, 0.7224999970080805), (1.0, 0.994999979056564)), ((0.689999998005387, 0.7125000299191943), (0.8667000165951797, 0.9900000329111137)), ((0.5433000053455627, 0.7125000299191943), (0.6967000026328891, 0.9850000119676777)), ((0.39330000035903034, 0.7099999820484835), (0.5467000225790186, 0.9799999910242417)), ((0.2400000079784518, 0.7075000089757583), (0.4032999923805785, 0.9700000239353553)), ((0.09000000299191942, 0.7000000149595971), (0.253300012326708, 0.9724999970080805)), ((0.0, 0.6974999670888863), (0.1000000012466331, 0.9700000239353553))]\n",
      "已評估 50/50 張圖像，當前平均 IoU: 0.2354\n",
      "\n",
      "=== 雙射映射評估結果摘要 ===\n",
      "總體精確度 (Precision): 0.1772\n",
      "總體召回率 (Recall): 0.1772\n",
      "總體 F1 分數: 0.1772\n",
      "總體平均 IoU: 0.2354\n",
      "平均精確度 (mAP): 0.1195\n",
      "匹配率: 1.0000\n",
      "總匹配對數: 158\n",
      "總檢測數: 158\n",
      "總真實標註數: 158\n",
      "\n",
      "=== 各類別結果 ===\n",
      "類別 1011: P=0.5000, R=0.5000, F1=0.5000, IoU=0.3104\n",
      "類別 643: P=0.4000, R=0.4000, F1=0.4000, IoU=0.2654\n",
      "類別 1190: P=0.2500, R=0.2500, F1=0.2500, IoU=0.3554\n",
      "類別 1164: P=1.0000, R=1.0000, F1=1.0000, IoU=0.7900\n",
      "類別 299: P=0.3333, R=0.3333, F1=0.3333, IoU=0.3262\n",
      "類別 771: P=0.0000, R=0.0000, F1=0.0000, IoU=0.0948\n",
      "類別 858: P=0.0000, R=0.0000, F1=0.0000, IoU=0.0726\n",
      "類別 374: P=0.0000, R=0.0000, F1=0.0000, IoU=0.2230\n",
      "類別 641: P=0.0000, R=0.0000, F1=0.0000, IoU=0.2258\n",
      "類別 421: P=0.0000, R=0.0000, F1=0.0000, IoU=0.0000\n",
      "類別 125: P=0.0000, R=0.0000, F1=0.0000, IoU=0.0000\n",
      "類別 380: P=0.0000, R=0.0000, F1=0.0000, IoU=0.2088\n",
      "類別 433: P=0.0000, R=0.0000, F1=0.0000, IoU=0.0000\n",
      "類別 107: P=0.0000, R=0.0000, F1=0.0000, IoU=0.1106\n",
      "類別 362: P=0.3333, R=0.3333, F1=0.3333, IoU=0.2989\n",
      "類別 548: P=0.0000, R=0.0000, F1=0.0000, IoU=0.1425\n",
      "類別 63: P=1.0000, R=1.0000, F1=1.0000, IoU=0.7233\n",
      "類別 654: P=0.0000, R=0.0000, F1=0.0000, IoU=0.0937\n",
      "類別 834: P=0.3333, R=0.3333, F1=0.3333, IoU=0.2858\n",
      "類別 568: P=0.5000, R=0.5000, F1=0.5000, IoU=0.4574\n",
      "類別 1015: P=0.0000, R=0.0000, F1=0.0000, IoU=0.0906\n",
      "類別 832: P=0.6667, R=0.6667, F1=0.6667, IoU=0.6062\n",
      "類別 290: P=0.0000, R=0.0000, F1=0.0000, IoU=0.0000\n",
      "類別 269: P=1.0000, R=1.0000, F1=1.0000, IoU=0.5941\n",
      "類別 638: P=1.0000, R=1.0000, F1=1.0000, IoU=0.5664\n",
      "類別 1083: P=1.0000, R=1.0000, F1=1.0000, IoU=0.6708\n",
      "類別 278: P=0.0000, R=0.0000, F1=0.0000, IoU=0.1348\n",
      "類別 199: P=0.2000, R=0.2000, F1=0.2000, IoU=0.3608\n",
      "類別 1024: P=0.0000, R=0.0000, F1=0.0000, IoU=0.0767\n",
      "類別 108: P=0.0000, R=0.0000, F1=0.0000, IoU=0.0000\n",
      "類別 739: P=0.0000, R=0.0000, F1=0.0000, IoU=0.1551\n",
      "類別 822: P=0.1111, R=0.1111, F1=0.1111, IoU=0.2125\n",
      "類別 1145: P=0.0000, R=0.0000, F1=0.0000, IoU=0.1882\n",
      "類別 861: P=1.0000, R=1.0000, F1=1.0000, IoU=0.6674\n",
      "類別 692: P=0.0000, R=0.0000, F1=0.0000, IoU=0.1621\n",
      "類別 209: P=0.5000, R=0.5000, F1=0.5000, IoU=0.3735\n",
      "類別 566: P=0.0000, R=0.0000, F1=0.0000, IoU=0.2374\n",
      "類別 699: P=0.0000, R=0.0000, F1=0.0000, IoU=0.1577\n",
      "類別 1028: P=0.0000, R=0.0000, F1=0.0000, IoU=0.1548\n",
      "類別 875: P=0.5000, R=0.5000, F1=0.5000, IoU=0.5235\n",
      "類別 1093: P=0.0000, R=0.0000, F1=0.0000, IoU=0.1234\n",
      "類別 67: P=0.5000, R=0.5000, F1=0.5000, IoU=0.6011\n",
      "類別 510: P=0.0000, R=0.0000, F1=0.0000, IoU=0.0000\n",
      "類別 1155: P=1.0000, R=1.0000, F1=1.0000, IoU=0.6448\n",
      "類別 411: P=0.0000, R=0.0000, F1=0.0000, IoU=0.2460\n",
      "類別 672: P=0.0000, R=0.0000, F1=0.0000, IoU=0.0000\n",
      "類別 351: P=0.0000, R=0.0000, F1=0.0000, IoU=0.0491\n",
      "類別 670: P=0.0000, R=0.0000, F1=0.0000, IoU=0.2222\n",
      "類別 880: P=0.0000, R=0.0000, F1=0.0000, IoU=0.1221\n"
     ]
    }
   ],
   "source": [
    "# 基本評估\n",
    "results = lcp.evaluate(dataloader_train, img_normalization, box_coder, cfg, count=50)\n",
    "\n",
    "# # 保存結果\n",
    "# lcp.save_evaluation_results(results, \"pruned_model_evaluation.json\")\n",
    "\n",
    "# # 可視化單個樣本\n",
    "# lcp.visualize_evaluation_sample(dataloader_train, img_normalization, box_coder, cfg)\n",
    "\n",
    "# # 使用不同的IoU閾值進行評估\n",
    "# results_strict = lcp.evaluate(dataloader_train, img_normalization, box_coder, cfg, \n",
    "#                                    count=100, iou_threshold=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5454c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "評估結果已保存到: evaluation_results.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def save_evaluation_to_csv(results, filename='evaluation_results.csv'):\n",
    "    \"\"\"\n",
    "    將評估結果保存到 CSV 文件\n",
    "    \n",
    "    Args:\n",
    "        results: 評估結果字典\n",
    "        filename: CSV 文件名\n",
    "    \"\"\"\n",
    "    \n",
    "    # 確保目錄存在\n",
    "    directory = os.path.dirname(filename)\n",
    "    if directory and not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    # 提取主要指標\n",
    "    overall_metrics = results['overall_metrics']\n",
    "    bijection_stats = results['bijection_stats']\n",
    "    eval_params = results['evaluation_params']\n",
    "    \n",
    "    # 計算額外統計\n",
    "    class_metrics = results['class_metrics']\n",
    "    num_classes = len(class_metrics)\n",
    "    classes_with_perfect_score = sum(1 for metrics in class_metrics.values() if metrics['f1_score'] == 1.0)\n",
    "    classes_with_zero_score = sum(1 for metrics in class_metrics.values() if metrics['f1_score'] == 0.0)\n",
    "    \n",
    "    # 準備 CSV 數據\n",
    "    csv_data = {\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'model_type': eval_params['model_type'],\n",
    "        'evaluated_images': eval_params['evaluated_images'],\n",
    "        'iou_threshold': eval_params['iou_threshold'],\n",
    "        'precision': overall_metrics['precision'],\n",
    "        'recall': overall_metrics['recall'],\n",
    "        'f1_score': overall_metrics['f1_score'],\n",
    "        'mean_iou': overall_metrics['mean_iou'],\n",
    "        'map': overall_metrics['map'],\n",
    "        'matching_rate': overall_metrics['matching_rate'],\n",
    "        'total_detections': bijection_stats['total_detections'],\n",
    "        'total_ground_truths': bijection_stats['total_ground_truths'],\n",
    "        'total_matched_pairs': bijection_stats['total_matched_pairs'],\n",
    "        'unmatched_detections': bijection_stats['unmatched_detections'],\n",
    "        'unmatched_gts': bijection_stats['unmatched_gts'],\n",
    "        'num_classes': num_classes,\n",
    "        'classes_perfect_score': classes_with_perfect_score,\n",
    "        'classes_zero_score': classes_with_zero_score\n",
    "    }\n",
    "    \n",
    "    # 檢查文件是否存在以決定是否寫入標題\n",
    "    file_exists = os.path.exists(filename)\n",
    "    \n",
    "    # 寫入 CSV\n",
    "    with open(filename, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_data.keys())\n",
    "        \n",
    "        # 如果文件不存在，寫入標題\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        \n",
    "        # 寫入數據\n",
    "        writer.writerow(csv_data)\n",
    "    \n",
    "    print(f\"評估結果已保存到: {filename}\")\n",
    "    return filename\n",
    "\n",
    "# 使用範例\n",
    "filename = save_evaluation_to_csv(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2864def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntut-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
