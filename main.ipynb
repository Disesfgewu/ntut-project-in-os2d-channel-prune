{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8582b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from os2d.modeling.model import build_os2d_from_config\n",
    "from os2d.config import cfg\n",
    "import  os2d.utils.visualization as visualizer\n",
    "from os2d.structures.feature_map import FeatureMapSize\n",
    "from os2d.utils import setup_logger, read_image, get_image_size_after_resize_preserving_aspect_ratio\n",
    "from os2d.data import dataloader\n",
    "from os2d.modeling.model import build_os2d_from_config\n",
    "\n",
    "from os2d.data.dataloader import build_eval_dataloaders_from_cfg, build_train_dataloader_from_config\n",
    "from os2d.engine.train import trainval_loop\n",
    "from os2d.utils import set_random_seed, get_trainable_parameters, mkdir, save_config, setup_logger, get_data_path\n",
    "from os2d.engine.optimization import create_optimizer\n",
    "from os2d.config import cfg\n",
    "from os2d.utils.visualization import *\n",
    "import random\n",
    "import os2d.utils.visualization as visualizer\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os2d.utils import get_image_size_after_resize_preserving_aspect_ratio\n",
    "from src.util.detection import generate_detection_boxes\n",
    "from src.util.visualize import visualize_boxes_on_image\n",
    "from src.util.filter import DataLoaderDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f90fa5",
   "metadata": {},
   "source": [
    "### INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c57cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def show_gpu_memory_usage():\n",
    "    \"\"\"顯示當前 GPU RAM 使用情況\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.cuda.current_device()\n",
    "        device_name = torch.cuda.get_device_name(device)\n",
    "\n",
    "        # 獲取記憶體使用情況 (轉換為 GB)\n",
    "        allocated = torch.cuda.memory_allocated(device) / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved(device) / 1024**3\n",
    "        total = torch.cuda.get_device_properties(device).total_memory / 1024**3\n",
    "\n",
    "        print(f\"🖥️  GPU 設備: {device_name}\")\n",
    "        print(f\"📊 記憶體使用情況:\")\n",
    "        print(f\"   已分配: {allocated:.2f} GB\")\n",
    "        print(f\"   已保留: {reserved:.2f} GB\")\n",
    "        print(f\"   總容量: {total:.2f} GB\")\n",
    "        print(f\"   使用率: {(allocated/total)*100:.1f}%\")\n",
    "        print(f\"   保留率: {(reserved/total)*100:.1f}%\")\n",
    "\n",
    "        # 視覺化進度條\n",
    "        usage_percent = int((allocated/total)*100)\n",
    "        bar_length = 20\n",
    "        filled_length = int(bar_length * usage_percent / 100)\n",
    "        bar = '█' * filled_length + '░' * (bar_length - filled_length)\n",
    "        print(f\"   [{bar}] {usage_percent}%\")\n",
    "\n",
    "    else:\n",
    "        print(\"❌ CUDA 不可用，無法檢測 GPU 記憶體\")\n",
    "\n",
    "import torch\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    計算模型的參數數量\n",
    "    Returns:\n",
    "      total_params: 包含所有參數\n",
    "      trainable_params: 只包含 requires_grad=True 的參數\n",
    "    \"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "import io\n",
    "\n",
    "def estimate_model_size(model):\n",
    "    \"\"\"\n",
    "    將模型序列化到緩衝區，估算存檔大小（MB）\n",
    "    \"\"\"\n",
    "    buffer = io.BytesIO()\n",
    "    torch.save(model.state_dict(), buffer)\n",
    "    size_mb = buffer.getbuffer().nbytes / (1024 ** 2)\n",
    "    return size_mb\n",
    "\n",
    "def show_network_status( orig_net, prune_net ):\n",
    "    print( \"原始網路參數統計:\\n\" )\n",
    "    model = orig_net\n",
    "    total, trainable = count_parameters(model)\n",
    "    print(f\"總參數量: {total:,}\")\n",
    "    print(f\"可訓練參數量: {trainable:,}\")\n",
    "\n",
    "    size_mb = estimate_model_size(model)\n",
    "    print(f\"模型存儲大小: {size_mb:.2f} MB\")\n",
    "\n",
    "    print( \"剪枝網路參數統計:\\n\" )\n",
    "    model = prune_net\n",
    "    total, trainable = count_parameters(model)\n",
    "    print(f\"總參數量: {total:,}\")\n",
    "    print(f\"可訓練參數量: {trainable:,}\")\n",
    "\n",
    "    size_mb = estimate_model_size(model)\n",
    "    print(f\"模型存儲大小: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b091ee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.is_cuda:\n",
    "    assert torch.cuda.is_available(), \"Do not have available GPU, but cfg.is_cuda == 1\"\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# random seed\n",
    "set_random_seed(cfg.random_seed, cfg.is_cuda)\n",
    "\n",
    "# Model\n",
    "net, box_coder, criterion, img_normalization, optimizer_state = build_os2d_from_config(cfg)\n",
    "\n",
    "# Optimizer\n",
    "parameters = get_trainable_parameters(net)\n",
    "optimizer = create_optimizer(parameters, cfg.train.optim, optimizer_state)\n",
    "\n",
    "# load the dataset\n",
    "data_path = get_data_path()\n",
    "dataloader_train, datasets_train_for_eval = build_train_dataloader_from_config(cfg, box_coder, img_normalization,\n",
    "                                                                                data_path=data_path)\n",
    "\n",
    "dataloaders_eval = build_eval_dataloaders_from_cfg(cfg, box_coder, img_normalization,\n",
    "                                                    datasets_for_eval=datasets_train_for_eval,\n",
    "                                                    data_path=data_path)\n",
    "\n",
    "db = DataLoaderDB( path = './src/db/data.csv' , dataloader = dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d80149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lcp.ct_aoi_align import ContextAoiAlign\n",
    "transform_image = transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize(img_normalization[\"mean\"], img_normalization[\"std\"])\n",
    "                      ])\n",
    "\n",
    "context_aoi_align = ContextAoiAlign( db, dataloader_train, transform_image , net , cfg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7336e720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lcp.aux_net import AuxiliaryNetwork\n",
    "aux_net = AuxiliaryNetwork( context_aoi_align, db )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48eb8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lcp.lcp import LCP\n",
    "lcp = LCP(net, aux_net, dataloader_train)\n",
    "lcp.init_for_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d8eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.util.prune_db import PruneDBControler\n",
    "prune_db = PruneDBControler( path = './src/db/prune_channel_information.csv' )\n",
    "# prune_db.initial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417c4a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lcp.pruner import Pruner\n",
    "pruner = Pruner( lcp._prune_net )\n",
    "pruner.set_prune_db( prune_db )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d44c8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = lcp.get_layers_name()\n",
    "print( layers )\n",
    "layer_names = []\n",
    "for name, ch in layers:\n",
    "    if name.endswith('.conv1') or name.endswith('.conv2'):\n",
    "        layer_names.append( name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d02c3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcp.set_prune_db(prune_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1287006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lcp.lcpfinetune import LCPFineTune\n",
    "lcp_finetune = LCPFineTune(\n",
    "    prune_net = lcp._prune_net,\n",
    "    dataloader_train = dataloader_train,\n",
    "    img_normalization = img_normalization,\n",
    "    box_coder = box_coder,\n",
    "    cfg       = cfg,\n",
    "    optimizer=optimizer,\n",
    "    parameters=parameters\n",
    ")\n",
    "lcp_finetune._setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d084e7b",
   "metadata": {},
   "source": [
    "#### Try one layer for channel selection computing for Test SetUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bd837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, ch in layers:\n",
    "    if name == 'layer2.0.conv2':\n",
    "        pass\n",
    "    else:\n",
    "        continue\n",
    "    print(f\"{name}: {ch} channels\")\n",
    "    keep, discard = lcp.get_channel_selection_by_no_grad(\n",
    "        layer_name   = f\"net_feature_maps.{name}\",\n",
    "        discard_rate = 0.5,\n",
    "        lambda_rate  = 1.0,\n",
    "        use_image_num= 3,\n",
    "        random_seed  = 42\n",
    "    )\n",
    "    print(f\"layer {name} , 預計保留通道數量: {len(keep)}/{ch}, 預計捨棄通道數量: {len(discard)}/{ch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e71bd6b",
   "metadata": {},
   "source": [
    "### Main For Prune + Finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bd2332",
   "metadata": {},
   "source": [
    "##### Set Up for config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.defrost()\n",
    "\n",
    "cfg.train.optim.max_iter = 100\n",
    "cfg.train.do_training = True\n",
    "cfg.output.print_iter = 10\n",
    "cfg.eval.iter = 10\n",
    "cfg.train.batch_size = 1\n",
    "\n",
    "cfg.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44c2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.util.loss import LCPFinetuneCriterion\n",
    "lcp_criterion = LCPFinetuneCriterion(\n",
    "    original_criterion=criterion,  # 原始損失函數實例\n",
    "    aux_net=lcp._aux_net,  # 包含 aux_loss 方法的實例\n",
    "    auxiliary_weight=1.0  # 可以調整輔助損失權重\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf2950d",
   "metadata": {},
   "source": [
    "#### Load Pruned Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa8fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lcp.recontruction import LCPReconstruction\n",
    "lcp_reconstruction = LCPReconstruction(\n",
    "    prune_db = prune_db,\n",
    "    pruner = pruner,\n",
    "    prune_net = lcp._prune_net\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900274f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcp_reconstruction.load_checkpoint_with_pruned_net(\n",
    "    './src/util/checkpoints-test/checkpoint_lcp_finetune_26_layer3.5.conv2.pth'\n",
    ")\n",
    "lcp._prune_net = lcp_reconstruction._prune_net\n",
    "pruned_layers = []\n",
    "for layer in lcp_reconstruction._pruned_layers:\n",
    "    if layer not in pruned_layers:\n",
    "        pruned_layers.append(layer)\n",
    "for layer in pruned_layers:\n",
    "    lcp.prune_layer(\n",
    "        layer_name   = layer,\n",
    "        discard_rate = None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce45713d",
   "metadata": {},
   "source": [
    "##### Main code for LCP Algorithm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf120e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, layer_name in enumerate(layer_names):\n",
    "#     if layer_name == 'layer3.0.conv1' or layer_name == 'layer3.1.conv1' or layer_name == 'layer3.2.conv1' or layer_name == 'layer3.3.conv1' or layer_name == 'layer3.4.conv1' or layer_name == 'layer3.5.conv1':\n",
    "#         continue\n",
    "#     cfg.defrost()\n",
    "#     if idx > 13:\n",
    "#         cfg.train.optim.max_iter = 50\n",
    "#         lcp.prune_layer(\n",
    "#             layer_name   = layer_name,\n",
    "#             discard_rate = 0.6,\n",
    "#         )\n",
    "#     else:\n",
    "#         cfg.train.optim.max_iter = 25\n",
    "#         lcp.prune_layer(\n",
    "#             layer_name   = layer_name,\n",
    "#             discard_rate = 0.8,\n",
    "#         )\n",
    "#     cfg.freeze()\n",
    "#     lcp_finetune.start_finetune(\n",
    "#         criterion= lcp_criterion,  # 使用自定義損失函數\n",
    "#     )\n",
    "#     show_gpu_memory_usage()\n",
    "#     print(f\"剪枝後網路狀態 (第 {idx+1}, {layer_name} 層):\")\n",
    "#     show_network_status(lcp._net, lcp_finetune._prune_net)\n",
    "#     lcp._prune_net = lcp_finetune._prune_net  # 更新剪枝網路\n",
    "#     lcp.save_checkpoint_with_pruned_net(\n",
    "#         log_path = './src/util/checkpoints-test2',\n",
    "#         optimizer = optimizer,\n",
    "#         model_name = f\"lcp_finetune_{idx+1}_{layer_name}\",\n",
    "#         i_iter = cfg.train.optim.max_iter\n",
    "#     )\n",
    "#     lcp.debug_for_test_vision(\n",
    "#         dataloader_train = dataloader_train,\n",
    "#         img_normalization = img_normalization,\n",
    "#         box_coder = box_coder,\n",
    "#         cfg = cfg,\n",
    "#         count = 2\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d533e41e",
   "metadata": {},
   "source": [
    "##### The Global Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cd836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_network_status(lcp._net, lcp._prune_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e9799",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_finetune_iter = 9000\n",
    "cfg.defrost()\n",
    "cfg.train.optim.max_iter = 100\n",
    "cfg.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a986c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range( int(global_finetune_iter / cfg.train.optim.max_iter) ):\n",
    "    print(f\"Global Finetune Iteration: {iter+1}/{int(global_finetune_iter / cfg.train.optim.max_iter)}\")\n",
    "    lcp_finetune.start_finetune(\n",
    "        criterion= lcp_criterion,  # 使用自定義損失函數\n",
    "    )\n",
    "    lcp.save_checkpoint_with_pruned_net(\n",
    "        log_path = './src/util/checkpoints-test',\n",
    "        optimizer = optimizer,\n",
    "        model_name = f\"lcp_finetune_{iter+1}_global\",\n",
    "        i_iter = cfg.train.optim.max_iter\n",
    "    )\n",
    "    lcp._prune_net = lcp_finetune._prune_net  # 更新剪枝網路\n",
    "    lcp.debug_for_test_vision(\n",
    "        dataloader_train = dataloader_train,\n",
    "        img_normalization = img_normalization,\n",
    "        box_coder = box_coder,\n",
    "        cfg = cfg,\n",
    "        count = 2\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntut-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
