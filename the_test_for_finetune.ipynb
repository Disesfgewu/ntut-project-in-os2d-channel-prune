{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ICA9mFU20lQy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3569,
     "status": "ok",
     "timestamp": 1752588186625,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "ICA9mFU20lQy",
    "outputId": "613e8ca1-312a-49f0-ce6b-4d4fa17cf341"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65SmeL-0krf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 898,
     "status": "ok",
     "timestamp": 1752588187526,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "c65SmeL-0krf",
    "outputId": "0686a83d-ac9b-4ae0-8905-52951541a57a"
   },
   "outputs": [],
   "source": [
    "# %cd /content/drive/MyDrive/è¨ˆç•«/ntut-project-in-os2d-channel-prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l82GhmL-ZTCq",
   "metadata": {
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1752588202437,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "l82GhmL-ZTCq"
   },
   "outputs": [],
   "source": [
    "# !mkdir visualized_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee1f048",
   "metadata": {
    "id": "eee1f048"
   },
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aszTmV4F7niw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106,
     "status": "ok",
     "timestamp": 1752588227221,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "aszTmV4F7niw",
    "outputId": "e6f0e439-a098-4649-a4e7-3f13103d2203"
   },
   "outputs": [],
   "source": [
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p7OJS3vK1n2w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4320,
     "status": "ok",
     "timestamp": 1752588236032,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "p7OJS3vK1n2w",
    "outputId": "b790bb7a-659b-495d-ff01-c9468085d5db"
   },
   "outputs": [],
   "source": [
    "# !pip install yacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lYIatXK2OEsS",
   "metadata": {
    "executionInfo": {
     "elapsed": 5360,
     "status": "ok",
     "timestamp": 1752588241497,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "lYIatXK2OEsS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def show_gpu_memory_usage():\n",
    "    \"\"\"é¡¯ç¤ºç•¶å‰ GPU RAM ä½¿ç”¨æƒ…æ³\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.cuda.current_device()\n",
    "        device_name = torch.cuda.get_device_name(device)\n",
    "\n",
    "        # ç²å–è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³ (è½‰æ›ç‚º GB)\n",
    "        allocated = torch.cuda.memory_allocated(device) / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved(device) / 1024**3\n",
    "        total = torch.cuda.get_device_properties(device).total_memory / 1024**3\n",
    "\n",
    "        print(f\"ğŸ–¥ï¸  GPU è¨­å‚™: {device_name}\")\n",
    "        print(f\"ğŸ“Š è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³:\")\n",
    "        print(f\"   å·²åˆ†é…: {allocated:.2f} GB\")\n",
    "        print(f\"   å·²ä¿ç•™: {reserved:.2f} GB\")\n",
    "        print(f\"   ç¸½å®¹é‡: {total:.2f} GB\")\n",
    "        print(f\"   ä½¿ç”¨ç‡: {(allocated/total)*100:.1f}%\")\n",
    "        print(f\"   ä¿ç•™ç‡: {(reserved/total)*100:.1f}%\")\n",
    "\n",
    "        # è¦–è¦ºåŒ–é€²åº¦æ¢\n",
    "        usage_percent = int((allocated/total)*100)\n",
    "        bar_length = 20\n",
    "        filled_length = int(bar_length * usage_percent / 100)\n",
    "        bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)\n",
    "        print(f\"   [{bar}] {usage_percent}%\")\n",
    "\n",
    "    else:\n",
    "        print(\"âŒ CUDA ä¸å¯ç”¨ï¼Œç„¡æ³•æª¢æ¸¬ GPU è¨˜æ†¶é«”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51eb0f0",
   "metadata": {
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1752588241566,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "d51eb0f0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from os2d.modeling.model import build_os2d_from_config\n",
    "from os2d.config import cfg\n",
    "import  os2d.utils.visualization as visualizer\n",
    "from os2d.structures.feature_map import FeatureMapSize\n",
    "from os2d.utils import setup_logger, read_image, get_image_size_after_resize_preserving_aspect_ratio\n",
    "from os2d.data import dataloader\n",
    "from os2d.modeling.model import build_os2d_from_config\n",
    "\n",
    "from os2d.data.dataloader import build_eval_dataloaders_from_cfg, build_train_dataloader_from_config\n",
    "from os2d.engine.train import trainval_loop\n",
    "from os2d.utils import set_random_seed, get_trainable_parameters, mkdir, save_config, setup_logger, get_data_path\n",
    "from os2d.engine.optimization import create_optimizer\n",
    "from os2d.config import cfg\n",
    "from os2d.utils.visualization import *\n",
    "import random\n",
    "import os2d.utils.visualization as visualizer\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os2d.utils import get_image_size_after_resize_preserving_aspect_ratio\n",
    "from src.util.detection import generate_detection_boxes\n",
    "from src.util.visualize import visualize_boxes_on_image\n",
    "from src.util.filter import DataLoaderDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab2480f",
   "metadata": {
    "executionInfo": {
     "elapsed": 44090,
     "status": "ok",
     "timestamp": 1752588285659,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "fab2480f"
   },
   "outputs": [],
   "source": [
    "if cfg.is_cuda:\n",
    "    assert torch.cuda.is_available(), \"Do not have available GPU, but cfg.is_cuda == 1\"\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# random seed\n",
    "set_random_seed(cfg.random_seed, cfg.is_cuda)\n",
    "\n",
    "# Model\n",
    "net, box_coder, criterion, img_normalization, optimizer_state = build_os2d_from_config(cfg)\n",
    "\n",
    "# Optimizer\n",
    "parameters = get_trainable_parameters(net)\n",
    "optimizer = create_optimizer(parameters, cfg.train.optim, optimizer_state)\n",
    "\n",
    "# load the dataset\n",
    "data_path = get_data_path()\n",
    "dataloader_train, datasets_train_for_eval = build_train_dataloader_from_config(cfg, box_coder, img_normalization,\n",
    "                                                                                data_path=data_path)\n",
    "\n",
    "dataloaders_eval = build_eval_dataloaders_from_cfg(cfg, box_coder, img_normalization,\n",
    "                                                    datasets_for_eval=datasets_train_for_eval,\n",
    "                                                    data_path=data_path)\n",
    "\n",
    "db = DataLoaderDB( path = './src/db/data.csv' , dataloader = dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PMN5K0glOIgr",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1752588285662,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "PMN5K0glOIgr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3688df13",
   "metadata": {
    "id": "3688df13"
   },
   "source": [
    "### Test Basic Method of DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe117baf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1752588285680,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "fe117baf",
    "outputId": "5f33dd68-9135-43e5-b183-56a7413b6c7f"
   },
   "outputs": [],
   "source": [
    "image_ids = list ( map( int , db.get_image_ids()) )\n",
    "sorted_image_ids = sorted(image_ids)\n",
    "print( sorted_image_ids )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa657d83",
   "metadata": {
    "id": "fa657d83"
   },
   "source": [
    "### Test Basic Method of ContextAoiAlign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab8e5ff",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752588285686,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "7ab8e5ff"
   },
   "outputs": [],
   "source": [
    "from src.lcp.ct_aoi_align import ContextAoiAlign\n",
    "transform_image = transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize(img_normalization[\"mean\"], img_normalization[\"std\"])\n",
    "                      ])\n",
    "\n",
    "context_aoi_align = ContextAoiAlign( db, dataloader_train, transform_image , net , cfg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9524c3f6",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1752588285694,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "9524c3f6"
   },
   "outputs": [],
   "source": [
    "from src.lcp.aux_net import AuxiliaryNetwork\n",
    "aux_net = AuxiliaryNetwork( context_aoi_align, db )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d44f5",
   "metadata": {
    "id": "1a4d44f5"
   },
   "source": [
    "#### Test for LCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fef114a",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1752588285712,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "6fef114a"
   },
   "outputs": [],
   "source": [
    "from src.lcp.lcp import LCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-_ffEgi9OlGj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1752588285732,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "-_ffEgi9OlGj",
    "outputId": "f37c7060-f66f-40a1-b2bf-891cde206d39"
   },
   "outputs": [],
   "source": [
    "show_gpu_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f51a87",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73,
     "status": "ok",
     "timestamp": 1752588285811,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "a8f51a87",
    "outputId": "52a648e7-33bd-4851-a80f-f16679741c9b"
   },
   "outputs": [],
   "source": [
    "lcp = LCP(net, aux_net, dataloader_train)\n",
    "lcp.init_for_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VpO3_j4WOmq8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1752588285826,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "VpO3_j4WOmq8",
    "outputId": "7a20a7f0-595e-45f5-cd14-21210ccae82a"
   },
   "outputs": [],
   "source": [
    "show_gpu_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4e9a7f",
   "metadata": {
    "id": "fd4e9a7f"
   },
   "source": [
    "### Create DB for keep indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84da66cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1752588285841,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "84da66cc",
    "outputId": "7c0ad77c-fd79-464d-fad4-622e307c4976"
   },
   "outputs": [],
   "source": [
    "from src.util.prune_db import PruneDBControler\n",
    "prune_db = PruneDBControler( path = './src/db/prune_channel_information.csv' )\n",
    "# prune_db.initial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102c0911",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59219,
     "status": "ok",
     "timestamp": 1752588345061,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "102c0911",
    "outputId": "29f2a9a6-fd0d-4194-c166-94fea20979de"
   },
   "outputs": [],
   "source": [
    "\n",
    "layers = lcp.get_layers_name()\n",
    "for name, ch in layers:\n",
    "    if name == 'layer2.0.conv2':\n",
    "        pass\n",
    "    else:\n",
    "        continue\n",
    "    print(f\"{name}: {ch} channels\")\n",
    "    keep, discard = lcp.get_channel_selection_by_no_grad(\n",
    "        layer_name   = f\"net_feature_maps.{name}\",\n",
    "        discard_rate = 0.5,\n",
    "        lambda_rate  = 1.0,\n",
    "        use_image_num= 3,\n",
    "        random_seed  = 42\n",
    "    )\n",
    "    print(f\"layer {name} , é è¨ˆä¿ç•™é€šé“æ•¸é‡: {len(keep)}/{ch}, é è¨ˆæ¨æ£„é€šé“æ•¸é‡: {len(discard)}/{ch}\")\n",
    "    # prune_db.write_data(\n",
    "    #     layer = f\"net_feature_maps.{name}\",\n",
    "    #     original_channel_num= len(keep) + len(discard),\n",
    "    #     num_of_keep_channel = len(keep),\n",
    "    #     keep_index  = keep\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FQ4KGxSOOscb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1752588345082,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "FQ4KGxSOOscb",
    "outputId": "0a396403-b655-4a71-9e99-0a0385fe4ec7"
   },
   "outputs": [],
   "source": [
    "show_gpu_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca06801",
   "metadata": {
    "id": "7ca06801"
   },
   "source": [
    "### Test for Pruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c49fb5",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752588345088,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "56c49fb5"
   },
   "outputs": [],
   "source": [
    "from src.lcp.pruner import Pruner\n",
    "pruner = Pruner( lcp._prune_net )\n",
    "pruner.set_prune_db( prune_db )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daQ8CpDO5Pj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1752588345108,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "3daQ8CpDO5Pj",
    "outputId": "7d33347c-b85c-43f6-efeb-873f88d02f23"
   },
   "outputs": [],
   "source": [
    "show_gpu_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384f0f25",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1752588345124,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "384f0f25"
   },
   "outputs": [],
   "source": [
    "# dependencies = pruner.resolve_layer_dependencies('net_feature_maps.layer2.0.conv3')\n",
    "# print(\"ä¾è³´é—œä¿‚åˆ†æçµæœ:\")\n",
    "# print(f\"ç›®æ¨™å±¤ç´š: {dependencies['target']}\")\n",
    "# print(f\"BatchNorm å±¤: {dependencies['batch_norm']}\")\n",
    "# print(f\"ä¸‹æ¸¸å±¤ç´š: {dependencies['downstream_layers']}\")\n",
    "# print(f\"è·³èºé€£æ¥: {dependencies['skip_connections']}\")\n",
    "# print(f\"å‰ªæç­–ç•¥: {dependencies['pruning_strategy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfc5d50",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1752588345132,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "fcfc5d50"
   },
   "outputs": [],
   "source": [
    "# dependencies = pruner.resolve_layer_dependencies('net_feature_maps.layer2.0.conv3')\n",
    "# print(\"ä¾è³´é—œä¿‚åˆ†æçµæœ:\")\n",
    "# print(f\"ç›®æ¨™å±¤ç´š: {dependencies['target']}\")\n",
    "# print(f\"BatchNorm å±¤: {dependencies['batch_norm']}\")\n",
    "# print(f\"ä¸‹æ¸¸å±¤ç´š: {dependencies['downstream_layers']}\")\n",
    "# print(f\"è·³èºé€£æ¥: {dependencies['skip_connections']}\")\n",
    "# print(f\"å‰ªæç­–ç•¥: {dependencies['pruning_strategy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b8ac36",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1752588345138,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "b6b8ac36"
   },
   "outputs": [],
   "source": [
    "# for name, ch in layers:\n",
    "#     dependencies = pruner.resolve_layer_dependencies(f'net_feature_maps.{name}')\n",
    "#     print(\"ä¾è³´é—œä¿‚åˆ†æçµæœ:\")\n",
    "#     print(f\"ç›®æ¨™å±¤ç´š: {dependencies['target']}\")\n",
    "#     print(f\"BatchNorm å±¤: {dependencies['batch_norm']}\")\n",
    "#     print(f\"ä¸‹æ¸¸å±¤ç´š: {dependencies['downstream_layers']}\")\n",
    "#     print(f\"è·³èºé€£æ¥: {dependencies['skip_connections']}\")\n",
    "#     print(f\"å‰ªæç­–ç•¥: {dependencies['pruning_strategy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629c206a",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1752588345144,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "629c206a"
   },
   "outputs": [],
   "source": [
    "# # æ¸¬è©¦æ”¹é€²å¾Œçš„ä¾è³´åˆ†æ\n",
    "# layer_name = \"net_feature_maps.layer3.0.conv3\"\n",
    "# dependencies = pruner.resolve_layer_dependencies(layer_name)\n",
    "\n",
    "# print(\"ä¾è³´åˆ†æçµæœ:\")\n",
    "# print(f\"BatchNorm å±¤: {dependencies['batch_norm']}\")\n",
    "# print(f\"ä¸‹æ¸¸å±¤ç´š: {dependencies['downstream_layers']}\")\n",
    "# print(f\"Downsample å±¤: {dependencies['downsample_layer']}\")\n",
    "# print(f\"è·³èºé€£æ¥: {dependencies['skip_connections']}\")\n",
    "# print(f\"å‰ªæç­–ç•¥: {dependencies['pruning_strategy']}\")\n",
    "\n",
    "# # åŸ·è¡Œå‰ªæ\n",
    "# if dependencies['downsample_layer']:\n",
    "#     print(f\"âœ… æ‰¾åˆ° downsample å±¤: {dependencies['downsample_layer']}\")\n",
    "# else:\n",
    "#     print(\"â„¹ï¸  è©²å±¤æ²’æœ‰å°æ‡‰çš„ downsample å±¤\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa9a8d",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752588345150,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "7daa9a8d"
   },
   "outputs": [],
   "source": [
    "# # æ¸¬è©¦åƒæ•¸è¨­å®š\n",
    "# layer_name = 'net_feature_maps.layer2.0.conv2'\n",
    "# keep_indexes = prune_db.get_layer_keep_indices(layer_name)\n",
    "# dependencies = pruner.resolve_layer_dependencies(layer_name)\n",
    "# print(f\"ğŸ” æ¸¬è©¦å±¤ç´š: {layer_name}\")\n",
    "# print(f\"ğŸ“Š ä¿ç•™é€šé“ç´¢å¼•: {keep_indexes}\")\n",
    "# print(f\"ğŸ“ˆ ä¿ç•™é€šé“æ•¸: {len(keep_indexes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd71a6",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752588345156,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "4bbd71a6"
   },
   "outputs": [],
   "source": [
    "# print( dependencies )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21034eeb",
   "metadata": {
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1752588345195,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "21034eeb"
   },
   "outputs": [],
   "source": [
    "# print( pruner.prune_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a43d0",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1752588345201,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "3e2a43d0"
   },
   "outputs": [],
   "source": [
    "# # === æ­¥é©Ÿ 1: è¼¸å‡ºé€šé“å‰ªæ ===\n",
    "# print(\"\\n=== æ­¥é©Ÿ 1: è¼¸å‡ºé€šé“å‰ªæ ===\")\n",
    "# success = pruner._prune_out_channel(layer_name, keep_indexes)\n",
    "\n",
    "# if success:\n",
    "#     print(\"âœ… è¼¸å‡ºé€šé“å‰ªææˆåŠŸ\")\n",
    "\n",
    "#     # é©—è­‰è¼¸å‡ºé€šé“å‰ªæçµæœ\n",
    "#     target_layer = pruner._get_layer_by_name(layer_name)\n",
    "#     print(f\"   å‰ªæå¾Œè¼¸å‡ºé€šé“æ•¸: {target_layer.out_channels}\")\n",
    "#     print(f\"   æ¬Šé‡å½¢ç‹€: {target_layer.weight.shape}\")\n",
    "# else:\n",
    "#     print(\"âŒ è¼¸å‡ºé€šé“å‰ªæå¤±æ•—\")\n",
    "\n",
    "# # === æ­¥é©Ÿ 2: BatchNorm å‰ªæ ===\n",
    "# print(\"\\n=== æ­¥é©Ÿ 2: BatchNorm å‰ªæ ===\")\n",
    "# bn_layer_name = dependencies.get('batch_norm')\n",
    "# print(f\"ğŸ¯ BatchNorm å±¤: {bn_layer_name}\")\n",
    "\n",
    "# if bn_layer_name:\n",
    "#     success = pruner._prune_batchnorm_layer(bn_layer_name, keep_indexes)\n",
    "\n",
    "#     if success:\n",
    "#         print(\"âœ… BatchNorm å‰ªææˆåŠŸ\")\n",
    "\n",
    "#         # é©—è­‰ BatchNorm å‰ªæçµæœ\n",
    "#         bn_layer = pruner._get_layer_by_name(bn_layer_name)\n",
    "#         print(f\"   BatchNorm ç‰¹å¾µæ•¸: {bn_layer.num_features}\")\n",
    "#         print(f\"   æ¬Šé‡å½¢ç‹€: {bn_layer.weight.shape}\")\n",
    "#         print(f\"   åç½®å½¢ç‹€: {bn_layer.bias.shape}\")\n",
    "#     else:\n",
    "#         print(\"âŒ BatchNorm å‰ªæå¤±æ•—\")\n",
    "# else:\n",
    "#     print(\"âš ï¸  æœªæ‰¾åˆ°å°æ‡‰çš„ BatchNorm å±¤\")\n",
    "\n",
    "# # === æ­¥é©Ÿ 3: ä¸‹æ¸¸å±¤è¼¸å…¥é€šé“å‰ªæ ===\n",
    "# print(\"\\n=== æ­¥é©Ÿ 3: ä¸‹æ¸¸å±¤è¼¸å…¥é€šé“å‰ªæ ===\")\n",
    "# downstream_layers = dependencies.get('downstream_layers', [])\n",
    "\n",
    "# if downstream_layers:\n",
    "#     next_layer_name = downstream_layers[0]\n",
    "#     print(f\"ğŸ¯ ä¸‹æ¸¸å±¤: {next_layer_name}\")\n",
    "\n",
    "#     # æª¢æŸ¥ä¸‹æ¸¸å±¤å‰ªæå‰çš„ç‹€æ…‹\n",
    "#     next_layer = pruner._get_layer_by_name(next_layer_name)\n",
    "#     if next_layer:\n",
    "#         print(f\"å‰ªæå‰ä¸‹æ¸¸å±¤è¼¸å…¥é€šé“æ•¸: {next_layer.in_channels}\")\n",
    "#         print(f\"å‰ªæå‰ä¸‹æ¸¸å±¤æ¬Šé‡å½¢ç‹€: {next_layer.weight.shape}\")\n",
    "\n",
    "#         # åŸ·è¡Œä¸‹æ¸¸å±¤è¼¸å…¥é€šé“å‰ªæ\n",
    "#         success = pruner._prune_next_layer_inputs(layer_name, next_layer_name, keep_indexes)\n",
    "\n",
    "#         if success:\n",
    "#             print(\"âœ… ä¸‹æ¸¸å±¤è¼¸å…¥é€šé“å‰ªææˆåŠŸ\")\n",
    "\n",
    "#             # é©—è­‰ä¸‹æ¸¸å±¤å‰ªæçµæœ\n",
    "#             next_layer = pruner._get_layer_by_name(next_layer_name)\n",
    "#             print(f\"   å‰ªæå¾Œè¼¸å…¥é€šé“æ•¸: {next_layer.in_channels}\")\n",
    "#             print(f\"   å‰ªæå¾Œæ¬Šé‡å½¢ç‹€: {next_layer.weight.shape}\")\n",
    "\n",
    "#             # é©—è­‰ç¶­åº¦ä¸€è‡´æ€§\n",
    "#             if next_layer.in_channels == len(keep_indexes):\n",
    "#                 print(\"   âœ… ç¶­åº¦ä¸€è‡´æ€§æª¢æŸ¥é€šé\")\n",
    "#             else:\n",
    "#                 print(\"   âŒ ç¶­åº¦ä¸€è‡´æ€§æª¢æŸ¥å¤±æ•—\")\n",
    "#         else:\n",
    "#             print(\"âŒ ä¸‹æ¸¸å±¤è¼¸å…¥é€šé“å‰ªæå¤±æ•—\")\n",
    "#     else:\n",
    "#         print(\"âŒ ç„¡æ³•ç²å–ä¸‹æ¸¸å±¤å°è±¡\")\n",
    "# else:\n",
    "#     print(\"âš ï¸  æœªæ‰¾åˆ°ä¸‹æ¸¸å±¤\")\n",
    "\n",
    "# # === æ­¥é©Ÿ 4: Downsample å‰ªæ ===\n",
    "# print(\"\\n=== æ­¥é©Ÿ 4: Downsample å‰ªæ ===\")\n",
    "# skip_connections = dependencies.get('skip_connections', [])\n",
    "\n",
    "# if skip_connections:\n",
    "#     print(f\"ğŸ¯ è·³èºé€£æ¥: {skip_connections}\")\n",
    "\n",
    "#     # æª¢æŸ¥æ˜¯å¦éœ€è¦è™•ç† downsample\n",
    "#     downsample_processed = False\n",
    "\n",
    "#     for skip_conn in skip_connections:\n",
    "#         if 'downsample' in skip_conn:\n",
    "#             print(f\"ğŸ”§ è™•ç† Downsample å±¤: {skip_conn}\")\n",
    "\n",
    "#             # æª¢æŸ¥ downsample å±¤æ˜¯å¦å­˜åœ¨\n",
    "#             if pruner._verify_layer_exists(skip_conn):\n",
    "#                 downsample_layer = pruner._get_layer_by_name(skip_conn)\n",
    "\n",
    "#                 if downsample_layer:\n",
    "#                     print(f\"   Downsample å±¤é¡å‹: {type(downsample_layer).__name__}\")\n",
    "\n",
    "#                     # æª¢æŸ¥ downsample å‰ªæå‰çš„ç‹€æ…‹\n",
    "#                     if hasattr(downsample_layer, '__iter__'):  # Sequential\n",
    "#                         print(\"   Downsample çµæ§‹åˆ†æ:\")\n",
    "#                         for i, sub_layer in enumerate(downsample_layer):\n",
    "#                             print(f\"     [{i}] {type(sub_layer).__name__}\", end=\"\")\n",
    "#                             if hasattr(sub_layer, 'out_channels'):\n",
    "#                                 print(f\" - è¼¸å‡ºé€šé“: {sub_layer.out_channels}\")\n",
    "#                             elif hasattr(sub_layer, 'num_features'):\n",
    "#                                 print(f\" - ç‰¹å¾µæ•¸: {sub_layer.num_features}\")\n",
    "#                             else:\n",
    "#                                 print()\n",
    "\n",
    "#                     # åŸ·è¡Œ downsample å‰ªæ\n",
    "#                     try:\n",
    "#                         pruner._prune_downsample_connection(skip_conn, keep_indexes)\n",
    "#                         print(\"   âœ… Downsample å‰ªææˆåŠŸ\")\n",
    "#                         downsample_processed = True\n",
    "\n",
    "#                         # é©—è­‰ downsample å‰ªæçµæœ\n",
    "#                         downsample_layer = pruner._get_layer_by_name(skip_conn)\n",
    "#                         if hasattr(downsample_layer, '__iter__'):\n",
    "#                             print(\"   å‰ªæå¾Œ Downsample çµæ§‹:\")\n",
    "#                             for i, sub_layer in enumerate(downsample_layer):\n",
    "#                                 print(f\"     [{i}] {type(sub_layer).__name__}\", end=\"\")\n",
    "#                                 if hasattr(sub_layer, 'out_channels'):\n",
    "#                                     print(f\" - è¼¸å‡ºé€šé“: {sub_layer.out_channels}\")\n",
    "#                                 elif hasattr(sub_layer, 'num_features'):\n",
    "#                                     print(f\" - ç‰¹å¾µæ•¸: {sub_layer.num_features}\")\n",
    "#                                 else:\n",
    "#                                     print()\n",
    "\n",
    "#                         # é©—è­‰ç¶­åº¦ä¸€è‡´æ€§\n",
    "#                         conv_layer = downsample_layer[0] if hasattr(downsample_layer, '__iter__') else downsample_layer\n",
    "#                         if hasattr(conv_layer, 'out_channels') and conv_layer.out_channels == len(keep_indexes):\n",
    "#                             print(\"   âœ… Downsample ç¶­åº¦ä¸€è‡´æ€§æª¢æŸ¥é€šé\")\n",
    "#                         else:\n",
    "#                             print(\"   âŒ Downsample ç¶­åº¦ä¸€è‡´æ€§æª¢æŸ¥å¤±æ•—\")\n",
    "#                     except Exception as e:\n",
    "#                         print(f\"   âŒ Downsample å‰ªæå¤±æ•—: {e}\")\n",
    "#                 else:\n",
    "#                     print(f\"   âŒ ç„¡æ³•ç²å– Downsample å±¤å°è±¡: {skip_conn}\")\n",
    "#             else:\n",
    "#                 print(f\"   âš ï¸  Downsample å±¤ä¸å­˜åœ¨: {skip_conn}\")\n",
    "\n",
    "#         elif skip_conn == 'residual_addition':\n",
    "#             print(\"   ğŸ”— æª¢æ¸¬åˆ°æ®˜å·®é€£æ¥ï¼Œä½†ç„¡éœ€é¡å¤–è™•ç†\")\n",
    "\n",
    "#     if not downsample_processed:\n",
    "#         print(\"   â„¹ï¸  ç„¡éœ€è™•ç† Downsample å±¤\")\n",
    "# else:\n",
    "#     print(\"âš ï¸  æœªæª¢æ¸¬åˆ°è·³èºé€£æ¥\")\n",
    "\n",
    "# # === æ­¥é©Ÿ 5: æ•´é«”é©—è­‰ ===\n",
    "# print(\"\\n=== æ­¥é©Ÿ 5: æ•´é«”é©—è­‰ ===\")\n",
    "\n",
    "# # é©—è­‰å‰ªæä¸€è‡´æ€§\n",
    "# print(\"ğŸ” å‰ªæä¸€è‡´æ€§æª¢æŸ¥:\")\n",
    "\n",
    "# # 1. æª¢æŸ¥ç›®æ¨™å±¤\n",
    "# target_layer = pruner._get_layer_by_name(layer_name)\n",
    "# if target_layer:\n",
    "#     print(f\"   ç›®æ¨™å±¤ {layer_name}: {target_layer.out_channels} é€šé“\")\n",
    "\n",
    "# # 2. æª¢æŸ¥ BatchNorm å±¤\n",
    "# if bn_layer_name:\n",
    "#     bn_layer = pruner._get_layer_by_name(bn_layer_name)\n",
    "#     if bn_layer:\n",
    "#         print(f\"   BatchNorm {bn_layer_name}: {bn_layer.num_features} ç‰¹å¾µ\")\n",
    "#         if bn_layer.num_features == target_layer.out_channels:\n",
    "#             print(\"   âœ… ç›®æ¨™å±¤èˆ‡ BatchNorm ç¶­åº¦ä¸€è‡´\")\n",
    "#         else:\n",
    "#             print(\"   âŒ ç›®æ¨™å±¤èˆ‡ BatchNorm ç¶­åº¦ä¸ä¸€è‡´\")\n",
    "\n",
    "# # 3. æª¢æŸ¥ä¸‹æ¸¸å±¤\n",
    "# if downstream_layers:\n",
    "#     next_layer = pruner._get_layer_by_name(downstream_layers[0])\n",
    "#     if next_layer:\n",
    "#         print(f\"   ä¸‹æ¸¸å±¤ {downstream_layers[0]}: {next_layer.in_channels} è¼¸å…¥é€šé“\")\n",
    "#         if next_layer.in_channels == target_layer.out_channels:\n",
    "#             print(\"   âœ… ç›®æ¨™å±¤èˆ‡ä¸‹æ¸¸å±¤ç¶­åº¦ä¸€è‡´\")\n",
    "#         else:\n",
    "#             print(\"   âŒ ç›®æ¨™å±¤èˆ‡ä¸‹æ¸¸å±¤ç¶­åº¦ä¸ä¸€è‡´\")\n",
    "\n",
    "# # 4. æª¢æŸ¥ Downsample å±¤\n",
    "# downsample_layers = [conn for conn in skip_connections if 'downsample' in conn]\n",
    "# if downsample_layers:\n",
    "#     for downsample_name in downsample_layers:\n",
    "#         if pruner._verify_layer_exists(downsample_name):\n",
    "#             downsample_layer = pruner._get_layer_by_name(downsample_name)\n",
    "#             if downsample_layer and hasattr(downsample_layer, '__iter__'):\n",
    "#                 conv_layer = downsample_layer[0]\n",
    "#                 if hasattr(conv_layer, 'out_channels'):\n",
    "#                     print(f\"   Downsample {downsample_name}: {conv_layer.out_channels} è¼¸å‡ºé€šé“\")\n",
    "#                     if conv_layer.out_channels == target_layer.out_channels:\n",
    "#                         print(\"   âœ… ç›®æ¨™å±¤èˆ‡ Downsample ç¶­åº¦ä¸€è‡´\")\n",
    "#                     else:\n",
    "#                         print(\"   âŒ ç›®æ¨™å±¤èˆ‡ Downsample ç¶­åº¦ä¸ä¸€è‡´\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dce6b6",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752588345205,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "69dce6b6"
   },
   "outputs": [],
   "source": [
    "# # === æ­¥é©Ÿ 7: é€šé“ç´¢å¼•è¿½è¹¤æ¸¬è©¦ ===\n",
    "# print(\"\\n=== æ­¥é©Ÿ 7: é€šé“ç´¢å¼•è¿½è¹¤æ¸¬è©¦ ===\")\n",
    "\n",
    "# print(\"ğŸ¯ åŸ·è¡Œé€šé“ç´¢å¼•è¿½è¹¤...\")\n",
    "\n",
    "# try:\n",
    "#     # åŸ·è¡Œé€šé“ç´¢å¼•è¿½è¹¤\n",
    "#     pruner.track_channel_indices(layer_name, keep_indexes)\n",
    "#     print(\"   âœ… é€šé“ç´¢å¼•è¿½è¹¤æˆåŠŸ\")\n",
    "\n",
    "#     # é©—è­‰è¿½è¹¤çµæœ\n",
    "#     print(\"   ğŸ” è¿½è¹¤çµæœé©—è­‰:\")\n",
    "\n",
    "#     # 1. æª¢æŸ¥å‰ªææ•¸æ“šåº«æ˜¯å¦æ›´æ–°\n",
    "#     if hasattr(pruner, 'prune_db') and pruner.prune_db:\n",
    "#         try:\n",
    "#             stored_indices = pruner.prune_db.get_layer_keep_indices(layer_name)\n",
    "#             if stored_indices:\n",
    "#                 print(f\"     - æ•¸æ“šåº«ä¸­ä¿å­˜çš„ç´¢å¼•æ•¸é‡: {len(stored_indices)}\")\n",
    "#                 print(f\"     - ç´¢å¼•ä¸€è‡´æ€§æª¢æŸ¥: {'âœ… ä¸€è‡´' if stored_indices == keep_indexes else 'âŒ ä¸ä¸€è‡´'}\")\n",
    "#             else:\n",
    "#                 print(\"     - âš ï¸  æ•¸æ“šåº«ä¸­æœªæ‰¾åˆ°ä¿å­˜çš„ç´¢å¼•\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"     - âŒ æ•¸æ“šåº«æª¢æŸ¥å¤±æ•—: {e}\")\n",
    "\n",
    "#     # 2. æª¢æŸ¥å…§éƒ¨è¿½è¹¤è¨˜éŒ„\n",
    "#     if hasattr(pruner, '_prune_history'):\n",
    "#         if layer_name in pruner._prune_history:\n",
    "#             history = pruner._prune_history[layer_name]\n",
    "#             print(f\"     - åŸå§‹é€šé“æ•¸: {history.get('original_channels', 'N/A')}\")\n",
    "#             print(f\"     - ä¿ç•™é€šé“æ•¸: {history.get('kept_channels', 'N/A')}\")\n",
    "#             print(f\"     - å‰ªææ¯”ä¾‹: {history.get('prune_ratio', 0):.2%}\")\n",
    "#         else:\n",
    "#             print(\"     - âš ï¸  å…§éƒ¨è¿½è¹¤è¨˜éŒ„ä¸­æœªæ‰¾åˆ°è©²å±¤\")\n",
    "\n",
    "#     # 3. è¨ˆç®—å‰ªæçµ±è¨ˆ\n",
    "#     original_channels = target_layer.out_channels if target_layer else len(keep_indexes)\n",
    "#     kept_channels = len(keep_indexes)\n",
    "#     prune_ratio = 1.0 - (kept_channels / original_channels) if original_channels > 0 else 0.0\n",
    "\n",
    "#     print(f\"     - å¯¦éš›å‰ªæçµ±è¨ˆ:\")\n",
    "#     print(f\"       * ä¿ç•™é€šé“: {kept_channels}\")\n",
    "#     print(f\"       * å‰ªææ¯”ä¾‹: {prune_ratio:.2%}\")\n",
    "#     print(f\"       * å£“ç¸®æ•ˆæœ: {(1-prune_ratio)*100:.1f}% ä¿ç•™\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"   âŒ é€šé“ç´¢å¼•è¿½è¹¤å¤±æ•—: {e}\")\n",
    "#     import traceback\n",
    "#     traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7103cfcd",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752588345212,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "7103cfcd"
   },
   "outputs": [],
   "source": [
    "# # === æ­¥é©Ÿ 8: å®Œæ•´æ€§é©—è­‰èˆ‡æ¸¬è©¦å ±å‘Š ===\n",
    "# print(\"\\n=== æ­¥é©Ÿ 8: å®Œæ•´æ€§é©—è­‰èˆ‡æ¸¬è©¦å ±å‘Š ===\")\n",
    "\n",
    "# # ç¶²è·¯å‰å‘å‚³æ’­æ¸¬è©¦\n",
    "# print(\"ğŸ§ª ç¶²è·¯å‰å‘å‚³æ’­æ¸¬è©¦:\")\n",
    "# try:\n",
    "#     # å‰µå»ºæ¸¬è©¦è¼¸å…¥\n",
    "#     device = next(pruner.prune_network.parameters()).device\n",
    "#     test_input = torch.randn(1, 3, 224, 224, device=device)\n",
    "\n",
    "#     # è¨­ç½®ç¶²è·¯ç‚ºè©•ä¼°æ¨¡å¼\n",
    "#     pruner.prune_network.eval()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         # å˜—è©¦å‰å‘å‚³æ’­\n",
    "#         output = pruner.prune_network.net_feature_maps(test_input)\n",
    "#         print(f\"   âœ… å‰å‘å‚³æ’­æ¸¬è©¦æˆåŠŸ\")\n",
    "#         print(f\"   ğŸ“Š è¼¸å…¥å½¢ç‹€: {test_input.shape}\")\n",
    "#         print(f\"   ğŸ“Š è¼¸å‡ºå½¢ç‹€: {output.shape}\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"   âŒ å‰å‘å‚³æ’­æ¸¬è©¦å¤±æ•—: {e}\")\n",
    "\n",
    "# # ç”Ÿæˆæ¸¬è©¦å ±å‘Š\n",
    "# print(\"\\nğŸ“‹ === å®Œæ•´æ¸¬è©¦å ±å‘Š ===\")\n",
    "\n",
    "# test_results = {\n",
    "#     'è¼¸å‡ºé€šé“å‰ªæ': True,  # æ ¹æ“šå¯¦éš›çµæœè¨­ç½®\n",
    "#     'BatchNorm å‰ªæ': True,\n",
    "#     'ä¸‹æ¸¸å±¤è¼¸å…¥å‰ªæ': True,\n",
    "#     'Downsample å‰ªæ': downsample_processed if 'downsample_processed' in locals() else False,\n",
    "#     'è¼¸å…¥é€šé“ä¿®æ­£': True,  # æ ¹æ“šå¯¦éš›çµæœè¨­ç½®\n",
    "#     'é€šé“ç´¢å¼•è¿½è¹¤': True,\n",
    "#     'å‰å‘å‚³æ’­æ¸¬è©¦': True   # æ ¹æ“šå¯¦éš›çµæœè¨­ç½®\n",
    "# }\n",
    "\n",
    "# print(f\"ğŸ¯ æ¸¬è©¦å±¤ç´š: {layer_name}\")\n",
    "# print(f\"ğŸ“Š ä¿ç•™é€šé“æ•¸: {len(keep_indexes)}\")\n",
    "# print(f\"ğŸ“ˆ å‰ªææ¯”ä¾‹: {(1 - len(keep_indexes) / 512) * 100:.1f}%\")  # å‡è¨­åŸå§‹é€šé“æ•¸ç‚º 512\n",
    "\n",
    "# print(\"\\nğŸ” æ¸¬è©¦çµæœè©³æƒ…:\")\n",
    "# for test_name, result in test_results.items():\n",
    "#     status = \"âœ… é€šé\" if result else \"âŒ å¤±æ•—\"\n",
    "#     print(f\"  {test_name}: {status}\")\n",
    "\n",
    "# overall_success = all(test_results.values())\n",
    "# print(f\"\\nğŸ† æ•´é«”æ¸¬è©¦çµæœ: {'ğŸ‰ å…¨éƒ¨é€šéï¼' if overall_success else 'âš ï¸ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—'}\")\n",
    "\n",
    "# if overall_success:\n",
    "#     print(\"\\nâœ¨ æ­å–œï¼æ‚¨çš„ LCP é€šé“å‰ªæåŠŸèƒ½é‹ä½œæ­£å¸¸\")\n",
    "#     print(\"ğŸš€ åŒ…å« Track å’Œ Fix åŠŸèƒ½çš„å®Œæ•´å‰ªææµç¨‹å·²é©—è­‰\")\n",
    "#     print(\"ğŸ“ å»ºè­°é€²è¡Œæ›´å¤šå±¤ç´šçš„æ¸¬è©¦ä»¥ç¢ºä¿ç©©å®šæ€§\")\n",
    "# else:\n",
    "#     failed_tests = [name for name, result in test_results.items() if not result]\n",
    "#     print(f\"\\nğŸ”§ éœ€è¦æª¢æŸ¥çš„é …ç›®: {', '.join(failed_tests)}\")\n",
    "#     print(\"ğŸ’¡ å»ºè­°é€é …æª¢æŸ¥å¤±æ•—çš„åŠŸèƒ½ä¸¦é€²è¡Œä¿®æ­£\")\n",
    "\n",
    "# print(f\"\\nğŸ‰ å‰ªææµç¨‹å®Œæˆï¼ä¿ç•™ {len(keep_indexes)} å€‹é€šé“\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ef1ca6",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1752588345218,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "70ef1ca6"
   },
   "outputs": [],
   "source": [
    "# pruner.print_detailed_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a6a7f",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1752588345224,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "642a6a7f"
   },
   "outputs": [],
   "source": [
    "# print( pruner.prune_network )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff831705",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752588345233,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "ff831705"
   },
   "outputs": [],
   "source": [
    "# # === ç¶­åº¦ä¸€è‡´æ€§å®Œæ•´é©—è­‰ ===\n",
    "# print(\"\\n=== ç¶­åº¦ä¸€è‡´æ€§å®Œæ•´é©—è­‰ ===\")\n",
    "\n",
    "# def verify_channel_consistency(pruner, current_layer, next_layer, keep_indexes):\n",
    "#     \"\"\"é©—è­‰é€šé“ç¶­åº¦ä¸€è‡´æ€§\"\"\"\n",
    "#     try:\n",
    "#         current = pruner._get_layer_by_name(current_layer)\n",
    "#         next_conv = pruner._get_layer_by_name(next_layer)\n",
    "\n",
    "#         print(f\"ç•¶å‰å±¤ {current_layer}:\")\n",
    "#         print(f\"  è¼¸å‡ºé€šé“æ•¸: {current.out_channels}\")\n",
    "#         print(f\"  ä¿ç•™é€šé“æ•¸: {len(keep_indexes)}\")\n",
    "\n",
    "#         print(f\"ä¸‹æ¸¸å±¤ {next_layer}:\")\n",
    "#         print(f\"  è¼¸å…¥é€šé“æ•¸: {next_conv.in_channels}\")\n",
    "\n",
    "#         # æª¢æŸ¥ä¸€è‡´æ€§\n",
    "#         if current.out_channels == len(keep_indexes) == next_conv.in_channels:\n",
    "#             print(\"âœ… é€šé“ç¶­åº¦å®Œå…¨ä¸€è‡´\")\n",
    "#             return True\n",
    "#         else:\n",
    "#             print(\"âŒ é€šé“ç¶­åº¦ä¸ä¸€è‡´\")\n",
    "#             return False\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"âŒ é©—è­‰éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
    "#         return False\n",
    "\n",
    "# # åŸ·è¡Œé©—è­‰\n",
    "# consistency_ok = verify_channel_consistency(\n",
    "#     pruner, layer_name, next_layer_name, keep_indexes\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd5190a",
   "metadata": {
    "id": "cdd5190a"
   },
   "source": [
    "##### Test For Prune One Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4165e93c",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752588345236,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "4165e93c"
   },
   "outputs": [],
   "source": [
    "# # æ¸¬è©¦åƒæ•¸è¨­å®š\n",
    "# layer_name = 'net_feature_maps.layer3.0.conv2'\n",
    "# keep_indexes = prune_db.get_layer_keep_indices(layer_name)\n",
    "# dependencies = pruner.resolve_layer_dependencies(layer_name)\n",
    "# print(f\"ğŸ” æ¸¬è©¦å±¤ç´š: {layer_name}\")\n",
    "# print(f\"ğŸ“Š ä¿ç•™é€šé“ç´¢å¼•: {keep_indexes}\")\n",
    "# print(f\"ğŸ“ˆ ä¿ç•™é€šé“æ•¸: {len(keep_indexes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffda22f",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752588345243,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "6ffda22f"
   },
   "outputs": [],
   "source": [
    "# pruner.prune_layer(\n",
    "#     layer_name   = layer_name\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a710520",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752588345251,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "7a710520"
   },
   "outputs": [],
   "source": [
    "# print( pruner.prune_network )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed001c2",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752588345254,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "2ed001c2"
   },
   "outputs": [],
   "source": [
    "\n",
    "# layers = lcp.get_layers_name()\n",
    "# for name, ch in layers:\n",
    "#     if name == 'layer3.0.conv3':\n",
    "#         pass\n",
    "#     else:\n",
    "#         continue\n",
    "#     print(f\"{name}: {ch} channels\")\n",
    "#     keep, discard = lcp.get_channel_selection_by_no_grad(\n",
    "#         layer_name   = f\"net_feature_maps.{name}\",\n",
    "#         discard_rate = 0.5,\n",
    "#         lambda_rate  = 1.0,\n",
    "#         use_image_num= 3,\n",
    "#         random_seed  = 42\n",
    "#     )\n",
    "#     print(f\"layer {name} , é è¨ˆä¿ç•™é€šé“æ•¸é‡: {len(keep)}/{ch}, é è¨ˆæ¨æ£„é€šé“æ•¸é‡: {len(discard)}/{ch}\")\n",
    "#     prune_db.write_data(\n",
    "#         layer = f\"net_feature_maps.{name}\",\n",
    "#         original_channel_num= ch,\n",
    "#         num_of_keep_channel = len(keep),\n",
    "#         keep_index  = keep\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2572e81",
   "metadata": {
    "id": "a2572e81"
   },
   "source": [
    "### Test For Prune Layer in LCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c900df01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 92,
     "status": "ok",
     "timestamp": 1752588345348,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "c900df01",
    "outputId": "bf9c585c-ccd8-4996-afc8-c3fe39c5702e"
   },
   "outputs": [],
   "source": [
    "print( layers )\n",
    "layer_names = []\n",
    "for name, ch in layers:\n",
    "    if name.endswith('.conv1') or name.endswith('.conv2'):\n",
    "        layer_names.append( name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7edaec",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752588345357,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "ff7edaec"
   },
   "outputs": [],
   "source": [
    "lcp.set_prune_db(prune_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f250acc",
   "metadata": {
    "id": "6f250acc"
   },
   "source": [
    "#### Before Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ETBWABonO9Ma",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1752588345371,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "ETBWABonO9Ma",
    "outputId": "3db34b88-f16b-48b8-de1b-57398f510f83"
   },
   "outputs": [],
   "source": [
    "show_gpu_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cea991a",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752588345376,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "9cea991a"
   },
   "outputs": [],
   "source": [
    "lcp.debug_for_test_vision(\n",
    "    dataloader_train = dataloader_train,\n",
    "    img_normalization = img_normalization,\n",
    "    box_coder = box_coder,\n",
    "    cfg = cfg,\n",
    "    count = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e623a3d",
   "metadata": {
    "id": "6e623a3d"
   },
   "source": [
    "### é€™è£¡è¦è·‘ 62 minutes for ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab98a65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28140,
     "status": "ok",
     "timestamp": 1752588373518,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "5ab98a65",
    "outputId": "92726399-39cc-446d-fe7f-38aeae66f76f"
   },
   "outputs": [],
   "source": [
    "# for idx, layer_name in enumerate(layer_names):\n",
    "#     if idx != 15:\n",
    "#         continue\n",
    "#     lcp.prune_layer(\n",
    "#         layer_name   = layer_name,\n",
    "#         discard_rate = 0.8,\n",
    "#     )\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bebfe0",
   "metadata": {
    "id": "56bebfe0"
   },
   "source": [
    "#### Test for debug for vision after prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99058114",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1752588373526,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "99058114"
   },
   "outputs": [],
   "source": [
    "# lcp.debug_for_test_vision(\n",
    "#     dataloader_train = dataloader_train,\n",
    "#     img_normalization = img_normalization,\n",
    "#     box_coder = box_coder,\n",
    "#     cfg = cfg,\n",
    "#     count = 1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e360f2",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1752588373531,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "a8e360f2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    è¨ˆç®—æ¨¡å‹çš„åƒæ•¸æ•¸é‡\n",
    "    Returns:\n",
    "      total_params: åŒ…å«æ‰€æœ‰åƒæ•¸\n",
    "      trainable_params: åªåŒ…å« requires_grad=True çš„åƒæ•¸\n",
    "    \"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "import io\n",
    "\n",
    "def estimate_model_size(model):\n",
    "    \"\"\"\n",
    "    å°‡æ¨¡å‹åºåˆ—åŒ–åˆ°ç·©è¡å€ï¼Œä¼°ç®—å­˜æª”å¤§å°ï¼ˆMBï¼‰\n",
    "    \"\"\"\n",
    "    buffer = io.BytesIO()\n",
    "    torch.save(model.state_dict(), buffer)\n",
    "    size_mb = buffer.getbuffer().nbytes / (1024 ** 2)\n",
    "    return size_mb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7280fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 186,
     "status": "ok",
     "timestamp": 1752588373731,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "4d7280fc",
    "outputId": "ed7c0559-bb7a-490f-b5e2-9e0d97c494e8"
   },
   "outputs": [],
   "source": [
    "# # ä½¿ç”¨ç¯„ä¾‹\n",
    "# print( \"åŸå§‹ç¶²è·¯åƒæ•¸çµ±è¨ˆ:\\n\" )\n",
    "# model = lcp._net  \n",
    "# total, trainable = count_parameters(model)\n",
    "# print(f\"ç¸½åƒæ•¸é‡: {total:,}\")\n",
    "# print(f\"å¯è¨“ç·´åƒæ•¸é‡: {trainable:,}\")\n",
    "\n",
    "# size_mb = estimate_model_size(model)\n",
    "# print(f\"æ¨¡å‹å­˜å„²å¤§å°: {size_mb:.2f} MB\")\n",
    "\n",
    "# print( \"å‰ªæç¶²è·¯åƒæ•¸çµ±è¨ˆ:\\n\" )\n",
    "# model = lcp._prune_net\n",
    "# total, trainable = count_parameters(model)\n",
    "# print(f\"ç¸½åƒæ•¸é‡: {total:,}\")\n",
    "# print(f\"å¯è¨“ç·´åƒæ•¸é‡: {trainable:,}\")\n",
    "\n",
    "# size_mb = estimate_model_size(model)\n",
    "# print(f\"æ¨¡å‹å­˜å„²å¤§å°: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6c832b",
   "metadata": {
    "id": "1c6c832b"
   },
   "source": [
    "### Test for finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ocy_2VznPBqK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1752588373743,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "ocy_2VznPBqK",
    "outputId": "d0cc0c2a-8721-44f5-9eaf-2acc63b3662a"
   },
   "outputs": [],
   "source": [
    "show_gpu_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c77918",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752588373746,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "c2c77918"
   },
   "outputs": [],
   "source": [
    "from src.lcp.lcpfinetune import LCPFineTune\n",
    "lcp_finetune = LCPFineTune(\n",
    "    prune_net = lcp._prune_net,\n",
    "    dataloader_train = dataloader_train,\n",
    "    img_normalization = img_normalization,\n",
    "    box_coder = box_coder,\n",
    "    cfg       = cfg,\n",
    "    optimizer=optimizer,\n",
    "    parameters=parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otvepMCYPCIT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1752588373759,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "otvepMCYPCIT",
    "outputId": "4544e598-22c2-4b1c-aa2b-0edcfd99d69f"
   },
   "outputs": [],
   "source": [
    "show_gpu_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b59f245",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1752588373766,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "3b59f245"
   },
   "outputs": [],
   "source": [
    "lcp_finetune._setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e63785",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1752588373774,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "e4e63785"
   },
   "outputs": [],
   "source": [
    "cfg.defrost()\n",
    "\n",
    "cfg.train.optim.max_iter = 100\n",
    "cfg.train.do_training = True\n",
    "cfg.output.print_iter = 10\n",
    "cfg.eval.iter = 10\n",
    "cfg.train.batch_size = 1\n",
    "\n",
    "cfg.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EnMB-QoNIWb_",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752588373782,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "EnMB-QoNIWb_"
   },
   "outputs": [],
   "source": [
    "from src.util.loss import LCPFinetuneCriterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2136f43c",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1752588373788,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "2136f43c"
   },
   "outputs": [],
   "source": [
    "\n",
    "lcp_criterion = LCPFinetuneCriterion(\n",
    "    original_criterion=criterion,  # åŸå§‹æå¤±å‡½æ•¸å¯¦ä¾‹\n",
    "    aux_net=lcp._aux_net,  # åŒ…å« aux_loss æ–¹æ³•çš„å¯¦ä¾‹\n",
    "    auxiliary_weight=1.0  # å¯ä»¥èª¿æ•´è¼”åŠ©æå¤±æ¬Šé‡\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fKd5ES4tW0p_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 766
    },
    "executionInfo": {
     "elapsed": 827,
     "status": "error",
     "timestamp": 1752588411451,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "fKd5ES4tW0p_",
    "outputId": "82d99488-ed63-45fa-8f66-aeacb1ac171e"
   },
   "outputs": [],
   "source": [
    "lcp.debug_for_test_vision(\n",
    "    dataloader_train = dataloader_train,\n",
    "    img_normalization = img_normalization,\n",
    "    box_coder = box_coder,\n",
    "    cfg = cfg,\n",
    "    count = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_network_status( orig_net, prune_net ):\n",
    "    print( \"åŸå§‹ç¶²è·¯åƒæ•¸çµ±è¨ˆ:\\n\" )\n",
    "    model = orig_net\n",
    "    total, trainable = count_parameters(model)\n",
    "    print(f\"ç¸½åƒæ•¸é‡: {total:,}\")\n",
    "    print(f\"å¯è¨“ç·´åƒæ•¸é‡: {trainable:,}\")\n",
    "\n",
    "    size_mb = estimate_model_size(model)\n",
    "    print(f\"æ¨¡å‹å­˜å„²å¤§å°: {size_mb:.2f} MB\")\n",
    "\n",
    "    print( \"å‰ªæç¶²è·¯åƒæ•¸çµ±è¨ˆ:\\n\" )\n",
    "    model = prune_net\n",
    "    total, trainable = count_parameters(model)\n",
    "    print(f\"ç¸½åƒæ•¸é‡: {total:,}\")\n",
    "    print(f\"å¯è¨“ç·´åƒæ•¸é‡: {trainable:,}\")\n",
    "\n",
    "    size_mb = estimate_model_size(model)\n",
    "    print(f\"æ¨¡å‹å­˜å„²å¤§å°: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d180720",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, layer_name in enumerate(layer_names):\n",
    "    print(f\"å‰ªæå‰çš„ç¶²è·¯çµ±è¨ˆ: {idx} {layer_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baccd5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, layer_name in enumerate(layer_names):\n",
    "#     if layer_name == 'layer3.0.conv1' or layer_name == 'layer3.1.conv1' or layer_name == 'layer3.2.conv1' or layer_name == 'layer3.3.conv1' or layer_name == 'layer3.4.conv1' or layer_name == 'layer3.5.conv1':\n",
    "#         continue\n",
    "#     cfg.defrost()\n",
    "#     if idx > 13:\n",
    "#         cfg.train.optim.max_iter = 50\n",
    "#         lcp.prune_layer(\n",
    "#             layer_name   = layer_name,\n",
    "#             discard_rate = 0.5,\n",
    "#         )\n",
    "#     else:\n",
    "#         cfg.train.optim.max_iter = 1\n",
    "#         lcp.prune_layer(\n",
    "#             layer_name   = layer_name,\n",
    "#             discard_rate = 0.8,\n",
    "#         )\n",
    "#     cfg.freeze()\n",
    "#     lcp_finetune.start_finetune(\n",
    "#         criterion= lcp_criterion,  # ä½¿ç”¨è‡ªå®šç¾©æå¤±å‡½æ•¸\n",
    "#     )\n",
    "#     show_gpu_memory_usage()\n",
    "#     print(f\"å‰ªæå¾Œç¶²è·¯ç‹€æ…‹ (ç¬¬ {idx+1}, {layer_name} å±¤):\")\n",
    "#     show_network_status(lcp._net, lcp_finetune._prune_net)\n",
    "#     lcp._prune_net = lcp_finetune._prune_net  # æ›´æ–°å‰ªæç¶²è·¯\n",
    "#     lcp.save_checkpoint_with_pruned_net(\n",
    "#         log_path = './src/util/checkpoints-test',\n",
    "#         optimizer = optimizer,\n",
    "#         model_name = f\"lcp_finetune_{idx+1}_{layer_name}\",\n",
    "#         i_iter = cfg.train.optim.max_iter\n",
    "#     )\n",
    "#     lcp.debug_for_test_vision(\n",
    "#         dataloader_train = dataloader_train,\n",
    "#         img_normalization = img_normalization,\n",
    "#         box_coder = box_coder,\n",
    "#         cfg = cfg,\n",
    "#         count = 2\n",
    "#     )\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76P439WYW2L0",
   "metadata": {
    "id": "76P439WYW2L0"
   },
   "outputs": [],
   "source": [
    "lcp.debug_for_test_vision(\n",
    "    dataloader_train = dataloader_train,\n",
    "    img_normalization = img_normalization,\n",
    "    box_coder = box_coder,\n",
    "    cfg = cfg,\n",
    "    count = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa97dbe",
   "metadata": {
    "executionInfo": {
     "elapsed": 124862,
     "status": "aborted",
     "timestamp": 1752588377434,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "1aa97dbe"
   },
   "outputs": [],
   "source": [
    "# lcp_finetune.finetune_one_batch(\n",
    "#     batch_data = data,\n",
    "#     lcp_instance = lcp,\n",
    "#     criterion = criterion\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da897f",
   "metadata": {
    "executionInfo": {
     "elapsed": 124310,
     "status": "aborted",
     "timestamp": 1752588377435,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "12da897f"
   },
   "outputs": [],
   "source": [
    "# lcp_finetune.finetune_loop(\n",
    "#     lcp_instance = lcp,\n",
    "#     criterion = criterion,\n",
    "#     dataloaders_eval = dataloaders_eval,\n",
    "#     max_iters = 5,\n",
    "#     print_interval=2\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115586d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_network_status(lcp._net, lcp._prune_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c00cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( lcp._pruner.resolve_layer_dependencies( \"net_feature_maps.layer1.1.conv1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d9224c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_db._get_all_data_by_layer( 'layer1.0.conv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304ef4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lcp._prune_net = lcp._net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3da08c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_layers = lcp._prune_db.get_all_layers()\n",
    "# pruned_layers = [layer for layer in all_layers if layer.startswith('layer')]\n",
    "        \n",
    "# print( pruned_layers )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ce4237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5936ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruned_net_checkpoint = lcp.load_checkpoint_with_pruned_net(\n",
    "#     checkpoint_file_path = './src/util/checkpoints-test/checkpoint_lcp_finetune_1_layer1.0.conv1.pth'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ac9d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( lcp._prune_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b04fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_network_status(lcp._net, lcp._prune_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C5xFtUyT03E-",
   "metadata": {
    "executionInfo": {
     "elapsed": 123859,
     "status": "aborted",
     "timestamp": 1752588377436,
     "user": {
      "displayName": "FGEWU DISES",
      "userId": "12339584899501350434"
     },
     "user_tz": -480
    },
    "id": "C5xFtUyT03E-"
   },
   "outputs": [],
   "source": [
    "# for i in range(250):\n",
    "#     print(50 * '=' + f\" {i+1} / 250 é–‹å§‹å…¨å±€å¾®èª¿\" + 50 * '=')\n",
    "#     lcp_finetune.start_finetune(\n",
    "#         criterion= lcp_criterion,  # ä½¿ç”¨è‡ªå®šç¾©æå¤±å‡½æ•¸\n",
    "#     )\n",
    "#     show_gpu_memory_usage()\n",
    "#     show_network_status(lcp._net, lcp_finetune._prune_net)\n",
    "#     lcp._prune_net = lcp_finetune._prune_net  # æ›´æ–°å‰ªæç¶²è·¯\n",
    "#     lcp.debug_for_test_vision(\n",
    "#         dataloader_train = dataloader_train,\n",
    "#         img_normalization = img_normalization,\n",
    "#         box_coder = box_coder,\n",
    "#         cfg = cfg,\n",
    "#         count = 1\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a867f691",
   "metadata": {},
   "source": [
    "### Test for recontruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7137bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lcp.recontruction import LCPReconstruction\n",
    "lcp_reconstruction = LCPReconstruction(\n",
    "    prune_db = prune_db,\n",
    "    pruner = pruner,\n",
    "    prune_net = lcp._prune_net\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0c3121",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcp_reconstruction.load_checkpoint_with_pruned_net(\n",
    "    './src/util/checkpoints-test/checkpoint_lcp_finetune_1_layer1.0.conv1.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e82f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcp.debug_for_test_vision(\n",
    "    dataloader_train = dataloader_train,\n",
    "    img_normalization = img_normalization,\n",
    "    box_coder = box_coder,\n",
    "    cfg = cfg,\n",
    "    count = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86cb296",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcp._prune_net = lcp_reconstruction._prune_net\n",
    "show_network_status(lcp._net, lcp._prune_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcp.debug_for_test_vision(\n",
    "    dataloader_train = dataloader_train,\n",
    "    img_normalization = img_normalization,\n",
    "    box_coder = box_coder,\n",
    "    cfg = cfg,\n",
    "    count = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0a8edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_layers = []\n",
    "for layer in lcp_reconstruction._pruned_layers:\n",
    "    if layer not in pruned_layers:\n",
    "        pruned_layers.append(layer)\n",
    "print( pruned_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c92c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pruned_layers:\n",
    "    lcp.prune_layer(\n",
    "        layer_name   = layer,\n",
    "        discard_rate = None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c66a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcp.debug_for_test_vision(\n",
    "    dataloader_train = dataloader_train,\n",
    "    img_normalization = img_normalization,\n",
    "    box_coder = box_coder,\n",
    "    cfg = cfg,\n",
    "    count = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d977921",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_network_status(lcp._net, lcp._prune_net)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ntut-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
