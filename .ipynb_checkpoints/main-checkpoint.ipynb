{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8582b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from os2d.modeling.model import build_os2d_from_config\n",
    "from os2d.config import cfg\n",
    "import  os2d.utils.visualization as visualizer\n",
    "from os2d.structures.feature_map import FeatureMapSize\n",
    "from os2d.utils import setup_logger, read_image, get_image_size_after_resize_preserving_aspect_ratio\n",
    "from os2d.data import dataloader\n",
    "from os2d.modeling.model import build_os2d_from_config\n",
    "\n",
    "from os2d.data.dataloader import build_eval_dataloaders_from_cfg, build_train_dataloader_from_config\n",
    "from os2d.engine.train import trainval_loop\n",
    "from os2d.utils import set_random_seed, get_trainable_parameters, mkdir, save_config, setup_logger, get_data_path\n",
    "from os2d.engine.optimization import create_optimizer\n",
    "from os2d.config import cfg\n",
    "from os2d.utils.visualization import *\n",
    "import random\n",
    "import os2d.utils.visualization as visualizer\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os2d.utils import get_image_size_after_resize_preserving_aspect_ratio\n",
    "from src.util.detection import generate_detection_boxes\n",
    "from src.util.visualize import visualize_boxes_on_image\n",
    "from src.util.filter import DataLoaderDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f90fa5",
   "metadata": {},
   "source": [
    "### INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c57cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def save_evaluation_to_csv(iter, results, filename='./src/util/evaluation_results.csv'):\n",
    "    \"\"\"\n",
    "    將評估結果保存到 CSV 文件\n",
    "    \n",
    "    Args:\n",
    "        results: 評估結果字典\n",
    "        filename: CSV 文件名\n",
    "    \"\"\"\n",
    "    \n",
    "    # 確保目錄存在\n",
    "    directory = os.path.dirname(filename)\n",
    "    if directory and not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    # 提取主要指標\n",
    "    overall_metrics = results['overall_metrics']\n",
    "    bijection_stats = results['bijection_stats']\n",
    "    eval_params = results['evaluation_params']\n",
    "    \n",
    "    # 計算額外統計\n",
    "    class_metrics = results['class_metrics']\n",
    "    num_classes = len(class_metrics)\n",
    "    classes_with_perfect_score = sum(1 for metrics in class_metrics.values() if metrics['f1_score'] == 1.0)\n",
    "    classes_with_zero_score = sum(1 for metrics in class_metrics.values() if metrics['f1_score'] == 0.0)\n",
    "    \n",
    "    # 準備 CSV 數據\n",
    "    csv_data = {\n",
    "        'iteration': str(iter),\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'model_type': eval_params['model_type'],\n",
    "        'evaluated_images': eval_params['evaluated_images'],\n",
    "        'iou_threshold': eval_params['iou_threshold'],\n",
    "        'precision': overall_metrics['precision'],\n",
    "        'recall': overall_metrics['recall'],\n",
    "        'f1_score': overall_metrics['f1_score'],\n",
    "        'mean_iou': overall_metrics['mean_iou'],\n",
    "        'map': overall_metrics['map'],\n",
    "        'matching_rate': overall_metrics['matching_rate'],\n",
    "        'total_detections': bijection_stats['total_detections'],\n",
    "        'total_ground_truths': bijection_stats['total_ground_truths'],\n",
    "        'total_matched_pairs': bijection_stats['total_matched_pairs'],\n",
    "        'unmatched_detections': bijection_stats['unmatched_detections'],\n",
    "        'unmatched_gts': bijection_stats['unmatched_gts'],\n",
    "        'num_classes': num_classes,\n",
    "        'classes_perfect_score': classes_with_perfect_score,\n",
    "        'classes_zero_score': classes_with_zero_score\n",
    "    }\n",
    "    \n",
    "    # 檢查文件是否存在以決定是否寫入標題\n",
    "    file_exists = os.path.exists(filename)\n",
    "    \n",
    "    # 寫入 CSV\n",
    "    with open(filename, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_data.keys())\n",
    "        \n",
    "        # 如果文件不存在，寫入標題\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        \n",
    "        # 寫入數據\n",
    "        writer.writerow(csv_data)\n",
    "    \n",
    "    print(f\"評估結果已保存到: {filename}\")\n",
    "    return filename\n",
    "\n",
    "def show_gpu_memory_usage():\n",
    "    \"\"\"顯示當前 GPU RAM 使用情況\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.cuda.current_device()\n",
    "        device_name = torch.cuda.get_device_name(device)\n",
    "\n",
    "        # 獲取記憶體使用情況 (轉換為 GB)\n",
    "        allocated = torch.cuda.memory_allocated(device) / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved(device) / 1024**3\n",
    "        total = torch.cuda.get_device_properties(device).total_memory / 1024**3\n",
    "\n",
    "        print(f\"🖥️  GPU 設備: {device_name}\")\n",
    "        print(f\"📊 記憶體使用情況:\")\n",
    "        print(f\"   已分配: {allocated:.2f} GB\")\n",
    "        print(f\"   已保留: {reserved:.2f} GB\")\n",
    "        print(f\"   總容量: {total:.2f} GB\")\n",
    "        print(f\"   使用率: {(allocated/total)*100:.1f}%\")\n",
    "        print(f\"   保留率: {(reserved/total)*100:.1f}%\")\n",
    "\n",
    "        # 視覺化進度條\n",
    "        usage_percent = int((allocated/total)*100)\n",
    "        bar_length = 20\n",
    "        filled_length = int(bar_length * usage_percent / 100)\n",
    "        bar = '█' * filled_length + '░' * (bar_length - filled_length)\n",
    "        print(f\"   [{bar}] {usage_percent}%\")\n",
    "\n",
    "    else:\n",
    "        print(\"❌ CUDA 不可用，無法檢測 GPU 記憶體\")\n",
    "\n",
    "import torch\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    計算模型的參數數量\n",
    "    Returns:\n",
    "      total_params: 包含所有參數\n",
    "      trainable_params: 只包含 requires_grad=True 的參數\n",
    "    \"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "import io\n",
    "\n",
    "def estimate_model_size(model):\n",
    "    \"\"\"\n",
    "    將模型序列化到緩衝區，估算存檔大小（MB）\n",
    "    \"\"\"\n",
    "    buffer = io.BytesIO()\n",
    "    torch.save(model.state_dict(), buffer)\n",
    "    size_mb = buffer.getbuffer().nbytes / (1024 ** 2)\n",
    "    return size_mb\n",
    "\n",
    "def show_network_status( orig_net, prune_net ):\n",
    "    print( \"原始網路參數統計:\\n\" )\n",
    "    model = orig_net\n",
    "    total, trainable = count_parameters(model)\n",
    "    print(f\"總參數量: {total:,}\")\n",
    "    print(f\"可訓練參數量: {trainable:,}\")\n",
    "\n",
    "    size_mb = estimate_model_size(model)\n",
    "    print(f\"模型存儲大小: {size_mb:.2f} MB\")\n",
    "\n",
    "    print( \"剪枝網路參數統計:\\n\" )\n",
    "    model = prune_net\n",
    "    total, trainable = count_parameters(model)\n",
    "    print(f\"總參數量: {total:,}\")\n",
    "    print(f\"可訓練參數量: {trainable:,}\")\n",
    "\n",
    "    size_mb = estimate_model_size(model)\n",
    "    print(f\"模型存儲大小: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b091ee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.is_cuda:\n",
    "    assert torch.cuda.is_available(), \"Do not have available GPU, but cfg.is_cuda == 1\"\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# random seed\n",
    "set_random_seed(cfg.random_seed, cfg.is_cuda)\n",
    "\n",
    "# Model\n",
    "net, box_coder, criterion, img_normalization, optimizer_state = build_os2d_from_config(cfg)\n",
    "\n",
    "# Optimizer\n",
    "parameters = get_trainable_parameters(net)\n",
    "optimizer = create_optimizer(parameters, cfg.train.optim, optimizer_state)\n",
    "\n",
    "# load the dataset\n",
    "data_path = get_data_path()\n",
    "dataloader_train, datasets_train_for_eval = build_train_dataloader_from_config(cfg, box_coder, img_normalization,\n",
    "                                                                                data_path=data_path)\n",
    "\n",
    "dataloaders_eval = build_eval_dataloaders_from_cfg(cfg, box_coder, img_normalization,\n",
    "                                                    datasets_for_eval=datasets_train_for_eval,\n",
    "                                                    data_path=data_path)\n",
    "\n",
    "db = DataLoaderDB( path = './src/db/data.csv' , dataloader = dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34076cc-c36c-4b6c-a05a-08b18606492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_range_for_0 = []\n",
    "eval_range_for_1 = []\n",
    "for i in range( 1, 149 ):\n",
    "    try:\n",
    "        dataloaders_eval[0].get_batch(i)\n",
    "        eval_range_for_0.append(i)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for i in range( 1, 149 ):\n",
    "    try:\n",
    "        dataloaders_eval[1].get_batch(i)\n",
    "        eval_range_for_1.append(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d80149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lcp.ct_aoi_align import ContextAoiAlign\n",
    "transform_image = transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize(img_normalization[\"mean\"], img_normalization[\"std\"])\n",
    "                      ])\n",
    "\n",
    "context_aoi_align = ContextAoiAlign( db, dataloader_train, transform_image , net , cfg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7336e720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lcp.aux_net import AuxiliaryNetwork\n",
    "aux_net = AuxiliaryNetwork( context_aoi_align, db )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48eb8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lcp.lcp import LCP\n",
    "lcp = LCP(net, aux_net, dataloader_train)\n",
    "lcp.init_for_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d8eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.util.prune_db import PruneDBControler\n",
    "prune_db = PruneDBControler( path = './src/db/prune_channel_information-test-for_eval-2.csv' )\n",
    "prune_db.initial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417c4a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lcp.pruner import Pruner\n",
    "pruner = Pruner( lcp._prune_net )\n",
    "pruner.set_prune_db( prune_db )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d44c8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = lcp.get_layers_name()\n",
    "print( layers )\n",
    "layer_names = []\n",
    "for name, ch in layers:\n",
    "    if name.endswith('.conv1') or name.endswith('.conv2'):\n",
    "        layer_names.append( name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d02c3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcp.set_prune_db(prune_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1287006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lcp.lcpfinetune import LCPFineTune\n",
    "lcp_finetune = LCPFineTune(\n",
    "    prune_net = lcp._prune_net,\n",
    "    dataloader_train = dataloader_train,\n",
    "    img_normalization = img_normalization,\n",
    "    box_coder = box_coder,\n",
    "    cfg       = cfg,\n",
    "    optimizer=optimizer,\n",
    "    parameters=parameters\n",
    ")\n",
    "lcp_finetune._setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d084e7b",
   "metadata": {},
   "source": [
    "#### Try one layer for channel selection computing for Test SetUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bd837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, ch in layers:\n",
    "    if name == 'layer2.0.conv2':\n",
    "        pass\n",
    "    else:\n",
    "        continue\n",
    "    print(f\"{name}: {ch} channels\")\n",
    "    keep, discard = lcp.get_channel_selection_by_no_grad(\n",
    "        layer_name   = f\"net_feature_maps.{name}\",\n",
    "        discard_rate = 0.5,\n",
    "        lambda_rate  = 1.0,\n",
    "        use_image_num= 3,\n",
    "        random_seed  = 42\n",
    "    )\n",
    "    print(f\"layer {name} , 預計保留通道數量: {len(keep)}/{ch}, 預計捨棄通道數量: {len(discard)}/{ch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e71bd6b",
   "metadata": {},
   "source": [
    "### Main For Prune + Finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bd2332",
   "metadata": {},
   "source": [
    "##### Set Up for config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.defrost()\n",
    "\n",
    "cfg.train.optim.max_iter = 100\n",
    "cfg.train.do_training = True\n",
    "cfg.output.print_iter = 50\n",
    "cfg.eval.iter = 50\n",
    "cfg.train.batch_size = 1\n",
    "\n",
    "cfg.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44c2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.util.loss import LCPFinetuneCriterion\n",
    "lcp_criterion = LCPFinetuneCriterion(\n",
    "    original_criterion=criterion,  # 原始損失函數實例\n",
    "    aux_net=lcp._aux_net,  # 包含 aux_loss 方法的實例\n",
    "    auxiliary_weight=1.0  # 可以調整輔助損失權重\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf2950d",
   "metadata": {},
   "source": [
    "#### Load Pruned Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa8fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.lcp.recontruction import LCPReconstruction\n",
    "# lcp_reconstruction = LCPReconstruction(\n",
    "#     prune_db = prune_db,\n",
    "#     pruner = pruner,\n",
    "#     prune_net = lcp._prune_net\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900274f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lcp_reconstruction.load_checkpoint_with_pruned_net(\n",
    "#     './src/util/checkpoints-test/checkpoint_lcp_finetune_26_layer3.5.conv2.pth'\n",
    "# )\n",
    "# lcp._prune_net = lcp_reconstruction._prune_net\n",
    "# pruned_layers = []\n",
    "# for layer in lcp_reconstruction._pruned_layers:\n",
    "#     if layer not in pruned_layers:\n",
    "#         pruned_layers.append(layer)\n",
    "# for layer in pruned_layers:\n",
    "#     lcp.prune_layer(\n",
    "#         layer_name   = layer,\n",
    "#         discard_rate = None,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce45713d",
   "metadata": {},
   "source": [
    "##### Main code for LCP Algorithm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e346e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = lcp.evaluate(\n",
    "        dataloader_train,\n",
    "        img_normalization,\n",
    "        box_coder,\n",
    "        cfg,\n",
    "        count=50\n",
    "    )\n",
    "\n",
    "filename = save_evaluation_to_csv( f\"before_prune_iter_in_0_for_train\" , eval_results)\n",
    "\n",
    "eval_results = lcp.evaluate(\n",
    "        dataloaders_eval[0],\n",
    "        img_normalization,\n",
    "        box_coder,\n",
    "        cfg,\n",
    "        count=50,\n",
    "        eval_list = eval_range_for_0\n",
    "    )\n",
    "\n",
    "filename = save_evaluation_to_csv( f\"before_prune_iter_in_0_for_eval0\" , eval_results)\n",
    "eval_results = lcp.evaluate(\n",
    "        dataloaders_eval[1],\n",
    "        img_normalization,\n",
    "        box_coder,\n",
    "        cfg,\n",
    "        count=50,\n",
    "        eval_list = eval_range_for_1\n",
    "    )\n",
    "\n",
    "filename = save_evaluation_to_csv( f\"before_prune_iter_in_0_for_eval1\" , eval_results)\n",
    "\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a9ba2e-db52-438d-aa0d-02156f1f404b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, layer_name in enumerate(layer_names):\n",
    "    if layer_name == 'layer3.0.conv1' or layer_name == 'layer3.1.conv1' or layer_name == 'layer3.2.conv1' or layer_name == 'layer3.3.conv1' or layer_name == 'layer3.4.conv1' or layer_name == 'layer3.5.conv1':\n",
    "        continue\n",
    "    if layer_name.endswith( \".conv2\" ) :\n",
    "        cfg.defrost()\n",
    "        cfg.train.optim.max_iter += 200\n",
    "        cfg.freeze()\n",
    "    else:\n",
    "        cfg.defrost()\n",
    "        cfg.train.optim.max_iter -= 200\n",
    "        cfg.train.optim.max_iter = max( 100, cfg.train.optim.max_iter )\n",
    "        cfg.freeze()\n",
    "    if idx > 13:\n",
    "        cfg.defrost()\n",
    "        cfg.train.optim.max_iter += 200\n",
    "        lcp.prune_layer(\n",
    "            layer_name   = layer_name,\n",
    "            discard_rate = 0.3,\n",
    "        )\n",
    "        cfg.freeze()\n",
    "    else:\n",
    "        lcp.prune_layer(\n",
    "            layer_name   = layer_name,\n",
    "            discard_rate = 0.7,\n",
    "        )\n",
    "    lcp_finetune.start_finetune(\n",
    "        criterion= lcp_criterion,  # 使用自定義損失函數\n",
    "    )\n",
    "    show_gpu_memory_usage()\n",
    "    print(f\"剪枝後網路狀態 (第 {idx+1}, {layer_name} 層):\")\n",
    "    show_network_status(lcp._net, lcp_finetune._prune_net)\n",
    "    lcp._prune_net = lcp_finetune._prune_net  # 更新剪枝網路\n",
    "    lcp.save_checkpoint_with_pruned_net(\n",
    "        log_path = './src/util/checkpoints-test6',\n",
    "        optimizer = optimizer,\n",
    "        model_name = f\"lcp_finetune_{idx+1}_{layer_name}\",\n",
    "        i_iter = cfg.train.optim.max_iter\n",
    "    )\n",
    "    lcp.debug_for_test_vision(\n",
    "        dataloader_train = dataloader_train,\n",
    "        img_normalization = img_normalization,\n",
    "        box_coder = box_coder,\n",
    "        cfg = cfg,\n",
    "        count = 2\n",
    "    )\n",
    "    from PIL import Image\n",
    "\n",
    "    # 讀取圖片\n",
    "    img = Image.open(\"./visualized_images/image_None_.png\")\n",
    "    \n",
    "    # 存成新檔名\n",
    "    count += cfg.train.optim.max_iter\n",
    "    img.save(f\"./visualized_images/{layer_name}_{count}.png\")\n",
    "    eval_results = lcp.evaluate(\n",
    "        dataloader_train,\n",
    "        img_normalization,\n",
    "        box_coder,\n",
    "        cfg,\n",
    "        count=50\n",
    "    )\n",
    "\n",
    "    filename = save_evaluation_to_csv( f\"{layer_name}_iter_{count}_training_set\" , eval_results )\n",
    "    \n",
    "    eval_results = lcp.evaluate(\n",
    "            dataloaders_eval[0],\n",
    "            img_normalization,\n",
    "            box_coder,\n",
    "            cfg,\n",
    "            count=50,\n",
    "            eval_list = eval_range_for_0\n",
    "        )\n",
    "    \n",
    "    filename = save_evaluation_to_csv( f\"{layer_name}_iter_{count}_eval_set0\" , eval_results)\n",
    "    eval_results = lcp.evaluate(\n",
    "            dataloaders_eval[1],\n",
    "            img_normalization,\n",
    "            box_coder,\n",
    "            cfg,\n",
    "            count=50,\n",
    "            eval_list = eval_range_for_1\n",
    "        )\n",
    "    \n",
    "    filename = save_evaluation_to_csv( f\"{layer_name}_iter_{count}_eval_set1\" , eval_results)\n",
    "    \n",
    "\n",
    "\n",
    "lcp.debug_for_test_vision(\n",
    "    dataloader_train = dataloader_train,\n",
    "    img_normalization = img_normalization,\n",
    "    box_coder = box_coder,\n",
    "    cfg = cfg,\n",
    "    count = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d533e41e",
   "metadata": {},
   "source": [
    "##### The Global Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cd836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_network_status(lcp._net, lcp._prune_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e9799",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_finetune_iter = 20000\n",
    "cfg.defrost()\n",
    "cfg.train.optim.max_iter = 100\n",
    "cfg.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a986c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range( int(global_finetune_iter / cfg.train.optim.max_iter) ):\n",
    "    print(f\"Global Finetune Iteration: {iter+1}/{int(global_finetune_iter / cfg.train.optim.max_iter)}\")\n",
    "    lcp_finetune.start_finetune(\n",
    "        criterion= lcp_criterion,  # 使用自定義損失函數\n",
    "    )\n",
    "    lcp.save_checkpoint_with_pruned_net(\n",
    "        log_path = './src/util/checkpoints-test4',\n",
    "        optimizer = optimizer,\n",
    "        model_name = f\"lcp_finetune_{iter+1}_global\",\n",
    "        i_iter = cfg.train.optim.max_iter\n",
    "    )\n",
    "    lcp._prune_net = lcp_finetune._prune_net  # 更新剪枝網路\n",
    "    lcp.debug_for_test_vision(\n",
    "        dataloader_train = dataloader_train,\n",
    "        img_normalization = img_normalization,\n",
    "        box_coder = box_coder,\n",
    "        cfg = cfg,\n",
    "        count = 2\n",
    "    )\n",
    "\n",
    "    from PIL import Image\n",
    "\n",
    "    # 讀取圖片\n",
    "    img = Image.open(\"./visualized_images/image_None_.png\")\n",
    "    \n",
    "    # 存成新檔名\n",
    "    img.save(f\"./visualized_images/{iter}.png\")\n",
    "\n",
    "    eval_results = lcp.evaluate(\n",
    "        dataloader_train,\n",
    "        img_normalization,\n",
    "        box_coder,\n",
    "        cfg,\n",
    "        count=100\n",
    "    )\n",
    "\n",
    "    filename = save_evaluation_to_csv( f\"{iter}_iter_{cfg.train.optim.max_iter*(idx+1)}\" , eval_results )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ntut-project]",
   "language": "python",
   "name": "conda-env-ntut-project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
