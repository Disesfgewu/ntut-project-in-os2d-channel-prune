{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eee1f048",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d51eb0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from os2d.modeling.model import build_os2d_from_config\n",
    "from os2d.config import cfg\n",
    "import  os2d.utils.visualization as visualizer\n",
    "from os2d.structures.feature_map import FeatureMapSize\n",
    "from os2d.utils import setup_logger, read_image, get_image_size_after_resize_preserving_aspect_ratio\n",
    "from os2d.data import dataloader\n",
    "from os2d.modeling.model import build_os2d_from_config\n",
    "\n",
    "from os2d.data.dataloader import build_eval_dataloaders_from_cfg, build_train_dataloader_from_config\n",
    "from os2d.engine.train import trainval_loop\n",
    "from os2d.utils import set_random_seed, get_trainable_parameters, mkdir, save_config, setup_logger, get_data_path\n",
    "from os2d.engine.optimization import create_optimizer\n",
    "from os2d.config import cfg\n",
    "from os2d.utils.visualization import *\n",
    "import random\n",
    "import os2d.utils.visualization as visualizer\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os2d.utils import get_image_size_after_resize_preserving_aspect_ratio\n",
    "from src.util.detection import generate_detection_boxes\n",
    "from src.util.visualize import visualize_boxes_on_image\n",
    "from src.util.filter import DataLoaderDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab2480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.is_cuda:\n",
    "    assert torch.cuda.is_available(), \"Do not have available GPU, but cfg.is_cuda == 1\"\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# random seed\n",
    "set_random_seed(cfg.random_seed, cfg.is_cuda)\n",
    "\n",
    "# Model\n",
    "net, box_coder, criterion, img_normalization, optimizer_state = build_os2d_from_config(cfg)\n",
    "\n",
    "# Optimizer\n",
    "parameters = get_trainable_parameters(net)\n",
    "optimizer = create_optimizer(parameters, cfg.train.optim, optimizer_state)\n",
    "\n",
    "# load the dataset\n",
    "data_path = get_data_path()\n",
    "dataloader_train, datasets_train_for_eval = build_train_dataloader_from_config(cfg, box_coder, img_normalization,\n",
    "                                                                                data_path=data_path)\n",
    "\n",
    "dataloaders_eval = build_eval_dataloaders_from_cfg(cfg, box_coder, img_normalization,\n",
    "                                                    datasets_for_eval=datasets_train_for_eval,\n",
    "                                                    data_path=data_path)\n",
    "\n",
    "db = DataLoaderDB( path = './src/db/data.csv' , dataloader = dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe117baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "image_ids = list ( map( int , db.get_image_ids()) )\n",
    "sorted_image_ids = sorted(image_ids)\n",
    "print( sorted_image_ids )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ab8e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lcp.ct_aoi_align import ContextAoiAlign\n",
    "transform_image = transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize(img_normalization[\"mean\"], img_normalization[\"std\"])\n",
    "                      ])\n",
    "\n",
    "context_aoi_align = ContextAoiAlign( db, dataloader_train, transform_image , net , cfg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9524c3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lcp.aux_net import AuxiliaryNetwork\n",
    "aux_net = AuxiliaryNetwork( context_aoi_align, db )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fef114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lcp.lcp import LCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f51a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LCP] 初始化完成，共 43 層的 channel 索引\n"
     ]
    }
   ],
   "source": [
    "lcp = LCP(net, aux_net, dataloader_train)\n",
    "lcp.init_for_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84da66cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "檔案 ./src/db/prune_channel_information.csv 已存在，將刪除並重新創建。\n",
      "創建新檔案: ./src/db/prune_channel_information.csv\n",
      "檔案 ./src/db/prune_channel_information.csv 初始化完成。\n"
     ]
    }
   ],
   "source": [
    "from src.util.prune_db import PruneDBControler\n",
    "prune_db = PruneDBControler( path = './src/db/prune_channel_information.csv' )\n",
    "prune_db.initial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "102c0911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer2.0.conv2: 128 channels\n",
      "[LCP] 開始基於數學推導的無梯度通道重要性計算 - net_feature_maps.layer2.0.conv2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "無有效的特徵統計資料",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m channels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m keep, discard \u001b[38;5;241m=\u001b[39m \u001b[43mlcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_channel_selection_by_no_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnet_feature_maps.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiscard_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambda_rate\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_image_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\n\u001b[0;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m , 預計保留通道數量: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(keep)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, 預計捨棄通道數量: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(discard)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m prune_db\u001b[38;5;241m.\u001b[39mwrite_data(\n\u001b[0;32m     17\u001b[0m     layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnet_feature_maps.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m     original_channel_num\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(keep) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(discard),\n\u001b[0;32m     19\u001b[0m     num_of_keep_channel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(keep),\n\u001b[0;32m     20\u001b[0m     keep_index  \u001b[38;5;241m=\u001b[39m keep\n\u001b[0;32m     21\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\marti\\os2d-in-Channel-Prune\\src\\lcp\\lcp.py:727\u001b[0m, in \u001b[0;36mLCP.get_channel_selection_by_no_grad\u001b[1;34m(self, layer_name, discard_rate, lambda_rate, use_image_num, random_seed)\u001b[0m\n\u001b[0;32m    724\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(random_seed)\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# -------- 1. 計算通道重要性 --------\u001b[39;00m\n\u001b[1;32m--> 727\u001b[0m importance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_channel_importance_no_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambda_rate\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlambda_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_image_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muse_image_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# numpy array, shape = [C]\u001b[39;00m\n\u001b[0;32m    734\u001b[0m C \u001b[38;5;241m=\u001b[39m importance\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m C \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\marti\\os2d-in-Channel-Prune\\src\\lcp\\lcp.py:476\u001b[0m, in \u001b[0;36mLCP.compute_channel_importance_no_grad\u001b[1;34m(self, layer_name, lambda_rate, use_image_num, random_seed)\u001b[0m\n\u001b[0;32m    473\u001b[0m     all_auxiliary_losses\u001b[38;5;241m.\u001b[39mappend(auxiliary_loss)\n\u001b[0;32m    475\u001b[0m \u001b[38;5;66;03m# 4. 基於理論公式整合最終重要性\u001b[39;00m\n\u001b[1;32m--> 476\u001b[0m importance_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_integrate_importance_with_mathematical_formula\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_feature_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_reconstruction_errors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_auxiliary_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_rate\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LCP] 基於數學推導的無梯度計算完成\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m importance_scores\n",
      "File \u001b[1;32mc:\\Users\\marti\\os2d-in-Channel-Prune\\src\\lcp\\lcp.py:669\u001b[0m, in \u001b[0;36mLCP._integrate_importance_with_mathematical_formula\u001b[1;34m(self, feature_stats, reconstruction_errors, auxiliary_losses, lambda_rate)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"基於數學推導整合最終重要性分數\"\"\"\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m feature_stats:\n\u001b[1;32m--> 669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m無有效的特徵統計資料\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    671\u001b[0m num_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(feature_stats[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    672\u001b[0m importance_scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(num_channels)\n",
      "\u001b[1;31mValueError\u001b[0m: 無有效的特徵統計資料"
     ]
    }
   ],
   "source": [
    "\n",
    "layers = lcp.get_layers_name()\n",
    "for name, ch in layers:\n",
    "    if name == 'layer2.0.conv2' or name == 'layer3.0.conv2':\n",
    "        pass\n",
    "    else:\n",
    "        continue\n",
    "    print(f\"{name}: {ch} channels\")\n",
    "    keep, discard = lcp.get_channel_selection_by_no_grad(\n",
    "        layer_name   = f\"net_feature_maps.{name}\",\n",
    "        discard_rate = 0.5,\n",
    "        lambda_rate  = 1.0,\n",
    "        use_image_num= 3,\n",
    "        random_seed  = 42\n",
    "    )\n",
    "    print(f\"layer {name} , 預計保留通道數量: {len(keep)}/{ch}, 預計捨棄通道數量: {len(discard)}/{ch}\")\n",
    "    prune_db.write_data(\n",
    "        layer = f\"net_feature_maps.{name}\",\n",
    "        original_channel_num= len(keep) + len(discard),\n",
    "        num_of_keep_channel = len(keep),\n",
    "        keep_index  = keep\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca06801",
   "metadata": {},
   "source": [
    "### Test for Pruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c49fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lcp.pruner import Pruner\n",
    "pruner = Pruner( lcp._prune_net )\n",
    "pruner.set_prune_db( prune_db )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c900df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( layers )\n",
    "layer_names = []\n",
    "for name, ch in layers:\n",
    "    if name.endswith('.conv1') or name.endswith('.conv2'):\n",
    "        layer_names.append( name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab98a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, layer_name in enumerate(layer_names):\n",
    "    if idx != 15:\n",
    "        continue\n",
    "    lcp.prune_layer(\n",
    "        layer_name   = layer_name,\n",
    "        discard_rate = 0.8,\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13146c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( lcp._prune_net )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c77918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lcp.lcpfinetune import LCPFineTune\n",
    "lcp_finetune = LCPFineTune(\n",
    "    prune_net = lcp._prune_net,\n",
    "    dataloader_train = dataloader_train,\n",
    "    img_normalization = img_normalization,\n",
    "    box_coder = box_coder,\n",
    "    cfg       = cfg,\n",
    "    optimizer=optimizer,\n",
    "    parameters=parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e63785",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.defrost()\n",
    "\n",
    "cfg.train.optim.max_iter = 10\n",
    "cfg.train.do_training = True\n",
    "cfg.output.print_iter = 2\n",
    "cfg.eval.iter = 5\n",
    "cfg.train.batch_size = 1\n",
    "cfg.train.batch_size = 1  # 最小批次\n",
    "cfg.train.accumulate_grad_batches = 1\n",
    "\n",
    "# 關閉不必要的功能\n",
    "if hasattr(cfg.train, 'mining'):\n",
    "    cfg.train.mining.do_mining = False\n",
    "if hasattr(cfg.output, 'best_model'):\n",
    "    cfg.output.best_model.do_get_best_model = False\n",
    "\n",
    "cfg.freeze()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2136f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.util.loss import LCPFinetuneCriterion\n",
    "lcp_criterion = LCPFinetuneCriterion(\n",
    "    original_criterion=criterion,  # 原始損失函數實例\n",
    "    aux_net=lcp._aux_net,  # 包含 aux_loss 方法的實例\n",
    "    auxiliary_weight=1.0  # 可以調整輔助損失權重\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2841cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcp_finetune.start_finetune(\n",
    "    criterion= lcp_criterion,  # 使用自定義損失函數\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa97dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lcp_finetune.finetune_one_batch(\n",
    "#     batch_data = data,\n",
    "#     lcp_instance = lcp,\n",
    "#     criterion = criterion\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lcp_finetune.finetune_loop(\n",
    "#     lcp_instance = lcp,\n",
    "#     criterion = criterion,\n",
    "#     dataloaders_eval = dataloaders_eval,\n",
    "#     max_iters = 5,\n",
    "#     print_interval=2\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntut-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
