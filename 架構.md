架構：
LCP Pruner ( ResNetFeatureExtractor(ResNet) ):
   Original NetWork : 
      orig_net ( ResNetFeatureExtractor(ResNet) ) , load when init from checkpoint.pth 
   Pruned NetWork : 
      pruned_net ( ResNetFeatureExtractor(ResNet) ) , copy from Orignal when init
   Auxiliary Network : 
      aux_net ( ResNet ) , Create when init, contains Contextual Roi Align
   Finetune Loss : 
      return L_f , L_f = L_a + L_c + L_r 
   Reconstruction Loss: 
      X = from Dataloader D then get feature map X 
      M = number of channel after prune
      Q = M*H*Y (number)
      return Lre = 1/2Q||F - X * Wc ||^2 , where Q = M*H*Y , C is selection channels , M: number of channel after prune, H: height of feature map, Y: width of feature map, * : convolution operation
   Finetune Pruned network:
      Finetune Network... 
   
   Joint Loss:
      return min_Wc_Loss(Wc) = Lre(Wc) + a*L_f(Wc)

   update:
      return Wc = Wc - n * ( partial( Joint Loss(Wc) ) / partial( Wc ) )

   Prune Method algorithm 1:
      LCP( L: number of layers , W: Weigth of original model { W[l] | 0 < l < L } , D: Training Dataset, n: prune rate ):
         W_c[l] = W[l] for l in range( 1, L+1 ) , initailize
         for l in range( 1 , L+1 ):
            Finetune Pruned ( Fine tune Loss )
            Lre = Reconstruction Loss
            sele_chan = aux_net.con_roi_align.channel_selection
            W_c[l] = udpate

Auxiliary Network ( ResNet ):
   Contextual Roi Align ( RoiAlign ):
      con_roi_align, create when init
   Loss Functon:
      loss_f : an loss function object
   Loss( number ):
      return La = loss_f.CLS Loss + loss_f.Reg Loss
   Update Channel:
      Update Channel When Finetune in Pruned Network

   Contextual Roi Align( RoiAlign ):
      Pixel Alignment:
         return F(x, y) = sigma( i = 1 , 4 ) Wi * F(xi, yi) , (xi, yi) is the 4 neibors boxes from it
      Region of Interest Feature Extraction:
         return Froi = 1/N * (sigma(i=1, N) F(xi, yi) ) , N is the channel number of the layer
      Enlarging Receptive Fields:
         return IoU_AB = |A and B|/|A or B| , A : Ground Truth(From Dataset ) , B : Default Box(From Original Network)
      Context Awareness:
         return ( (Xc1, Yc1) , (Xc2, Yc2) ) = ( ( min(Xa1, Xb1) , min(Ya1, Yb1) ), ( max( Xa2, Xb2) , max( Ya2, Yb2 ) ) ) 
      Channel Importance:
         return Sk = sigma(i=1, H)sigma( j=1 , W ) (partial(L)/parital(Wk_i_j) )^2 , Sk the importance of k-th channel, Wk_i_j the weight of the channel
      Channel Selection:
         importance_list = Channel Importance( for l in range( 1, Layer channel max number+1 ) )
         sort( importance_list , descending )
         return importance_list[0: int(len(importance_list)*n) ]

   Loss Function:
      CLS Loss:
         return Lac = sigma(i) Ei , E is cross Entroy Loss
      GIoU Loss:
         return GIoU_AB = con_roi_align.Enlarging Receptive Fields( A, B ) - | Context Awareness(A, B) - ( A or B ) | / | Context Awareness(A, B) |
      Reg Loss:
         return Lar = sigma(i)m(1- GIoU Loss(i) ), m is constant default to 50
      

### 暑假進度設計

任務條列：
首要目標：
- [ ] 閱讀 UPScale Paper 查看作法
- [ ] 閱讀 AdaPruner Paper 查看作法和 BN 重建的東西
- [ ] 重讀 LCP Paper 並重新根據論文設計架構

os2d
- [ ] 1. 查看使用 dataloader load data from grozi 的格式是怎麼處理 目標：輸出一個 image 的圖片跟圈選框
- [ ] 2. 找出怎麼 input 一組 class & input image 可以直接得到 output 的座標 目標：做出 detection function 用於輸入一個 image from dataloader 且用框選的位置為 class image 後輸出偵測框+圈選框 並輸出信心值
- [ ] 3. 查看要怎麼可以限制框選的數量

lcp
- [ ] 1. 實作 contextualroialign
   - [ ] 目標：要提供一個 api Channel Selection() 可以回傳出保留通道
   - [ ] 目標：實作出
- [ ] 2. 實作 loss function
- [ ] 3. 實作 auxiliary network

